{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esperanto import AIFactory\n",
    "\n",
    "messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What's the capital of France?\"},\n",
    "    ]\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"max_tokens\": 850,\n",
    "    \"temperature\": 1.0,\n",
    "    \"streaming\": False,\n",
    "    \"top_p\": 0.9,\n",
    "    \"structured\": None\n",
    "}\n",
    "\n",
    "models = [\n",
    "    (\"openai-compatible\", AIFactory.create_language(\"openai-compatible\", \"qwen3:4b\")),\n",
    "    (\"openrouter\", AIFactory.create_language(\"openrouter\", \"openai/gpt-4o\")),\n",
    "    (\"openai\", AIFactory.create_language(\"openai\", \"gpt-5-mini\")),\n",
    "    (\"xai\", AIFactory.create_language(\"xai\", \"grok-3\")),\n",
    "    (\"groq\", AIFactory.create_language(\"groq\", \"llama3-8b-8192\")),\n",
    "    (\"anthropic\", AIFactory.create_language(\"anthropic\", \"claude-4-sonnet-latest\")),\n",
    "    (\"ollama\", AIFactory.create_language(\"ollama\", \"gemma3:4b\")),\n",
    "    (\"google\", AIFactory.create_language(\"google\", \"gemini-2.0-flash\")),\n",
    "    (\"google\", AIFactory.create_language(\"google\", \"gemini-2.5-flash\")),\n",
    "    (\"azure\", AIFactory.create_language(\"azure\", \"o4-mini\")),\n",
    "    (\"mistral\", AIFactory.create_language(\"mistral\", \"mistral-large-latest\")),\n",
    "    (\"deepseek\", AIFactory.create_language(\"deepseek\", \"deepseek-chat\")),\n",
    "    (\"vertex\", AIFactory.create_language(\"vertex\", \"gemini-2.0-flash\")),\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Models (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OPENAI-COMPATIBLE Models ===\n",
      "[Model(id='text-embedding-mxbai-embed-large-v1', owned_by='organization_owner', context_window=None, type='language'), Model(id='text-embedding-embeddinggemma-300m-qat', owned_by='organization_owner', context_window=None, type='language'), Model(id='text-embedding-nomic-embed-text-v1.5', owned_by='organization_owner', context_window=None, type='language'), Model(id='qwen/qwen3-4b', owned_by='organization_owner', context_window=None, type='language')]\n",
      "\n",
      "=== OPENROUTER Models ===\n",
      "[Model(id='minimax/minimax-m2:free', owned_by='minimax', context_window=None, type='language'), Model(id='openrouter/andromeda-alpha', owned_by='openrouter', context_window=None, type='language'), Model(id='liquid/lfm2-8b-a1b', owned_by='liquid', context_window=None, type='language'), Model(id='liquid/lfm-2.2-6b', owned_by='liquid', context_window=None, type='language'), Model(id='ibm-granite/granite-4.0-h-micro', owned_by='ibm-granite', context_window=None, type='language'), Model(id='deepcogito/cogito-v2-preview-llama-405b', owned_by='deepcogito', context_window=None, type='language'), Model(id='openai/gpt-5-image-mini', owned_by='openai', context_window=None, type='language'), Model(id='anthropic/claude-haiku-4.5', owned_by='anthropic', context_window=None, type='language'), Model(id='qwen/qwen3-vl-8b-thinking', owned_by='qwen', context_window=None, type='language'), Model(id='qwen/qwen3-vl-8b-instruct', owned_by='qwen', context_window=None, type='language'), Model(id='openai/gpt-5-image', owned_by='openai', context_window=None, type='language'), Model(id='inclusionai/ring-1t', owned_by='inclusionai', context_window=None, type='language'), Model(id='inclusionai/ling-1t', owned_by='inclusionai', context_window=None, type='language'), Model(id='openai/o3-deep-research', owned_by='openai', context_window=None, type='language'), Model(id='openai/o4-mini-deep-research', owned_by='openai', context_window=None, type='language'), Model(id='nvidia/llama-3.3-nemotron-super-49b-v1.5', owned_by='nvidia', context_window=None, type='language'), Model(id='baidu/ernie-4.5-21b-a3b-thinking', owned_by='baidu', context_window=None, type='language'), Model(id='google/gemini-2.5-flash-image', owned_by='google', context_window=None, type='language'), Model(id='qwen/qwen3-vl-30b-a3b-thinking', owned_by='qwen', context_window=None, type='language'), Model(id='qwen/qwen3-vl-30b-a3b-instruct', owned_by='qwen', context_window=None, type='language'), Model(id='openai/gpt-5-pro', owned_by='openai', context_window=None, type='language'), Model(id='z-ai/glm-4.6', owned_by='z-ai', context_window=None, type='language'), Model(id='z-ai/glm-4.6:exacto', owned_by='z-ai', context_window=None, type='language'), Model(id='anthropic/claude-sonnet-4.5', owned_by='anthropic', context_window=None, type='language'), Model(id='deepseek/deepseek-v3.2-exp', owned_by='deepseek', context_window=None, type='language'), Model(id='thedrummer/cydonia-24b-v4.1', owned_by='thedrummer', context_window=None, type='language'), Model(id='relace/relace-apply-3', owned_by='relace', context_window=None, type='language'), Model(id='google/gemini-2.5-flash-preview-09-2025', owned_by='google', context_window=None, type='language'), Model(id='google/gemini-2.5-flash-lite-preview-09-2025', owned_by='google', context_window=None, type='language'), Model(id='qwen/qwen3-vl-235b-a22b-thinking', owned_by='qwen', context_window=None, type='language'), Model(id='qwen/qwen3-vl-235b-a22b-instruct', owned_by='qwen', context_window=None, type='language'), Model(id='qwen/qwen3-max', owned_by='qwen', context_window=None, type='language'), Model(id='qwen/qwen3-coder-plus', owned_by='qwen', context_window=None, type='language'), Model(id='openai/gpt-5-codex', owned_by='openai', context_window=None, type='language'), Model(id='deepseek/deepseek-v3.1-terminus', owned_by='deepseek', context_window=None, type='language'), Model(id='deepseek/deepseek-v3.1-terminus:exacto', owned_by='deepseek', context_window=None, type='language'), Model(id='x-ai/grok-4-fast', owned_by='x-ai', context_window=None, type='language'), Model(id='alibaba/tongyi-deepresearch-30b-a3b:free', owned_by='alibaba', context_window=None, type='language'), Model(id='alibaba/tongyi-deepresearch-30b-a3b', owned_by='alibaba', context_window=None, type='language'), Model(id='qwen/qwen3-coder-flash', owned_by='qwen', context_window=None, type='language'), Model(id='arcee-ai/afm-4.5b', owned_by='arcee-ai', context_window=None, type='language'), Model(id='opengvlab/internvl3-78b', owned_by='opengvlab', context_window=None, type='language'), Model(id='qwen/qwen3-next-80b-a3b-thinking', owned_by='qwen', context_window=None, type='language'), Model(id='qwen/qwen3-next-80b-a3b-instruct', owned_by='qwen', context_window=None, type='language'), Model(id='meituan/longcat-flash-chat:free', owned_by='meituan', context_window=None, type='language'), Model(id='meituan/longcat-flash-chat', owned_by='meituan', context_window=None, type='language'), Model(id='qwen/qwen-plus-2025-07-28', owned_by='qwen', context_window=None, type='language'), Model(id='qwen/qwen-plus-2025-07-28:thinking', owned_by='qwen', context_window=None, type='language'), Model(id='nvidia/nemotron-nano-9b-v2:free', owned_by='nvidia', context_window=None, type='language'), Model(id='nvidia/nemotron-nano-9b-v2', owned_by='nvidia', context_window=None, type='language'), Model(id='moonshotai/kimi-k2-0905', owned_by='moonshotai', context_window=None, type='language'), Model(id='moonshotai/kimi-k2-0905:exacto', owned_by='moonshotai', context_window=None, type='language'), Model(id='deepcogito/cogito-v2-preview-llama-70b', owned_by='deepcogito', context_window=None, type='language'), Model(id='deepcogito/cogito-v2-preview-llama-109b-moe', owned_by='deepcogito', context_window=None, type='language'), Model(id='deepcogito/cogito-v2-preview-deepseek-671b', owned_by='deepcogito', context_window=None, type='language'), Model(id='stepfun-ai/step3', owned_by='stepfun-ai', context_window=None, type='language'), Model(id='qwen/qwen3-30b-a3b-thinking-2507', owned_by='qwen', context_window=None, type='language'), Model(id='x-ai/grok-code-fast-1', owned_by='x-ai', context_window=None, type='language'), Model(id='nousresearch/hermes-4-70b', owned_by='nousresearch', context_window=None, type='language'), Model(id='nousresearch/hermes-4-405b', owned_by='nousresearch', context_window=None, type='language'), Model(id='google/gemini-2.5-flash-image-preview', owned_by='google', context_window=None, type='language'), Model(id='deepseek/deepseek-chat-v3.1:free', owned_by='deepseek', context_window=None, type='language'), Model(id='deepseek/deepseek-chat-v3.1', owned_by='deepseek', context_window=None, type='language'), Model(id='openai/gpt-4o-audio-preview', owned_by='openai', context_window=None, type='language'), Model(id='mistralai/mistral-medium-3.1', owned_by='mistralai', context_window=None, type='language'), Model(id='baidu/ernie-4.5-21b-a3b', owned_by='baidu', context_window=None, type='language'), Model(id='baidu/ernie-4.5-vl-28b-a3b', owned_by='baidu', context_window=None, type='language'), Model(id='z-ai/glm-4.5v', owned_by='z-ai', context_window=None, type='language'), Model(id='ai21/jamba-mini-1.7', owned_by='ai21', context_window=None, type='language'), Model(id='ai21/jamba-large-1.7', owned_by='ai21', context_window=None, type='language'), Model(id='openai/gpt-5-chat', owned_by='openai', context_window=None, type='language'), Model(id='openai/gpt-5', owned_by='openai', context_window=None, type='language'), Model(id='openai/gpt-5-mini', owned_by='openai', context_window=None, type='language'), Model(id='openai/gpt-5-nano', owned_by='openai', context_window=None, type='language'), Model(id='openai/gpt-oss-120b', owned_by='openai', context_window=None, type='language'), Model(id='openai/gpt-oss-120b:exacto', owned_by='openai', context_window=None, type='language'), Model(id='openai/gpt-oss-20b:free', owned_by='openai', context_window=None, type='language'), Model(id='openai/gpt-oss-20b', owned_by='openai', context_window=None, type='language'), Model(id='anthropic/claude-opus-4.1', owned_by='anthropic', context_window=None, type='language'), Model(id='mistralai/codestral-2508', owned_by='mistralai', context_window=None, type='language'), Model(id='qwen/qwen3-coder-30b-a3b-instruct', owned_by='qwen', context_window=None, type='language'), Model(id='qwen/qwen3-30b-a3b-instruct-2507', owned_by='qwen', context_window=None, type='language'), Model(id='z-ai/glm-4.5', owned_by='z-ai', context_window=None, type='language'), Model(id='z-ai/glm-4.5-air:free', owned_by='z-ai', context_window=None, type='language'), Model(id='z-ai/glm-4.5-air', owned_by='z-ai', context_window=None, type='language'), Model(id='qwen/qwen3-235b-a22b-thinking-2507', owned_by='qwen', context_window=None, type='language'), Model(id='z-ai/glm-4-32b', owned_by='z-ai', context_window=None, type='language'), Model(id='qwen/qwen3-coder:free', owned_by='qwen', context_window=None, type='language'), Model(id='qwen/qwen3-coder', owned_by='qwen', context_window=None, type='language'), Model(id='qwen/qwen3-coder:exacto', owned_by='qwen', context_window=None, type='language'), Model(id='bytedance/ui-tars-1.5-7b', owned_by='bytedance', context_window=None, type='language'), Model(id='google/gemini-2.5-flash-lite', owned_by='google', context_window=None, type='language'), Model(id='qwen/qwen3-235b-a22b-2507', owned_by='qwen', context_window=None, type='language'), Model(id='switchpoint/router', owned_by='switchpoint', context_window=None, type='language'), Model(id='moonshotai/kimi-k2:free', owned_by='moonshotai', context_window=None, type='language'), Model(id='moonshotai/kimi-k2', owned_by='moonshotai', context_window=None, type='language'), Model(id='thudm/glm-4.1v-9b-thinking', owned_by='thudm', context_window=None, type='language'), Model(id='mistralai/devstral-medium', owned_by='mistralai', context_window=None, type='language'), Model(id='mistralai/devstral-small', owned_by='mistralai', context_window=None, type='language'), Model(id='cognitivecomputations/dolphin-mistral-24b-venice-edition:free', owned_by='cognitivecomputations', context_window=None, type='language'), Model(id='x-ai/grok-4', owned_by='x-ai', context_window=None, type='language'), Model(id='google/gemma-3n-e2b-it:free', owned_by='google', context_window=None, type='language'), Model(id='tencent/hunyuan-a13b-instruct:free', owned_by='tencent', context_window=None, type='language'), Model(id='tencent/hunyuan-a13b-instruct', owned_by='tencent', context_window=None, type='language'), Model(id='tngtech/deepseek-r1t2-chimera:free', owned_by='tngtech', context_window=None, type='language'), Model(id='tngtech/deepseek-r1t2-chimera', owned_by='tngtech', context_window=None, type='language'), Model(id='morph/morph-v3-large', owned_by='morph', context_window=None, type='language'), Model(id='morph/morph-v3-fast', owned_by='morph', context_window=None, type='language'), Model(id='baidu/ernie-4.5-vl-424b-a47b', owned_by='baidu', context_window=None, type='language'), Model(id='baidu/ernie-4.5-300b-a47b', owned_by='baidu', context_window=None, type='language'), Model(id='thedrummer/anubis-70b-v1.1', owned_by='thedrummer', context_window=None, type='language'), Model(id='inception/mercury', owned_by='inception', context_window=None, type='language'), Model(id='mistralai/mistral-small-3.2-24b-instruct:free', owned_by='mistralai', context_window=None, type='language'), Model(id='mistralai/mistral-small-3.2-24b-instruct', owned_by='mistralai', context_window=None, type='language'), Model(id='minimax/minimax-m1', owned_by='minimax', context_window=None, type='language'), Model(id='google/gemini-2.5-flash-lite-preview-06-17', owned_by='google', context_window=None, type='language'), Model(id='google/gemini-2.5-flash', owned_by='google', context_window=None, type='language'), Model(id='google/gemini-2.5-pro', owned_by='google', context_window=None, type='language'), Model(id='moonshotai/kimi-dev-72b:free', owned_by='moonshotai', context_window=None, type='language'), Model(id='moonshotai/kimi-dev-72b', owned_by='moonshotai', context_window=None, type='language'), Model(id='openai/o3-pro', owned_by='openai', context_window=None, type='language'), Model(id='x-ai/grok-3-mini', owned_by='x-ai', context_window=None, type='language'), Model(id='x-ai/grok-3', owned_by='x-ai', context_window=None, type='language'), Model(id='mistralai/magistral-small-2506', owned_by='mistralai', context_window=None, type='language'), Model(id='mistralai/magistral-medium-2506:thinking', owned_by='mistralai', context_window=None, type='language'), Model(id='mistralai/magistral-medium-2506', owned_by='mistralai', context_window=None, type='language'), Model(id='google/gemini-2.5-pro-preview', owned_by='google', context_window=None, type='language'), Model(id='deepseek/deepseek-r1-0528-qwen3-8b:free', owned_by='deepseek', context_window=None, type='language'), Model(id='deepseek/deepseek-r1-0528-qwen3-8b', owned_by='deepseek', context_window=None, type='language'), Model(id='deepseek/deepseek-r1-0528:free', owned_by='deepseek', context_window=None, type='language'), Model(id='deepseek/deepseek-r1-0528', owned_by='deepseek', context_window=None, type='language'), Model(id='anthropic/claude-opus-4', owned_by='anthropic', context_window=None, type='language'), Model(id='anthropic/claude-sonnet-4', owned_by='anthropic', context_window=None, type='language'), Model(id='mistralai/devstral-small-2505:free', owned_by='mistralai', context_window=None, type='language'), Model(id='mistralai/devstral-small-2505', owned_by='mistralai', context_window=None, type='language'), Model(id='google/gemma-3n-e4b-it:free', owned_by='google', context_window=None, type='language'), Model(id='google/gemma-3n-e4b-it', owned_by='google', context_window=None, type='language'), Model(id='openai/codex-mini', owned_by='openai', context_window=None, type='language'), Model(id='meta-llama/llama-3.3-8b-instruct:free', owned_by='meta-llama', context_window=None, type='language'), Model(id='nousresearch/deephermes-3-mistral-24b-preview', owned_by='nousresearch', context_window=None, type='language'), Model(id='mistralai/mistral-medium-3', owned_by='mistralai', context_window=None, type='language'), Model(id='google/gemini-2.5-pro-preview-05-06', owned_by='google', context_window=None, type='language'), Model(id='arcee-ai/spotlight', owned_by='arcee-ai', context_window=None, type='language'), Model(id='arcee-ai/maestro-reasoning', owned_by='arcee-ai', context_window=None, type='language'), Model(id='arcee-ai/virtuoso-large', owned_by='arcee-ai', context_window=None, type='language'), Model(id='arcee-ai/coder-large', owned_by='arcee-ai', context_window=None, type='language'), Model(id='microsoft/phi-4-reasoning-plus', owned_by='microsoft', context_window=None, type='language'), Model(id='inception/mercury-coder', owned_by='inception', context_window=None, type='language'), Model(id='qwen/qwen3-4b:free', owned_by='qwen', context_window=None, type='language'), Model(id='deepseek/deepseek-prover-v2', owned_by='deepseek', context_window=None, type='language'), Model(id='meta-llama/llama-guard-4-12b', owned_by='meta-llama', context_window=None, type='language'), Model(id='qwen/qwen3-30b-a3b:free', owned_by='qwen', context_window=None, type='language'), Model(id='qwen/qwen3-30b-a3b', owned_by='qwen', context_window=None, type='language'), Model(id='qwen/qwen3-8b:free', owned_by='qwen', context_window=None, type='language'), Model(id='qwen/qwen3-8b', owned_by='qwen', context_window=None, type='language'), Model(id='qwen/qwen3-14b:free', owned_by='qwen', context_window=None, type='language'), Model(id='qwen/qwen3-14b', owned_by='qwen', context_window=None, type='language'), Model(id='qwen/qwen3-32b', owned_by='qwen', context_window=None, type='language'), Model(id='qwen/qwen3-235b-a22b:free', owned_by='qwen', context_window=None, type='language'), Model(id='qwen/qwen3-235b-a22b', owned_by='qwen', context_window=None, type='language'), Model(id='tngtech/deepseek-r1t-chimera:free', owned_by='tngtech', context_window=None, type='language'), Model(id='tngtech/deepseek-r1t-chimera', owned_by='tngtech', context_window=None, type='language'), Model(id='microsoft/mai-ds-r1:free', owned_by='microsoft', context_window=None, type='language'), Model(id='microsoft/mai-ds-r1', owned_by='microsoft', context_window=None, type='language'), Model(id='thudm/glm-z1-32b', owned_by='thudm', context_window=None, type='language'), Model(id='openai/o4-mini-high', owned_by='openai', context_window=None, type='language'), Model(id='openai/o3', owned_by='openai', context_window=None, type='language'), Model(id='openai/o4-mini', owned_by='openai', context_window=None, type='language'), Model(id='shisa-ai/shisa-v2-llama3.3-70b:free', owned_by='shisa-ai', context_window=None, type='language'), Model(id='shisa-ai/shisa-v2-llama3.3-70b', owned_by='shisa-ai', context_window=None, type='language'), Model(id='qwen/qwen2.5-coder-7b-instruct', owned_by='qwen', context_window=None, type='language'), Model(id='openai/gpt-4.1', owned_by='openai', context_window=None, type='language'), Model(id='openai/gpt-4.1-mini', owned_by='openai', context_window=None, type='language'), Model(id='openai/gpt-4.1-nano', owned_by='openai', context_window=None, type='language'), Model(id='eleutherai/llemma_7b', owned_by='eleutherai', context_window=None, type='language'), Model(id='alfredpros/codellama-7b-instruct-solidity', owned_by='alfredpros', context_window=None, type='language'), Model(id='arliai/qwq-32b-arliai-rpr-v1:free', owned_by='arliai', context_window=None, type='language'), Model(id='arliai/qwq-32b-arliai-rpr-v1', owned_by='arliai', context_window=None, type='language'), Model(id='agentica-org/deepcoder-14b-preview:free', owned_by='agentica-org', context_window=None, type='language'), Model(id='agentica-org/deepcoder-14b-preview', owned_by='agentica-org', context_window=None, type='language'), Model(id='x-ai/grok-3-mini-beta', owned_by='x-ai', context_window=None, type='language'), Model(id='x-ai/grok-3-beta', owned_by='x-ai', context_window=None, type='language'), Model(id='nvidia/llama-3.1-nemotron-ultra-253b-v1', owned_by='nvidia', context_window=None, type='language'), Model(id='meta-llama/llama-4-maverick:free', owned_by='meta-llama', context_window=None, type='language'), Model(id='meta-llama/llama-4-maverick', owned_by='meta-llama', context_window=None, type='language'), Model(id='meta-llama/llama-4-scout:free', owned_by='meta-llama', context_window=None, type='language'), Model(id='meta-llama/llama-4-scout', owned_by='meta-llama', context_window=None, type='language'), Model(id='qwen/qwen2.5-vl-32b-instruct:free', owned_by='qwen', context_window=None, type='language'), Model(id='qwen/qwen2.5-vl-32b-instruct', owned_by='qwen', context_window=None, type='language'), Model(id='deepseek/deepseek-chat-v3-0324:free', owned_by='deepseek', context_window=None, type='language'), Model(id='deepseek/deepseek-chat-v3-0324', owned_by='deepseek', context_window=None, type='language'), Model(id='openai/o1-pro', owned_by='openai', context_window=None, type='language'), Model(id='mistralai/mistral-small-3.1-24b-instruct:free', owned_by='mistralai', context_window=None, type='language'), Model(id='mistralai/mistral-small-3.1-24b-instruct', owned_by='mistralai', context_window=None, type='language'), Model(id='allenai/olmo-2-0325-32b-instruct', owned_by='allenai', context_window=None, type='language'), Model(id='google/gemma-3-4b-it:free', owned_by='google', context_window=None, type='language'), Model(id='google/gemma-3-4b-it', owned_by='google', context_window=None, type='language'), Model(id='google/gemma-3-12b-it:free', owned_by='google', context_window=None, type='language'), Model(id='google/gemma-3-12b-it', owned_by='google', context_window=None, type='language'), Model(id='cohere/command-a', owned_by='cohere', context_window=None, type='language'), Model(id='openai/gpt-4o-mini-search-preview', owned_by='openai', context_window=None, type='language'), Model(id='openai/gpt-4o-search-preview', owned_by='openai', context_window=None, type='language'), Model(id='google/gemma-3-27b-it:free', owned_by='google', context_window=None, type='language'), Model(id='google/gemma-3-27b-it', owned_by='google', context_window=None, type='language'), Model(id='thedrummer/skyfall-36b-v2', owned_by='thedrummer', context_window=None, type='language'), Model(id='microsoft/phi-4-multimodal-instruct', owned_by='microsoft', context_window=None, type='language'), Model(id='perplexity/sonar-reasoning-pro', owned_by='perplexity', context_window=None, type='language'), Model(id='perplexity/sonar-pro', owned_by='perplexity', context_window=None, type='language'), Model(id='perplexity/sonar-deep-research', owned_by='perplexity', context_window=None, type='language'), Model(id='qwen/qwq-32b', owned_by='qwen', context_window=None, type='language'), Model(id='nousresearch/deephermes-3-llama-3-8b-preview:free', owned_by='nousresearch', context_window=None, type='language'), Model(id='nousresearch/deephermes-3-llama-3-8b-preview', owned_by='nousresearch', context_window=None, type='language'), Model(id='google/gemini-2.0-flash-lite-001', owned_by='google', context_window=None, type='language'), Model(id='anthropic/claude-3.7-sonnet:thinking', owned_by='anthropic', context_window=None, type='language'), Model(id='anthropic/claude-3.7-sonnet', owned_by='anthropic', context_window=None, type='language'), Model(id='mistralai/mistral-saba', owned_by='mistralai', context_window=None, type='language'), Model(id='cognitivecomputations/dolphin3.0-mistral-24b:free', owned_by='cognitivecomputations', context_window=None, type='language'), Model(id='cognitivecomputations/dolphin3.0-mistral-24b', owned_by='cognitivecomputations', context_window=None, type='language'), Model(id='meta-llama/llama-guard-3-8b', owned_by='meta-llama', context_window=None, type='language'), Model(id='openai/o3-mini-high', owned_by='openai', context_window=None, type='language'), Model(id='google/gemini-2.0-flash-001', owned_by='google', context_window=None, type='language'), Model(id='qwen/qwen-vl-plus', owned_by='qwen', context_window=None, type='language'), Model(id='aion-labs/aion-1.0', owned_by='aion-labs', context_window=None, type='language'), Model(id='aion-labs/aion-1.0-mini', owned_by='aion-labs', context_window=None, type='language'), Model(id='aion-labs/aion-rp-llama-3.1-8b', owned_by='aion-labs', context_window=None, type='language'), Model(id='qwen/qwen-vl-max', owned_by='qwen', context_window=None, type='language'), Model(id='qwen/qwen-turbo', owned_by='qwen', context_window=None, type='language'), Model(id='qwen/qwen2.5-vl-72b-instruct', owned_by='qwen', context_window=None, type='language'), Model(id='qwen/qwen-plus', owned_by='qwen', context_window=None, type='language'), Model(id='qwen/qwen-max', owned_by='qwen', context_window=None, type='language'), Model(id='openai/o3-mini', owned_by='openai', context_window=None, type='language'), Model(id='mistralai/mistral-small-24b-instruct-2501:free', owned_by='mistralai', context_window=None, type='language'), Model(id='mistralai/mistral-small-24b-instruct-2501', owned_by='mistralai', context_window=None, type='language'), Model(id='deepseek/deepseek-r1-distill-qwen-32b', owned_by='deepseek', context_window=None, type='language'), Model(id='deepseek/deepseek-r1-distill-qwen-14b', owned_by='deepseek', context_window=None, type='language'), Model(id='perplexity/sonar-reasoning', owned_by='perplexity', context_window=None, type='language'), Model(id='perplexity/sonar', owned_by='perplexity', context_window=None, type='language'), Model(id='deepseek/deepseek-r1-distill-llama-70b:free', owned_by='deepseek', context_window=None, type='language'), Model(id='deepseek/deepseek-r1-distill-llama-70b', owned_by='deepseek', context_window=None, type='language'), Model(id='deepseek/deepseek-r1:free', owned_by='deepseek', context_window=None, type='language'), Model(id='deepseek/deepseek-r1', owned_by='deepseek', context_window=None, type='language'), Model(id='minimax/minimax-01', owned_by='minimax', context_window=None, type='language'), Model(id='mistralai/codestral-2501', owned_by='mistralai', context_window=None, type='language'), Model(id='microsoft/phi-4', owned_by='microsoft', context_window=None, type='language'), Model(id='sao10k/l3.1-70b-hanami-x1', owned_by='sao10k', context_window=None, type='language'), Model(id='deepseek/deepseek-chat', owned_by='deepseek', context_window=None, type='language'), Model(id='sao10k/l3.3-euryale-70b', owned_by='sao10k', context_window=None, type='language'), Model(id='openai/o1', owned_by='openai', context_window=None, type='language'), Model(id='cohere/command-r7b-12-2024', owned_by='cohere', context_window=None, type='language'), Model(id='google/gemini-2.0-flash-exp:free', owned_by='google', context_window=None, type='language'), Model(id='meta-llama/llama-3.3-70b-instruct:free', owned_by='meta-llama', context_window=None, type='language'), Model(id='meta-llama/llama-3.3-70b-instruct', owned_by='meta-llama', context_window=None, type='language'), Model(id='amazon/nova-lite-v1', owned_by='amazon', context_window=None, type='language'), Model(id='amazon/nova-micro-v1', owned_by='amazon', context_window=None, type='language'), Model(id='amazon/nova-pro-v1', owned_by='amazon', context_window=None, type='language'), Model(id='openai/gpt-4o-2024-11-20', owned_by='openai', context_window=None, type='language'), Model(id='mistralai/mistral-large-2411', owned_by='mistralai', context_window=None, type='language'), Model(id='mistralai/mistral-large-2407', owned_by='mistralai', context_window=None, type='language'), Model(id='mistralai/pixtral-large-2411', owned_by='mistralai', context_window=None, type='language'), Model(id='qwen/qwen-2.5-coder-32b-instruct:free', owned_by='qwen', context_window=None, type='language'), Model(id='qwen/qwen-2.5-coder-32b-instruct', owned_by='qwen', context_window=None, type='language'), Model(id='raifle/sorcererlm-8x22b', owned_by='raifle', context_window=None, type='language'), Model(id='thedrummer/unslopnemo-12b', owned_by='thedrummer', context_window=None, type='language'), Model(id='anthropic/claude-3.5-haiku', owned_by='anthropic', context_window=None, type='language'), Model(id='anthropic/claude-3.5-haiku-20241022', owned_by='anthropic', context_window=None, type='language'), Model(id='anthracite-org/magnum-v4-72b', owned_by='anthracite-org', context_window=None, type='language'), Model(id='anthropic/claude-3.5-sonnet', owned_by='anthropic', context_window=None, type='language'), Model(id='mistralai/ministral-3b', owned_by='mistralai', context_window=None, type='language'), Model(id='mistralai/ministral-8b', owned_by='mistralai', context_window=None, type='language'), Model(id='qwen/qwen-2.5-7b-instruct', owned_by='qwen', context_window=None, type='language'), Model(id='nvidia/llama-3.1-nemotron-70b-instruct', owned_by='nvidia', context_window=None, type='language'), Model(id='inflection/inflection-3-pi', owned_by='inflection', context_window=None, type='language'), Model(id='inflection/inflection-3-productivity', owned_by='inflection', context_window=None, type='language'), Model(id='anthracite-org/magnum-v2-72b', owned_by='anthracite-org', context_window=None, type='language'), Model(id='thedrummer/rocinante-12b', owned_by='thedrummer', context_window=None, type='language'), Model(id='meta-llama/llama-3.2-90b-vision-instruct', owned_by='meta-llama', context_window=None, type='language'), Model(id='meta-llama/llama-3.2-3b-instruct:free', owned_by='meta-llama', context_window=None, type='language'), Model(id='meta-llama/llama-3.2-3b-instruct', owned_by='meta-llama', context_window=None, type='language'), Model(id='meta-llama/llama-3.2-1b-instruct', owned_by='meta-llama', context_window=None, type='language'), Model(id='meta-llama/llama-3.2-11b-vision-instruct', owned_by='meta-llama', context_window=None, type='language'), Model(id='qwen/qwen-2.5-72b-instruct:free', owned_by='qwen', context_window=None, type='language'), Model(id='qwen/qwen-2.5-72b-instruct', owned_by='qwen', context_window=None, type='language'), Model(id='neversleep/llama-3.1-lumimaid-8b', owned_by='neversleep', context_window=None, type='language'), Model(id='openai/o1-mini-2024-09-12', owned_by='openai', context_window=None, type='language'), Model(id='openai/o1-mini', owned_by='openai', context_window=None, type='language'), Model(id='mistralai/pixtral-12b', owned_by='mistralai', context_window=None, type='language'), Model(id='cohere/command-r-08-2024', owned_by='cohere', context_window=None, type='language'), Model(id='cohere/command-r-plus-08-2024', owned_by='cohere', context_window=None, type='language'), Model(id='qwen/qwen-2.5-vl-7b-instruct', owned_by='qwen', context_window=None, type='language'), Model(id='sao10k/l3.1-euryale-70b', owned_by='sao10k', context_window=None, type='language'), Model(id='microsoft/phi-3.5-mini-128k-instruct', owned_by='microsoft', context_window=None, type='language'), Model(id='nousresearch/hermes-3-llama-3.1-70b', owned_by='nousresearch', context_window=None, type='language'), Model(id='nousresearch/hermes-3-llama-3.1-405b:free', owned_by='nousresearch', context_window=None, type='language'), Model(id='nousresearch/hermes-3-llama-3.1-405b', owned_by='nousresearch', context_window=None, type='language'), Model(id='openai/chatgpt-4o-latest', owned_by='openai', context_window=None, type='language'), Model(id='sao10k/l3-lunaris-8b', owned_by='sao10k', context_window=None, type='language'), Model(id='openai/gpt-4o-2024-08-06', owned_by='openai', context_window=None, type='language'), Model(id='meta-llama/llama-3.1-405b', owned_by='meta-llama', context_window=None, type='language'), Model(id='meta-llama/llama-3.1-8b-instruct', owned_by='meta-llama', context_window=None, type='language'), Model(id='meta-llama/llama-3.1-70b-instruct', owned_by='meta-llama', context_window=None, type='language'), Model(id='meta-llama/llama-3.1-405b-instruct', owned_by='meta-llama', context_window=None, type='language'), Model(id='mistralai/mistral-nemo:free', owned_by='mistralai', context_window=None, type='language'), Model(id='mistralai/mistral-nemo', owned_by='mistralai', context_window=None, type='language'), Model(id='openai/gpt-4o-mini-2024-07-18', owned_by='openai', context_window=None, type='language'), Model(id='openai/gpt-4o-mini', owned_by='openai', context_window=None, type='language'), Model(id='google/gemma-2-27b-it', owned_by='google', context_window=None, type='language'), Model(id='google/gemma-2-9b-it:free', owned_by='google', context_window=None, type='language'), Model(id='google/gemma-2-9b-it', owned_by='google', context_window=None, type='language'), Model(id='anthropic/claude-3.5-sonnet-20240620', owned_by='anthropic', context_window=None, type='language'), Model(id='sao10k/l3-euryale-70b', owned_by='sao10k', context_window=None, type='language'), Model(id='nousresearch/hermes-2-pro-llama-3-8b', owned_by='nousresearch', context_window=None, type='language'), Model(id='mistralai/mistral-7b-instruct:free', owned_by='mistralai', context_window=None, type='language'), Model(id='mistralai/mistral-7b-instruct', owned_by='mistralai', context_window=None, type='language'), Model(id='mistralai/mistral-7b-instruct-v0.3', owned_by='mistralai', context_window=None, type='language'), Model(id='microsoft/phi-3-mini-128k-instruct', owned_by='microsoft', context_window=None, type='language'), Model(id='microsoft/phi-3-medium-128k-instruct', owned_by='microsoft', context_window=None, type='language'), Model(id='openai/gpt-4o-2024-05-13', owned_by='openai', context_window=None, type='language'), Model(id='openai/gpt-4o', owned_by='openai', context_window=None, type='language'), Model(id='openai/gpt-4o:extended', owned_by='openai', context_window=None, type='language'), Model(id='meta-llama/llama-guard-2-8b', owned_by='meta-llama', context_window=None, type='language'), Model(id='meta-llama/llama-3-70b-instruct', owned_by='meta-llama', context_window=None, type='language'), Model(id='meta-llama/llama-3-8b-instruct', owned_by='meta-llama', context_window=None, type='language'), Model(id='mistralai/mixtral-8x22b-instruct', owned_by='mistralai', context_window=None, type='language'), Model(id='microsoft/wizardlm-2-8x22b', owned_by='microsoft', context_window=None, type='language'), Model(id='openai/gpt-4-turbo', owned_by='openai', context_window=None, type='language'), Model(id='anthropic/claude-3-haiku', owned_by='anthropic', context_window=None, type='language'), Model(id='anthropic/claude-3-opus', owned_by='anthropic', context_window=None, type='language'), Model(id='mistralai/mistral-large', owned_by='mistralai', context_window=None, type='language'), Model(id='openai/gpt-3.5-turbo-0613', owned_by='openai', context_window=None, type='language'), Model(id='openai/gpt-4-turbo-preview', owned_by='openai', context_window=None, type='language'), Model(id='mistralai/mistral-tiny', owned_by='mistralai', context_window=None, type='language'), Model(id='mistralai/mistral-small', owned_by='mistralai', context_window=None, type='language'), Model(id='mistralai/mistral-7b-instruct-v0.2', owned_by='mistralai', context_window=None, type='language'), Model(id='mistralai/mixtral-8x7b-instruct', owned_by='mistralai', context_window=None, type='language'), Model(id='neversleep/noromaid-20b', owned_by='neversleep', context_window=None, type='language'), Model(id='alpindale/goliath-120b', owned_by='alpindale', context_window=None, type='language'), Model(id='openrouter/auto', owned_by='openrouter', context_window=None, type='language'), Model(id='openai/gpt-4-1106-preview', owned_by='openai', context_window=None, type='language'), Model(id='openai/gpt-3.5-turbo-instruct', owned_by='openai', context_window=None, type='language'), Model(id='mistralai/mistral-7b-instruct-v0.1', owned_by='mistralai', context_window=None, type='language'), Model(id='openai/gpt-3.5-turbo-16k', owned_by='openai', context_window=None, type='language'), Model(id='mancer/weaver', owned_by='mancer', context_window=None, type='language'), Model(id='undi95/remm-slerp-l2-13b', owned_by='undi95', context_window=None, type='language'), Model(id='gryphe/mythomax-l2-13b', owned_by='gryphe', context_window=None, type='language'), Model(id='openai/gpt-4', owned_by='openai', context_window=None, type='language'), Model(id='openai/gpt-4-0314', owned_by='openai', context_window=None, type='language'), Model(id='openai/gpt-3.5-turbo', owned_by='openai', context_window=None, type='language')]\n",
      "\n",
      "=== OPENAI Models ===\n",
      "[Model(id='gpt-4-0613', owned_by='openai', context_window=None, type='language'), Model(id='gpt-4', owned_by='openai', context_window=None, type='language'), Model(id='gpt-3.5-turbo', owned_by='openai', context_window=None, type='language'), Model(id='gpt-4-0314', owned_by='openai', context_window=None, type='language'), Model(id='gpt-5-search-api-2025-10-14', owned_by='system', context_window=None, type='language'), Model(id='gpt-realtime-mini', owned_by='system', context_window=None, type='language'), Model(id='gpt-realtime-mini-2025-10-06', owned_by='system', context_window=None, type='language'), Model(id='gpt-3.5-turbo-instruct', owned_by='system', context_window=None, type='language'), Model(id='gpt-3.5-turbo-instruct-0914', owned_by='system', context_window=None, type='language'), Model(id='gpt-4-1106-preview', owned_by='system', context_window=None, type='language'), Model(id='gpt-3.5-turbo-1106', owned_by='system', context_window=None, type='language'), Model(id='gpt-4-0125-preview', owned_by='system', context_window=None, type='language'), Model(id='gpt-4-turbo-preview', owned_by='system', context_window=None, type='language'), Model(id='gpt-3.5-turbo-0125', owned_by='system', context_window=None, type='language'), Model(id='gpt-4-turbo', owned_by='system', context_window=None, type='language'), Model(id='gpt-4-turbo-2024-04-09', owned_by='system', context_window=None, type='language'), Model(id='gpt-4o', owned_by='system', context_window=None, type='language'), Model(id='gpt-4o-2024-05-13', owned_by='system', context_window=None, type='language'), Model(id='gpt-4o-mini-2024-07-18', owned_by='system', context_window=None, type='language'), Model(id='gpt-4o-mini', owned_by='system', context_window=None, type='language'), Model(id='gpt-4o-2024-08-06', owned_by='system', context_window=None, type='language'), Model(id='gpt-4o-realtime-preview-2024-10-01', owned_by='system', context_window=None, type='language'), Model(id='gpt-4o-audio-preview-2024-10-01', owned_by='system', context_window=None, type='language'), Model(id='gpt-4o-audio-preview', owned_by='system', context_window=None, type='language'), Model(id='gpt-4o-realtime-preview', owned_by='system', context_window=None, type='language'), Model(id='gpt-4o-realtime-preview-2024-12-17', owned_by='system', context_window=None, type='language'), Model(id='gpt-4o-audio-preview-2024-12-17', owned_by='system', context_window=None, type='language'), Model(id='gpt-4o-mini-realtime-preview-2024-12-17', owned_by='system', context_window=None, type='language'), Model(id='gpt-4o-mini-audio-preview-2024-12-17', owned_by='system', context_window=None, type='language'), Model(id='gpt-4o-mini-realtime-preview', owned_by='system', context_window=None, type='language'), Model(id='gpt-4o-mini-audio-preview', owned_by='system', context_window=None, type='language'), Model(id='gpt-4o-2024-11-20', owned_by='system', context_window=None, type='language'), Model(id='gpt-4o-search-preview-2025-03-11', owned_by='system', context_window=None, type='language'), Model(id='gpt-4o-search-preview', owned_by='system', context_window=None, type='language'), Model(id='gpt-4o-mini-search-preview-2025-03-11', owned_by='system', context_window=None, type='language'), Model(id='gpt-4o-mini-search-preview', owned_by='system', context_window=None, type='language'), Model(id='gpt-4o-transcribe', owned_by='system', context_window=None, type='language'), Model(id='gpt-4o-mini-transcribe', owned_by='system', context_window=None, type='language'), Model(id='gpt-4o-mini-tts', owned_by='system', context_window=None, type='language'), Model(id='gpt-4.1-2025-04-14', owned_by='system', context_window=None, type='language'), Model(id='gpt-4.1', owned_by='system', context_window=None, type='language'), Model(id='gpt-4.1-mini-2025-04-14', owned_by='system', context_window=None, type='language'), Model(id='gpt-4.1-mini', owned_by='system', context_window=None, type='language'), Model(id='gpt-4.1-nano-2025-04-14', owned_by='system', context_window=None, type='language'), Model(id='gpt-4.1-nano', owned_by='system', context_window=None, type='language'), Model(id='gpt-image-1', owned_by='system', context_window=None, type='language'), Model(id='gpt-4o-realtime-preview-2025-06-03', owned_by='system', context_window=None, type='language'), Model(id='gpt-4o-audio-preview-2025-06-03', owned_by='system', context_window=None, type='language'), Model(id='gpt-4o-transcribe-diarize', owned_by='system', context_window=None, type='language'), Model(id='gpt-5-chat-latest', owned_by='system', context_window=None, type='language'), Model(id='gpt-5-2025-08-07', owned_by='system', context_window=None, type='language'), Model(id='gpt-5', owned_by='system', context_window=None, type='language'), Model(id='gpt-5-mini-2025-08-07', owned_by='system', context_window=None, type='language'), Model(id='gpt-5-mini', owned_by='system', context_window=None, type='language'), Model(id='gpt-5-nano-2025-08-07', owned_by='system', context_window=None, type='language'), Model(id='gpt-5-nano', owned_by='system', context_window=None, type='language'), Model(id='gpt-audio-2025-08-28', owned_by='system', context_window=None, type='language'), Model(id='gpt-realtime', owned_by='system', context_window=None, type='language'), Model(id='gpt-realtime-2025-08-28', owned_by='system', context_window=None, type='language'), Model(id='gpt-audio', owned_by='system', context_window=None, type='language'), Model(id='gpt-5-codex', owned_by='system', context_window=None, type='language'), Model(id='gpt-image-1-mini', owned_by='system', context_window=None, type='language'), Model(id='gpt-5-pro-2025-10-06', owned_by='system', context_window=None, type='language'), Model(id='gpt-5-pro', owned_by='system', context_window=None, type='language'), Model(id='gpt-audio-mini', owned_by='system', context_window=None, type='language'), Model(id='gpt-audio-mini-2025-10-06', owned_by='system', context_window=None, type='language'), Model(id='gpt-5-search-api', owned_by='system', context_window=None, type='language'), Model(id='gpt-3.5-turbo-16k', owned_by='openai-internal', context_window=None, type='language')]\n",
      "\n",
      "=== XAI Models ===\n",
      "[Model(id='grok-2-1212', owned_by='X.AI', context_window=None, type='language'), Model(id='grok-2-vision-1212', owned_by='X.AI', context_window=None, type='language'), Model(id='grok-3', owned_by='X.AI', context_window=None, type='language'), Model(id='grok-3-mini', owned_by='X.AI', context_window=None, type='language'), Model(id='grok-4-0709', owned_by='X.AI', context_window=None, type='language'), Model(id='grok-4-fast-non-reasoning', owned_by='X.AI', context_window=None, type='language'), Model(id='grok-4-fast-reasoning', owned_by='X.AI', context_window=None, type='language'), Model(id='grok-code-fast-1', owned_by='X.AI', context_window=None, type='language'), Model(id='grok-2-image-1212', owned_by='X.AI', context_window=None, type='language')]\n",
      "\n",
      "=== GROQ Models ===\n",
      "[Model(id='moonshotai/kimi-k2-instruct', owned_by='Groq', context_window=128000, type='language'), Model(id='playai-tts', owned_by='Groq', context_window=128000, type='language'), Model(id='meta-llama/llama-4-scout-17b-16e-instruct', owned_by='Groq', context_window=128000, type='language'), Model(id='openai/gpt-oss-120b', owned_by='Groq', context_window=128000, type='language'), Model(id='allam-2-7b', owned_by='Groq', context_window=128000, type='language'), Model(id='meta-llama/llama-guard-4-12b', owned_by='Groq', context_window=128000, type='language'), Model(id='qwen/qwen3-32b', owned_by='Groq', context_window=128000, type='language'), Model(id='playai-tts-arabic', owned_by='Groq', context_window=128000, type='language'), Model(id='meta-llama/llama-prompt-guard-2-22m', owned_by='Groq', context_window=128000, type='language'), Model(id='llama-3.3-70b-versatile', owned_by='Groq', context_window=128000, type='language'), Model(id='openai/gpt-oss-20b', owned_by='Groq', context_window=128000, type='language'), Model(id='groq/compound-mini', owned_by='Groq', context_window=128000, type='language'), Model(id='moonshotai/kimi-k2-instruct-0905', owned_by='Groq', context_window=128000, type='language'), Model(id='whisper-large-v3', owned_by='Groq', context_window=128000, type='language'), Model(id='meta-llama/llama-4-maverick-17b-128e-instruct', owned_by='Groq', context_window=128000, type='language'), Model(id='meta-llama/llama-prompt-guard-2-86m', owned_by='Groq', context_window=128000, type='language'), Model(id='groq/compound', owned_by='Groq', context_window=128000, type='language'), Model(id='llama-3.1-8b-instant', owned_by='Groq', context_window=128000, type='language'), Model(id='whisper-large-v3-turbo', owned_by='Groq', context_window=128000, type='language')]\n",
      "\n",
      "=== ANTHROPIC Models ===\n",
      "[Model(id='claude-haiku-4-5-20251001', owned_by='Anthropic', context_window=200000, type='language'), Model(id='claude-sonnet-4-5-20250929', owned_by='Anthropic', context_window=200000, type='language'), Model(id='claude-opus-4-1-20250805', owned_by='Anthropic', context_window=200000, type='language'), Model(id='claude-opus-4-20250514', owned_by='Anthropic', context_window=200000, type='language'), Model(id='claude-sonnet-4-20250514', owned_by='Anthropic', context_window=200000, type='language'), Model(id='claude-3-7-sonnet-20250219', owned_by='Anthropic', context_window=200000, type='language'), Model(id='claude-3-5-sonnet-20241022', owned_by='Anthropic', context_window=200000, type='language'), Model(id='claude-3-5-haiku-20241022', owned_by='Anthropic', context_window=200000, type='language'), Model(id='claude-3-5-sonnet-20240620', owned_by='Anthropic', context_window=200000, type='language'), Model(id='claude-3-haiku-20240307', owned_by='Anthropic', context_window=200000, type='language'), Model(id='claude-3-opus-20240229', owned_by='Anthropic', context_window=200000, type='language')]\n",
      "\n",
      "=== OLLAMA Models ===\n",
      "[Model(id='qwen3-embedding:latest', owned_by='Ollama', context_window=32768, type='language'), Model(id='granite4:latest', owned_by='Ollama', context_window=32768, type='language'), Model(id='granite4:small-h', owned_by='Ollama', context_window=32768, type='language'), Model(id='qwen3:14b', owned_by='Ollama', context_window=32768, type='language'), Model(id='qwen3:30b', owned_by='Ollama', context_window=32768, type='language'), Model(id='phi4-mini:latest', owned_by='Ollama', context_window=32768, type='language'), Model(id='phi4:latest', owned_by='Ollama', context_window=32768, type='language'), Model(id='phi3.5:3.8b-mini-instruct-fp16', owned_by='Ollama', context_window=32768, type='language'), Model(id='mistral-nemo:latest', owned_by='Ollama', context_window=32768, type='language'), Model(id='phi3:mini-128k', owned_by='Ollama', context_window=32768, type='language'), Model(id='phi3:medium-128k', owned_by='Ollama', context_window=32768, type='language'), Model(id='mistral-small:latest', owned_by='Ollama', context_window=32768, type='language'), Model(id='phi3:14b-instruct', owned_by='Ollama', context_window=32768, type='language'), Model(id='nomic-embed-text:latest', owned_by='Ollama', context_window=32768, type='language'), Model(id='mxbai-embed-large:latest', owned_by='Ollama', context_window=32768, type='language'), Model(id='gemma3:4b', owned_by='Ollama', context_window=32768, type='language'), Model(id='gemma3:1b', owned_by='Ollama', context_window=32768, type='language'), Model(id='phi4-reasoning:latest', owned_by='Ollama', context_window=32768, type='language'), Model(id='phi4-mini-reasoning:latest', owned_by='Ollama', context_window=32768, type='language'), Model(id='deepseek-r1:latest', owned_by='Ollama', context_window=32768, type='language'), Model(id='gemma3:27b', owned_by='Ollama', context_window=32768, type='language'), Model(id='deepseek-r1:8b', owned_by='Ollama', context_window=32768, type='language'), Model(id='gemma3:12b', owned_by='Ollama', context_window=32768, type='language'), Model(id='deepseek-r1:7b', owned_by='Ollama', context_window=32768, type='language'), Model(id='deepseek-r1:14b', owned_by='Ollama', context_window=32768, type='language'), Model(id='gpt-oss:20b', owned_by='Ollama', context_window=32768, type='language'), Model(id='magistral:latest', owned_by='Ollama', context_window=32768, type='language'), Model(id='bigtiger:128k', owned_by='Ollama', context_window=32768, type='language'), Model(id='minitiger:latest', owned_by='Ollama', context_window=32768, type='language')]\n",
      "\n",
      "=== GOOGLE Models ===\n",
      "[Model(id='gemini-2.5-pro-preview-03-25', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.5-flash-preview-05-20', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.5-flash', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.5-flash-lite-preview-06-17', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.5-pro-preview-05-06', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.5-pro-preview-06-05', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.5-pro', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.0-flash-exp', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.0-flash', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.0-flash-001', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.0-flash-exp-image-generation', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.0-flash-lite-001', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.0-flash-lite', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.0-flash-preview-image-generation', owned_by='Google', context_window=32768, type='language'), Model(id='gemini-2.0-flash-lite-preview-02-05', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.0-flash-lite-preview', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.0-pro-exp', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.0-pro-exp-02-05', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-exp-1206', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.0-flash-thinking-exp-01-21', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.0-flash-thinking-exp', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.0-flash-thinking-exp-1219', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.5-flash-preview-tts', owned_by='Google', context_window=8192, type='language'), Model(id='gemini-2.5-pro-preview-tts', owned_by='Google', context_window=8192, type='language'), Model(id='learnlm-2.0-flash-experimental', owned_by='Google', context_window=1048576, type='language'), Model(id='gemma-3-1b-it', owned_by='Google', context_window=32768, type='language'), Model(id='gemma-3-4b-it', owned_by='Google', context_window=32768, type='language'), Model(id='gemma-3-12b-it', owned_by='Google', context_window=32768, type='language'), Model(id='gemma-3-27b-it', owned_by='Google', context_window=131072, type='language'), Model(id='gemma-3n-e4b-it', owned_by='Google', context_window=8192, type='language'), Model(id='gemma-3n-e2b-it', owned_by='Google', context_window=8192, type='language'), Model(id='gemini-flash-latest', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-flash-lite-latest', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-pro-latest', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.5-flash-lite', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.5-flash-image-preview', owned_by='Google', context_window=32768, type='language'), Model(id='gemini-2.5-flash-image', owned_by='Google', context_window=32768, type='language'), Model(id='gemini-2.5-flash-preview-09-2025', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.5-flash-lite-preview-09-2025', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-robotics-er-1.5-preview', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.5-computer-use-preview-10-2025', owned_by='Google', context_window=131072, type='language')]\n",
      "\n",
      "=== GOOGLE Models ===\n",
      "[Model(id='gemini-2.5-pro-preview-03-25', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.5-flash-preview-05-20', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.5-flash', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.5-flash-lite-preview-06-17', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.5-pro-preview-05-06', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.5-pro-preview-06-05', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.5-pro', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.0-flash-exp', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.0-flash', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.0-flash-001', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.0-flash-exp-image-generation', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.0-flash-lite-001', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.0-flash-lite', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.0-flash-preview-image-generation', owned_by='Google', context_window=32768, type='language'), Model(id='gemini-2.0-flash-lite-preview-02-05', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.0-flash-lite-preview', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.0-pro-exp', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.0-pro-exp-02-05', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-exp-1206', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.0-flash-thinking-exp-01-21', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.0-flash-thinking-exp', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.0-flash-thinking-exp-1219', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.5-flash-preview-tts', owned_by='Google', context_window=8192, type='language'), Model(id='gemini-2.5-pro-preview-tts', owned_by='Google', context_window=8192, type='language'), Model(id='learnlm-2.0-flash-experimental', owned_by='Google', context_window=1048576, type='language'), Model(id='gemma-3-1b-it', owned_by='Google', context_window=32768, type='language'), Model(id='gemma-3-4b-it', owned_by='Google', context_window=32768, type='language'), Model(id='gemma-3-12b-it', owned_by='Google', context_window=32768, type='language'), Model(id='gemma-3-27b-it', owned_by='Google', context_window=131072, type='language'), Model(id='gemma-3n-e4b-it', owned_by='Google', context_window=8192, type='language'), Model(id='gemma-3n-e2b-it', owned_by='Google', context_window=8192, type='language'), Model(id='gemini-flash-latest', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-flash-lite-latest', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-pro-latest', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.5-flash-lite', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.5-flash-image-preview', owned_by='Google', context_window=32768, type='language'), Model(id='gemini-2.5-flash-image', owned_by='Google', context_window=32768, type='language'), Model(id='gemini-2.5-flash-preview-09-2025', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.5-flash-lite-preview-09-2025', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-robotics-er-1.5-preview', owned_by='Google', context_window=1048576, type='language'), Model(id='gemini-2.5-computer-use-preview-10-2025', owned_by='Google', context_window=131072, type='language')]\n",
      "\n",
      "=== AZURE Models ===\n",
      "[]\n",
      "\n",
      "=== MISTRAL Models ===\n",
      "[Model(id='mistral-medium-2505', owned_by='mistralai', context_window=None, type='language'), Model(id='mistral-large-latest', owned_by='mistralai', context_window=None, type='language'), Model(id='mistral-medium-2508', owned_by='mistralai', context_window=None, type='language'), Model(id='mistral-medium-latest', owned_by='mistralai', context_window=None, type='language'), Model(id='mistral-medium', owned_by='mistralai', context_window=None, type='language'), Model(id='ministral-3b-2410', owned_by='mistralai', context_window=None, type='language'), Model(id='ministral-3b-latest', owned_by='mistralai', context_window=None, type='language'), Model(id='ministral-8b-2410', owned_by='mistralai', context_window=None, type='language'), Model(id='ministral-8b-latest', owned_by='mistralai', context_window=None, type='language'), Model(id='open-mistral-7b', owned_by='mistralai', context_window=None, type='language'), Model(id='mistral-tiny', owned_by='mistralai', context_window=None, type='language'), Model(id='mistral-tiny-2312', owned_by='mistralai', context_window=None, type='language'), Model(id='open-mistral-nemo', owned_by='mistralai', context_window=None, type='language'), Model(id='open-mistral-nemo-2407', owned_by='mistralai', context_window=None, type='language'), Model(id='mistral-tiny-2407', owned_by='mistralai', context_window=None, type='language'), Model(id='mistral-tiny-latest', owned_by='mistralai', context_window=None, type='language'), Model(id='open-mixtral-8x7b', owned_by='mistralai', context_window=None, type='language'), Model(id='mistral-small', owned_by='mistralai', context_window=None, type='language'), Model(id='mistral-small-2312', owned_by='mistralai', context_window=None, type='language'), Model(id='open-mixtral-8x22b', owned_by='mistralai', context_window=None, type='language'), Model(id='open-mixtral-8x22b-2404', owned_by='mistralai', context_window=None, type='language'), Model(id='mistral-small-2409', owned_by='mistralai', context_window=None, type='language'), Model(id='mistral-large-2407', owned_by='mistralai', context_window=None, type='language'), Model(id='mistral-large-2411', owned_by='mistralai', context_window=None, type='language'), Model(id='pixtral-large-2411', owned_by='mistralai', context_window=None, type='language'), Model(id='pixtral-large-latest', owned_by='mistralai', context_window=None, type='language'), Model(id='mistral-large-pixtral-2411', owned_by='mistralai', context_window=None, type='language'), Model(id='codestral-2501', owned_by='mistralai', context_window=None, type='language'), Model(id='codestral-2412', owned_by='mistralai', context_window=None, type='language'), Model(id='codestral-2411-rc5', owned_by='mistralai', context_window=None, type='language'), Model(id='codestral-2508', owned_by='mistralai', context_window=None, type='language'), Model(id='codestral-latest', owned_by='mistralai', context_window=None, type='language'), Model(id='devstral-small-2507', owned_by='mistralai', context_window=None, type='language'), Model(id='devstral-small-latest', owned_by='mistralai', context_window=None, type='language'), Model(id='devstral-medium-2507', owned_by='mistralai', context_window=None, type='language'), Model(id='devstral-medium-latest', owned_by='mistralai', context_window=None, type='language'), Model(id='pixtral-12b-2409', owned_by='mistralai', context_window=None, type='language'), Model(id='pixtral-12b', owned_by='mistralai', context_window=None, type='language'), Model(id='pixtral-12b-latest', owned_by='mistralai', context_window=None, type='language'), Model(id='mistral-small-2501', owned_by='mistralai', context_window=None, type='language'), Model(id='mistral-small-2503', owned_by='mistralai', context_window=None, type='language'), Model(id='mistral-small-2506', owned_by='mistralai', context_window=None, type='language'), Model(id='mistral-small-latest', owned_by='mistralai', context_window=None, type='language'), Model(id='magistral-medium-2509', owned_by='mistralai', context_window=None, type='language'), Model(id='magistral-medium-latest', owned_by='mistralai', context_window=None, type='language'), Model(id='magistral-small-2509', owned_by='mistralai', context_window=None, type='language'), Model(id='magistral-small-latest', owned_by='mistralai', context_window=None, type='language'), Model(id='voxtral-mini-2507', owned_by='mistralai', context_window=None, type='language'), Model(id='voxtral-mini-latest', owned_by='mistralai', context_window=None, type='language'), Model(id='voxtral-small-2507', owned_by='mistralai', context_window=None, type='language'), Model(id='voxtral-small-latest', owned_by='mistralai', context_window=None, type='language'), Model(id='devstral-small-2505', owned_by='mistralai', context_window=None, type='language'), Model(id='magistral-small-2506', owned_by='mistralai', context_window=None, type='language'), Model(id='magistral-medium-2506', owned_by='mistralai', context_window=None, type='language'), Model(id='magistral-small-2507', owned_by='mistralai', context_window=None, type='language'), Model(id='magistral-medium-2507', owned_by='mistralai', context_window=None, type='language'), Model(id='mistral-moderation-2411', owned_by='mistralai', context_window=None, type='language'), Model(id='mistral-moderation-latest', owned_by='mistralai', context_window=None, type='language'), Model(id='mistral-ocr-2503', owned_by='mistralai', context_window=None, type='language'), Model(id='mistral-ocr-2505', owned_by='mistralai', context_window=None, type='language'), Model(id='mistral-ocr-latest', owned_by='mistralai', context_window=None, type='language'), Model(id='voxtral-mini-transcribe-2507', owned_by='mistralai', context_window=None, type='language'), Model(id='voxtral-mini-2507', owned_by='mistralai', context_window=None, type='language'), Model(id='voxtral-mini-latest', owned_by='mistralai', context_window=None, type='language')]\n",
      "\n",
      "=== DEEPSEEK Models ===\n",
      "[]\n",
      "\n",
      "=== VERTEX Models ===\n",
      "[Model(id='gemini-2.0-flash', owned_by='Google', context_window=1000000, type='language'), Model(id='gemini-1.5-pro', owned_by='Google', context_window=2000000, type='language'), Model(id='gemini-1.5-flash', owned_by='Google', context_window=1000000, type='language'), Model(id='gemini-pro', owned_by='Google', context_window=30720, type='language')]\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    try:\n",
    "        # Create an instance of the provider class\n",
    "        provider = model[0]\n",
    "        model = model[1]\n",
    "        print(f\"\\n=== {provider.upper()} Models ===\")\n",
    "        print(model.models)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to get models for {provider}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synchronous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for openai-compatible:\n",
      "Failed to process openai-compatible: OpenAI-compatible endpoint error: No models loaded. Please load a model in the developer page or use the `lms load` command.\n",
      "Results for openrouter:\n",
      "The capital of France is Paris.\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for openai:\n",
      "The capital of France is Paris.\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for xai:\n",
      "The capital of France is Paris.\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for groq:\n",
      "Failed to process groq: Groq API error: The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.\n",
      "Results for anthropic:\n",
      "Failed to process anthropic: Anthropic API error: model: claude-4-sonnet-latest\n",
      "Results for ollama:\n",
      "The capital of France is **Paris**. \n",
      "\n",
      "Do you want to know anything else about Paris, or perhaps another countrys capital?\n",
      "The capital of France is **Paris**. \n",
      "\n",
      "Do you want to know anything else about Paris, or perhaps another countrys capital?\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for google:\n",
      "The capital of France is Paris.\n",
      "\n",
      "The capital of France is Paris.\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for google:\n",
      "The capital of France is **Paris**.\n",
      "The capital of France is **Paris**.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for azure:\n",
      "The capital of France is Paris.\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for mistral:\n",
      "The capital of France is **Paris**. \n",
      "\n",
      "Would you like to know more about Paris or France?\n",
      "The capital of France is **Paris**. \n",
      "\n",
      "Would you like to know more about Paris or France?\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for deepseek:\n",
      "The capital of France is **Paris**. It is known for its rich history, iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Notre-Dame Cathedral, as well as its cultural and artistic influence worldwide.\n",
      "The capital of France is **Paris**. It is known for its rich history, iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Notre-Dame Cathedral, as well as its cultural and artistic influence worldwide.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for vertex:\n",
      "Failed to process vertex: [Errno 2] No such file or directory: 'gcloud'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for name, llm in models:\n",
    "    try:\n",
    "        print(f\"Results for {llm.provider}:\")\n",
    "        result = llm.chat_complete(messages)\n",
    "        print(result.choices[0].message.content)\n",
    "        \n",
    "        print(result.content)\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for openai:\n",
      "The capital of France is Paris.\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for azure:\n",
      "The capital of France is Paris.\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for name, llm in models:\n",
    "    try:\n",
    "        print(f\"Results for {llm.provider}:\")\n",
    "        result = await llm.achat_complete(messages)\n",
    "        print(result.choices[0].message.content)\n",
    "        print(result.content)\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for openai:\n",
      "[{'name': 'So Paulo', 'state': 'So Paulo'}, {'name': 'Rio de Janeiro', 'state': 'Rio de Janeiro'}, {'name': 'Braslia', 'state': 'Distrito Federal'}]\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for azure:\n",
      "{'top_3_brazilian_cities': ['So Paulo', 'Rio de Janeiro', 'Braslia']}\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Please return the top 3 brazilian cities in JSON format. Dont include ```json```  in the response.\"},\n",
    "    ]\n",
    "\n",
    "\n",
    "for name, llm in models:\n",
    "    try:\n",
    "        print(f\"Results for {llm.provider}:\")\n",
    "        result = llm.chat_complete(json_messages)\n",
    "        try:\n",
    "            json_data = json.loads(result.choices[0].message.content)\n",
    "            print(json_data)\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Error decoding JSON\")\n",
    "            print(result.choices[0].message.content)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed {name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pydantic (WIP)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from pydantic import BaseModel\n",
    "# from typing import List\n",
    "\n",
    "# class Country(BaseModel):\n",
    "#     name: str\n",
    "#     population: int\n",
    "\n",
    "# class Response(BaseModel):\n",
    "#     countries: List[Country]\n",
    "\n",
    "# json_messages = [\n",
    "#         {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#         {\"role\": \"user\", \"content\": \"Please return the top 3 countries in terms of population. Responda no formato JSON.\"},\n",
    "#     ]\n",
    "\n",
    "\n",
    "# for name, config in models.items():\n",
    "#     try:\n",
    "#         llm = config[\"class\"](model_name=config[\"model\"], structured={\"type\": \"json\", \"model\": Response})\n",
    "#         print(f\"Results for {llm.provider}:\")\n",
    "#         result = llm.chat_complete(json_messages)\n",
    "#         try:\n",
    "#             json_data = json.loads(result.choices[0].message.content)\n",
    "#             print(json_data)\n",
    "#         except json.JSONDecodeError:\n",
    "#             print(\"Error decoding JSON\")\n",
    "        \n",
    "#         print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to get models for {name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synchronous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for openai:\n",
      "id='chatcmpl-CHYUyX6ljFwI77aIRrBwqYyAGyI0h' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-5-mini-2025-08-07' created=1758300224 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYUyX6ljFwI77aIRrBwqYyAGyI0h' choices=[StreamChoice(index=0, delta=DeltaMessage(content='The', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-5-mini-2025-08-07' created=1758300224 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYUyX6ljFwI77aIRrBwqYyAGyI0h' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' capital', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-5-mini-2025-08-07' created=1758300224 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYUyX6ljFwI77aIRrBwqYyAGyI0h' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' of', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-5-mini-2025-08-07' created=1758300224 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYUyX6ljFwI77aIRrBwqYyAGyI0h' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' France', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-5-mini-2025-08-07' created=1758300224 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYUyX6ljFwI77aIRrBwqYyAGyI0h' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' is', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-5-mini-2025-08-07' created=1758300224 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYUyX6ljFwI77aIRrBwqYyAGyI0h' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' Paris', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-5-mini-2025-08-07' created=1758300224 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYUyX6ljFwI77aIRrBwqYyAGyI0h' choices=[StreamChoice(index=0, delta=DeltaMessage(content='.', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-5-mini-2025-08-07' created=1758300224 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYUyX6ljFwI77aIRrBwqYyAGyI0h' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='stop')] model='gpt-5-mini-2025-08-07' created=1758300224 object='chat.completion.chunk'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for azure:\n",
      "id='' choices=[] model='o4-mini' created=0 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYV1HOXL5XxsdmzJF7k9s4DMP8lQ' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1758300227 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYV1HOXL5XxsdmzJF7k9s4DMP8lQ' choices=[StreamChoice(index=0, delta=DeltaMessage(content='The', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1758300227 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYV1HOXL5XxsdmzJF7k9s4DMP8lQ' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' capital', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1758300227 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYV1HOXL5XxsdmzJF7k9s4DMP8lQ' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' of', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1758300227 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYV1HOXL5XxsdmzJF7k9s4DMP8lQ' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' France', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1758300227 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYV1HOXL5XxsdmzJF7k9s4DMP8lQ' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' is', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1758300227 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYV1HOXL5XxsdmzJF7k9s4DMP8lQ' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' Paris', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1758300227 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYV1HOXL5XxsdmzJF7k9s4DMP8lQ' choices=[StreamChoice(index=0, delta=DeltaMessage(content='.', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1758300227 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYV1HOXL5XxsdmzJF7k9s4DMP8lQ' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='stop')] model='o4-mini-2025-04-16' created=1758300227 object='chat.completion.chunk'\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for name, llm in models:\n",
    "    try:\n",
    "        print(f\"Results for {llm.provider}:\")\n",
    "        result = llm.chat_complete(\n",
    "            messages, stream=True\n",
    "        )\n",
    "\n",
    "        for chunk in result:\n",
    "            print(chunk)\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    except Exception as e:\n",
    "            print(f\"Failed to process for {name}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for openai:\n",
      "id='chatcmpl-CHYV36RbgqP8iAAr7qtlgxN0vKatr' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-5-mini-2025-08-07' created=1758300229 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYV36RbgqP8iAAr7qtlgxN0vKatr' choices=[StreamChoice(index=0, delta=DeltaMessage(content='Paris', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-5-mini-2025-08-07' created=1758300229 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYV36RbgqP8iAAr7qtlgxN0vKatr' choices=[StreamChoice(index=0, delta=DeltaMessage(content='.', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-5-mini-2025-08-07' created=1758300229 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYV36RbgqP8iAAr7qtlgxN0vKatr' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='stop')] model='gpt-5-mini-2025-08-07' created=1758300229 object='chat.completion.chunk'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for azure:\n",
      "id='' choices=[] model='o4-mini' created=0 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYV402pA4Mhyk9idPyVaXe9wfN3T' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1758300230 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYV402pA4Mhyk9idPyVaXe9wfN3T' choices=[StreamChoice(index=0, delta=DeltaMessage(content='The', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1758300230 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYV402pA4Mhyk9idPyVaXe9wfN3T' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' capital', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1758300230 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYV402pA4Mhyk9idPyVaXe9wfN3T' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' of', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1758300230 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYV402pA4Mhyk9idPyVaXe9wfN3T' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' France', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1758300230 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYV402pA4Mhyk9idPyVaXe9wfN3T' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' is', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1758300230 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYV402pA4Mhyk9idPyVaXe9wfN3T' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' Paris', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1758300230 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYV402pA4Mhyk9idPyVaXe9wfN3T' choices=[StreamChoice(index=0, delta=DeltaMessage(content='.', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1758300230 object='chat.completion.chunk'\n",
      "id='chatcmpl-CHYV402pA4Mhyk9idPyVaXe9wfN3T' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='stop')] model='o4-mini-2025-04-16' created=1758300230 object='chat.completion.chunk'\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for name, llm in models:\n",
    "    try:\n",
    "        print(f\"Results for {llm.provider}:\")\n",
    "        result = await llm.achat_complete(\n",
    "            messages, stream=True\n",
    "        )\n",
    "\n",
    "        async for chunk in result:\n",
    "            print(chunk)\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process for {name}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synchronous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for anthropic:\n",
      "The capital of France is Paris. It is also the largest city in France and one of the most populous cities in Europe. Paris is known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, Notre-Dame Cathedral, and the Arc de Triomphe.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for name, llm in models:\n",
    "    try:\n",
    "        print(f\"Results for {llm.provider}:\")\n",
    "        model = llm.to_langchain()\n",
    "        response = model.invoke(messages)\n",
    "        print(response.content)\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process for {name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for openai:\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for azure:\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for name, llm in models:\n",
    "    try:\n",
    "        print(f\"Results for {llm.provider}:\")\n",
    "        model = llm.to_langchain()\n",
    "        response = await model.ainvoke(messages)\n",
    "        print(response.content)\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process for {name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for openai:\n",
      "content='' additional_kwargs={} response_metadata={} id='run--d9c5dc84-b4f8-4309-8122-bf2f4feff38d'\n",
      "content='The' additional_kwargs={} response_metadata={} id='run--d9c5dc84-b4f8-4309-8122-bf2f4feff38d'\n",
      "content=' capital' additional_kwargs={} response_metadata={} id='run--d9c5dc84-b4f8-4309-8122-bf2f4feff38d'\n",
      "content=' of' additional_kwargs={} response_metadata={} id='run--d9c5dc84-b4f8-4309-8122-bf2f4feff38d'\n",
      "content=' France' additional_kwargs={} response_metadata={} id='run--d9c5dc84-b4f8-4309-8122-bf2f4feff38d'\n",
      "content=' is' additional_kwargs={} response_metadata={} id='run--d9c5dc84-b4f8-4309-8122-bf2f4feff38d'\n",
      "content=' Paris' additional_kwargs={} response_metadata={} id='run--d9c5dc84-b4f8-4309-8122-bf2f4feff38d'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--d9c5dc84-b4f8-4309-8122-bf2f4feff38d'\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-5-mini-2025-08-07', 'service_tier': 'default'} id='run--d9c5dc84-b4f8-4309-8122-bf2f4feff38d'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for azure:\n",
      "content='' additional_kwargs={} response_metadata={} id='run--e4ec21bb-9830-483a-b2e8-12d688931313'\n",
      "content='' additional_kwargs={} response_metadata={} id='run--e4ec21bb-9830-483a-b2e8-12d688931313'\n",
      "content='The' additional_kwargs={} response_metadata={} id='run--e4ec21bb-9830-483a-b2e8-12d688931313'\n",
      "content=' capital' additional_kwargs={} response_metadata={} id='run--e4ec21bb-9830-483a-b2e8-12d688931313'\n",
      "content=' of' additional_kwargs={} response_metadata={} id='run--e4ec21bb-9830-483a-b2e8-12d688931313'\n",
      "content=' France' additional_kwargs={} response_metadata={} id='run--e4ec21bb-9830-483a-b2e8-12d688931313'\n",
      "content=' is' additional_kwargs={} response_metadata={} id='run--e4ec21bb-9830-483a-b2e8-12d688931313'\n",
      "content=' Paris' additional_kwargs={} response_metadata={} id='run--e4ec21bb-9830-483a-b2e8-12d688931313'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--e4ec21bb-9830-483a-b2e8-12d688931313'\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'o4-mini-2025-04-16'} id='run--e4ec21bb-9830-483a-b2e8-12d688931313'\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, llm in models:\n",
    "    try:\n",
    "        # Create a new streaming instance using the factory\n",
    "        streaming_llm = AIFactory.create_language(llm.provider, llm.model_name, config={\"streaming\": True})\n",
    "        print(f\"Results for {streaming_llm.provider}:\")\n",
    "        model = streaming_llm.to_langchain()\n",
    "        response = model.stream(messages)\n",
    "        for chunk in response:\n",
    "            print(chunk)\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process for {name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for openai:\n",
      "content='' additional_kwargs={} response_metadata={} id='run--c1da6755-0b05-4a9c-95e5-8d2425c352b8'\n",
      "content='The' additional_kwargs={} response_metadata={} id='run--c1da6755-0b05-4a9c-95e5-8d2425c352b8'\n",
      "content=' capital' additional_kwargs={} response_metadata={} id='run--c1da6755-0b05-4a9c-95e5-8d2425c352b8'\n",
      "content=' of' additional_kwargs={} response_metadata={} id='run--c1da6755-0b05-4a9c-95e5-8d2425c352b8'\n",
      "content=' France' additional_kwargs={} response_metadata={} id='run--c1da6755-0b05-4a9c-95e5-8d2425c352b8'\n",
      "content=' is' additional_kwargs={} response_metadata={} id='run--c1da6755-0b05-4a9c-95e5-8d2425c352b8'\n",
      "content=' Paris' additional_kwargs={} response_metadata={} id='run--c1da6755-0b05-4a9c-95e5-8d2425c352b8'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--c1da6755-0b05-4a9c-95e5-8d2425c352b8'\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-5-mini-2025-08-07', 'service_tier': 'default'} id='run--c1da6755-0b05-4a9c-95e5-8d2425c352b8'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for azure:\n",
      "content='' additional_kwargs={} response_metadata={} id='run--80f396a2-d898-4403-834c-2a2b434870ee'\n",
      "content='' additional_kwargs={} response_metadata={} id='run--80f396a2-d898-4403-834c-2a2b434870ee'\n",
      "content='The' additional_kwargs={} response_metadata={} id='run--80f396a2-d898-4403-834c-2a2b434870ee'\n",
      "content=' capital' additional_kwargs={} response_metadata={} id='run--80f396a2-d898-4403-834c-2a2b434870ee'\n",
      "content=' of' additional_kwargs={} response_metadata={} id='run--80f396a2-d898-4403-834c-2a2b434870ee'\n",
      "content=' France' additional_kwargs={} response_metadata={} id='run--80f396a2-d898-4403-834c-2a2b434870ee'\n",
      "content=' is' additional_kwargs={} response_metadata={} id='run--80f396a2-d898-4403-834c-2a2b434870ee'\n",
      "content=' Paris' additional_kwargs={} response_metadata={} id='run--80f396a2-d898-4403-834c-2a2b434870ee'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--80f396a2-d898-4403-834c-2a2b434870ee'\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'o4-mini-2025-04-16'} id='run--80f396a2-d898-4403-834c-2a2b434870ee'\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, llm in models:\n",
    "    try:\n",
    "        # Create a new streaming instance using the factory\n",
    "        streaming_llm = AIFactory.create_language(llm.provider, llm.model_name, config={\"streaming\": True})\n",
    "        print(f\"Results for {streaming_llm.provider}:\")\n",
    "        model = streaming_llm.to_langchain()\n",
    "        response = model.astream(messages)\n",
    "        async for chunk in response:\n",
    "            print(chunk)\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process for {name}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
