{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esperanto import AIFactory\n",
    "\n",
    "messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What's the capital of France?\"},\n",
    "    ]\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"max_tokens\": 850,\n",
    "    \"temperature\": 1.0,\n",
    "    \"streaming\": False,\n",
    "    \"top_p\": 0.9,\n",
    "    \"structured\": None\n",
    "}\n",
    "\n",
    "models = [\n",
    "    (\"openai-compatible\", AIFactory.create_language(\"openai-compatible\", \"qwen3:4b\")),\n",
    "    (\"openrouter\", AIFactory.create_language(\"openrouter\", \"openai/gpt-4o\")),\n",
    "    (\"openai\", AIFactory.create_language(\"openai\", \"gpt-5-mini\")),\n",
    "    (\"xai\", AIFactory.create_language(\"xai\", \"grok-3\")),\n",
    "    (\"anthropic\", AIFactory.create_language(\"anthropic\", \"claude-4-sonnet-latest\")),\n",
    "    (\"groq\", AIFactory.create_language(\"groq\", \"llama-3.1-8b-instant\")),\n",
    "    (\"ollama\", AIFactory.create_language(\"ollama\", \"gpt-oss:20b\")),\n",
    "    (\"google\", AIFactory.create_language(\"google\", \"gemini-2.0-flash\")),\n",
    "    (\"google\", AIFactory.create_language(\"google\", \"gemini-2.5-flash\")),\n",
    "    (\"azure\", AIFactory.create_language(\"azure\", \"o4-mini\")),\n",
    "    (\"mistral\", AIFactory.create_language(\"mistral\", \"mistral-large-latest\")),\n",
    "    (\"deepseek\", AIFactory.create_language(\"deepseek\", \"deepseek-chat\")),\n",
    "    # (\"vertex\", AIFactory.create_language(\"vertex\", \"gemini-2.0-flash\")),\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Models (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OPENAI-COMPATIBLE Models ===\n",
      "[Model(id='openai/gpt-oss-120b', owned_by='organization_owner', context_window=None, type=None), Model(id='qwen/qwen2.5-coder-14b', owned_by='organization_owner', context_window=None, type=None), Model(id='qwen/qwen3-next-80b', owned_by='organization_owner', context_window=None, type=None), Model(id='zai-org/glm-4.7-flash', owned_by='organization_owner', context_window=None, type=None), Model(id='text-embedding-nomic-embed-text-v1.5', owned_by='organization_owner', context_window=None, type=None)]\n",
      "\n",
      "=== OPENROUTER Models ===\n",
      "[Model(id='arcee-ai/trinity-large-preview:free', owned_by='arcee-ai', context_window=None, type=None), Model(id='moonshotai/kimi-k2.5', owned_by='moonshotai', context_window=None, type=None), Model(id='upstage/solar-pro-3:free', owned_by='upstage', context_window=None, type=None), Model(id='minimax/minimax-m2-her', owned_by='minimax', context_window=None, type=None), Model(id='writer/palmyra-x5', owned_by='writer', context_window=None, type=None), Model(id='liquid/lfm-2.5-1.2b-thinking:free', owned_by='liquid', context_window=None, type=None), Model(id='liquid/lfm-2.5-1.2b-instruct:free', owned_by='liquid', context_window=None, type=None), Model(id='openai/gpt-audio', owned_by='openai', context_window=None, type=None), Model(id='openai/gpt-audio-mini', owned_by='openai', context_window=None, type=None), Model(id='z-ai/glm-4.7-flash', owned_by='z-ai', context_window=None, type=None), Model(id='openai/gpt-5.2-codex', owned_by='openai', context_window=None, type=None), Model(id='allenai/molmo-2-8b:free', owned_by='allenai', context_window=None, type=None), Model(id='allenai/olmo-3.1-32b-instruct', owned_by='allenai', context_window=None, type=None), Model(id='bytedance-seed/seed-1.6-flash', owned_by='bytedance-seed', context_window=None, type=None), Model(id='bytedance-seed/seed-1.6', owned_by='bytedance-seed', context_window=None, type=None), Model(id='minimax/minimax-m2.1', owned_by='minimax', context_window=None, type=None), Model(id='z-ai/glm-4.7', owned_by='z-ai', context_window=None, type=None), Model(id='google/gemini-3-flash-preview', owned_by='google', context_window=None, type=None), Model(id='mistralai/mistral-small-creative', owned_by='mistralai', context_window=None, type=None), Model(id='allenai/olmo-3.1-32b-think', owned_by='allenai', context_window=None, type=None), Model(id='xiaomi/mimo-v2-flash', owned_by='xiaomi', context_window=None, type=None), Model(id='nvidia/nemotron-3-nano-30b-a3b:free', owned_by='nvidia', context_window=None, type=None), Model(id='nvidia/nemotron-3-nano-30b-a3b', owned_by='nvidia', context_window=None, type=None), Model(id='openai/gpt-5.2-chat', owned_by='openai', context_window=None, type=None), Model(id='openai/gpt-5.2-pro', owned_by='openai', context_window=None, type=None), Model(id='openai/gpt-5.2', owned_by='openai', context_window=None, type=None), Model(id='mistralai/devstral-2512', owned_by='mistralai', context_window=None, type=None), Model(id='relace/relace-search', owned_by='relace', context_window=None, type=None), Model(id='z-ai/glm-4.6v', owned_by='z-ai', context_window=None, type=None), Model(id='nex-agi/deepseek-v3.1-nex-n1', owned_by='nex-agi', context_window=None, type=None), Model(id='essentialai/rnj-1-instruct', owned_by='essentialai', context_window=None, type=None), Model(id='openrouter/bodybuilder', owned_by='openrouter', context_window=None, type=None), Model(id='openai/gpt-5.1-codex-max', owned_by='openai', context_window=None, type=None), Model(id='amazon/nova-2-lite-v1', owned_by='amazon', context_window=None, type=None), Model(id='mistralai/ministral-14b-2512', owned_by='mistralai', context_window=None, type=None), Model(id='mistralai/ministral-8b-2512', owned_by='mistralai', context_window=None, type=None), Model(id='mistralai/ministral-3b-2512', owned_by='mistralai', context_window=None, type=None), Model(id='mistralai/mistral-large-2512', owned_by='mistralai', context_window=None, type=None), Model(id='arcee-ai/trinity-mini:free', owned_by='arcee-ai', context_window=None, type=None), Model(id='arcee-ai/trinity-mini', owned_by='arcee-ai', context_window=None, type=None), Model(id='deepseek/deepseek-v3.2-speciale', owned_by='deepseek', context_window=None, type=None), Model(id='deepseek/deepseek-v3.2', owned_by='deepseek', context_window=None, type=None), Model(id='prime-intellect/intellect-3', owned_by='prime-intellect', context_window=None, type=None), Model(id='tngtech/tng-r1t-chimera:free', owned_by='tngtech', context_window=None, type=None), Model(id='tngtech/tng-r1t-chimera', owned_by='tngtech', context_window=None, type=None), Model(id='anthropic/claude-opus-4.5', owned_by='anthropic', context_window=None, type=None), Model(id='allenai/olmo-3-32b-think', owned_by='allenai', context_window=None, type=None), Model(id='allenai/olmo-3-7b-instruct', owned_by='allenai', context_window=None, type=None), Model(id='allenai/olmo-3-7b-think', owned_by='allenai', context_window=None, type=None), Model(id='google/gemini-3-pro-image-preview', owned_by='google', context_window=None, type=None), Model(id='x-ai/grok-4.1-fast', owned_by='x-ai', context_window=None, type=None), Model(id='google/gemini-3-pro-preview', owned_by='google', context_window=None, type=None), Model(id='deepcogito/cogito-v2.1-671b', owned_by='deepcogito', context_window=None, type=None), Model(id='openai/gpt-5.1', owned_by='openai', context_window=None, type=None), Model(id='openai/gpt-5.1-chat', owned_by='openai', context_window=None, type=None), Model(id='openai/gpt-5.1-codex', owned_by='openai', context_window=None, type=None), Model(id='openai/gpt-5.1-codex-mini', owned_by='openai', context_window=None, type=None), Model(id='kwaipilot/kat-coder-pro', owned_by='kwaipilot', context_window=None, type=None), Model(id='moonshotai/kimi-k2-thinking', owned_by='moonshotai', context_window=None, type=None), Model(id='amazon/nova-premier-v1', owned_by='amazon', context_window=None, type=None), Model(id='perplexity/sonar-pro-search', owned_by='perplexity', context_window=None, type=None), Model(id='mistralai/voxtral-small-24b-2507', owned_by='mistralai', context_window=None, type=None), Model(id='openai/gpt-oss-safeguard-20b', owned_by='openai', context_window=None, type=None), Model(id='nvidia/nemotron-nano-12b-v2-vl:free', owned_by='nvidia', context_window=None, type=None), Model(id='nvidia/nemotron-nano-12b-v2-vl', owned_by='nvidia', context_window=None, type=None), Model(id='minimax/minimax-m2', owned_by='minimax', context_window=None, type=None), Model(id='qwen/qwen3-vl-32b-instruct', owned_by='qwen', context_window=None, type=None), Model(id='liquid/lfm2-8b-a1b', owned_by='liquid', context_window=None, type=None), Model(id='liquid/lfm-2.2-6b', owned_by='liquid', context_window=None, type=None), Model(id='ibm-granite/granite-4.0-h-micro', owned_by='ibm-granite', context_window=None, type=None), Model(id='deepcogito/cogito-v2-preview-llama-405b', owned_by='deepcogito', context_window=None, type=None), Model(id='openai/gpt-5-image-mini', owned_by='openai', context_window=None, type=None), Model(id='anthropic/claude-haiku-4.5', owned_by='anthropic', context_window=None, type=None), Model(id='qwen/qwen3-vl-8b-thinking', owned_by='qwen', context_window=None, type=None), Model(id='qwen/qwen3-vl-8b-instruct', owned_by='qwen', context_window=None, type=None), Model(id='openai/gpt-5-image', owned_by='openai', context_window=None, type=None), Model(id='openai/o3-deep-research', owned_by='openai', context_window=None, type=None), Model(id='openai/o4-mini-deep-research', owned_by='openai', context_window=None, type=None), Model(id='nvidia/llama-3.3-nemotron-super-49b-v1.5', owned_by='nvidia', context_window=None, type=None), Model(id='baidu/ernie-4.5-21b-a3b-thinking', owned_by='baidu', context_window=None, type=None), Model(id='google/gemini-2.5-flash-image', owned_by='google', context_window=None, type=None), Model(id='qwen/qwen3-vl-30b-a3b-thinking', owned_by='qwen', context_window=None, type=None), Model(id='qwen/qwen3-vl-30b-a3b-instruct', owned_by='qwen', context_window=None, type=None), Model(id='openai/gpt-5-pro', owned_by='openai', context_window=None, type=None), Model(id='z-ai/glm-4.6', owned_by='z-ai', context_window=None, type=None), Model(id='z-ai/glm-4.6:exacto', owned_by='z-ai', context_window=None, type=None), Model(id='anthropic/claude-sonnet-4.5', owned_by='anthropic', context_window=None, type=None), Model(id='deepseek/deepseek-v3.2-exp', owned_by='deepseek', context_window=None, type=None), Model(id='thedrummer/cydonia-24b-v4.1', owned_by='thedrummer', context_window=None, type=None), Model(id='relace/relace-apply-3', owned_by='relace', context_window=None, type=None), Model(id='google/gemini-2.5-flash-preview-09-2025', owned_by='google', context_window=None, type=None), Model(id='google/gemini-2.5-flash-lite-preview-09-2025', owned_by='google', context_window=None, type=None), Model(id='qwen/qwen3-vl-235b-a22b-thinking', owned_by='qwen', context_window=None, type=None), Model(id='qwen/qwen3-vl-235b-a22b-instruct', owned_by='qwen', context_window=None, type=None), Model(id='qwen/qwen3-max', owned_by='qwen', context_window=None, type=None), Model(id='qwen/qwen3-coder-plus', owned_by='qwen', context_window=None, type=None), Model(id='openai/gpt-5-codex', owned_by='openai', context_window=None, type=None), Model(id='deepseek/deepseek-v3.1-terminus:exacto', owned_by='deepseek', context_window=None, type=None), Model(id='deepseek/deepseek-v3.1-terminus', owned_by='deepseek', context_window=None, type=None), Model(id='x-ai/grok-4-fast', owned_by='x-ai', context_window=None, type=None), Model(id='alibaba/tongyi-deepresearch-30b-a3b', owned_by='alibaba', context_window=None, type=None), Model(id='qwen/qwen3-coder-flash', owned_by='qwen', context_window=None, type=None), Model(id='opengvlab/internvl3-78b', owned_by='opengvlab', context_window=None, type=None), Model(id='qwen/qwen3-next-80b-a3b-thinking', owned_by='qwen', context_window=None, type=None), Model(id='qwen/qwen3-next-80b-a3b-instruct:free', owned_by='qwen', context_window=None, type=None), Model(id='qwen/qwen3-next-80b-a3b-instruct', owned_by='qwen', context_window=None, type=None), Model(id='meituan/longcat-flash-chat', owned_by='meituan', context_window=None, type=None), Model(id='qwen/qwen-plus-2025-07-28', owned_by='qwen', context_window=None, type=None), Model(id='qwen/qwen-plus-2025-07-28:thinking', owned_by='qwen', context_window=None, type=None), Model(id='nvidia/nemotron-nano-9b-v2:free', owned_by='nvidia', context_window=None, type=None), Model(id='nvidia/nemotron-nano-9b-v2', owned_by='nvidia', context_window=None, type=None), Model(id='moonshotai/kimi-k2-0905', owned_by='moonshotai', context_window=None, type=None), Model(id='moonshotai/kimi-k2-0905:exacto', owned_by='moonshotai', context_window=None, type=None), Model(id='deepcogito/cogito-v2-preview-llama-70b', owned_by='deepcogito', context_window=None, type=None), Model(id='deepcogito/cogito-v2-preview-llama-109b-moe', owned_by='deepcogito', context_window=None, type=None), Model(id='stepfun-ai/step3', owned_by='stepfun-ai', context_window=None, type=None), Model(id='qwen/qwen3-30b-a3b-thinking-2507', owned_by='qwen', context_window=None, type=None), Model(id='x-ai/grok-code-fast-1', owned_by='x-ai', context_window=None, type=None), Model(id='nousresearch/hermes-4-70b', owned_by='nousresearch', context_window=None, type=None), Model(id='nousresearch/hermes-4-405b', owned_by='nousresearch', context_window=None, type=None), Model(id='deepseek/deepseek-chat-v3.1', owned_by='deepseek', context_window=None, type=None), Model(id='openai/gpt-4o-audio-preview', owned_by='openai', context_window=None, type=None), Model(id='mistralai/mistral-medium-3.1', owned_by='mistralai', context_window=None, type=None), Model(id='baidu/ernie-4.5-21b-a3b', owned_by='baidu', context_window=None, type=None), Model(id='baidu/ernie-4.5-vl-28b-a3b', owned_by='baidu', context_window=None, type=None), Model(id='z-ai/glm-4.5v', owned_by='z-ai', context_window=None, type=None), Model(id='ai21/jamba-mini-1.7', owned_by='ai21', context_window=None, type=None), Model(id='ai21/jamba-large-1.7', owned_by='ai21', context_window=None, type=None), Model(id='openai/gpt-5-chat', owned_by='openai', context_window=None, type=None), Model(id='openai/gpt-5', owned_by='openai', context_window=None, type=None), Model(id='openai/gpt-5-mini', owned_by='openai', context_window=None, type=None), Model(id='openai/gpt-5-nano', owned_by='openai', context_window=None, type=None), Model(id='openai/gpt-oss-120b:free', owned_by='openai', context_window=None, type=None), Model(id='openai/gpt-oss-120b', owned_by='openai', context_window=None, type=None), Model(id='openai/gpt-oss-120b:exacto', owned_by='openai', context_window=None, type=None), Model(id='openai/gpt-oss-20b:free', owned_by='openai', context_window=None, type=None), Model(id='openai/gpt-oss-20b', owned_by='openai', context_window=None, type=None), Model(id='anthropic/claude-opus-4.1', owned_by='anthropic', context_window=None, type=None), Model(id='mistralai/codestral-2508', owned_by='mistralai', context_window=None, type=None), Model(id='qwen/qwen3-coder-30b-a3b-instruct', owned_by='qwen', context_window=None, type=None), Model(id='qwen/qwen3-30b-a3b-instruct-2507', owned_by='qwen', context_window=None, type=None), Model(id='z-ai/glm-4.5', owned_by='z-ai', context_window=None, type=None), Model(id='z-ai/glm-4.5-air:free', owned_by='z-ai', context_window=None, type=None), Model(id='z-ai/glm-4.5-air', owned_by='z-ai', context_window=None, type=None), Model(id='qwen/qwen3-235b-a22b-thinking-2507', owned_by='qwen', context_window=None, type=None), Model(id='z-ai/glm-4-32b', owned_by='z-ai', context_window=None, type=None), Model(id='qwen/qwen3-coder:free', owned_by='qwen', context_window=None, type=None), Model(id='qwen/qwen3-coder', owned_by='qwen', context_window=None, type=None), Model(id='qwen/qwen3-coder:exacto', owned_by='qwen', context_window=None, type=None), Model(id='bytedance/ui-tars-1.5-7b', owned_by='bytedance', context_window=None, type=None), Model(id='google/gemini-2.5-flash-lite', owned_by='google', context_window=None, type=None), Model(id='qwen/qwen3-235b-a22b-2507', owned_by='qwen', context_window=None, type=None), Model(id='switchpoint/router', owned_by='switchpoint', context_window=None, type=None), Model(id='moonshotai/kimi-k2:free', owned_by='moonshotai', context_window=None, type=None), Model(id='moonshotai/kimi-k2', owned_by='moonshotai', context_window=None, type=None), Model(id='mistralai/devstral-medium', owned_by='mistralai', context_window=None, type=None), Model(id='mistralai/devstral-small', owned_by='mistralai', context_window=None, type=None), Model(id='cognitivecomputations/dolphin-mistral-24b-venice-edition:free', owned_by='cognitivecomputations', context_window=None, type=None), Model(id='x-ai/grok-4', owned_by='x-ai', context_window=None, type=None), Model(id='google/gemma-3n-e2b-it:free', owned_by='google', context_window=None, type=None), Model(id='tencent/hunyuan-a13b-instruct', owned_by='tencent', context_window=None, type=None), Model(id='tngtech/deepseek-r1t2-chimera:free', owned_by='tngtech', context_window=None, type=None), Model(id='tngtech/deepseek-r1t2-chimera', owned_by='tngtech', context_window=None, type=None), Model(id='morph/morph-v3-large', owned_by='morph', context_window=None, type=None), Model(id='morph/morph-v3-fast', owned_by='morph', context_window=None, type=None), Model(id='baidu/ernie-4.5-vl-424b-a47b', owned_by='baidu', context_window=None, type=None), Model(id='baidu/ernie-4.5-300b-a47b', owned_by='baidu', context_window=None, type=None), Model(id='inception/mercury', owned_by='inception', context_window=None, type=None), Model(id='mistralai/mistral-small-3.2-24b-instruct', owned_by='mistralai', context_window=None, type=None), Model(id='minimax/minimax-m1', owned_by='minimax', context_window=None, type=None), Model(id='google/gemini-2.5-flash', owned_by='google', context_window=None, type=None), Model(id='google/gemini-2.5-pro', owned_by='google', context_window=None, type=None), Model(id='moonshotai/kimi-dev-72b', owned_by='moonshotai', context_window=None, type=None), Model(id='openai/o3-pro', owned_by='openai', context_window=None, type=None), Model(id='x-ai/grok-3-mini', owned_by='x-ai', context_window=None, type=None), Model(id='x-ai/grok-3', owned_by='x-ai', context_window=None, type=None), Model(id='google/gemini-2.5-pro-preview', owned_by='google', context_window=None, type=None), Model(id='deepseek/deepseek-r1-0528:free', owned_by='deepseek', context_window=None, type=None), Model(id='deepseek/deepseek-r1-0528', owned_by='deepseek', context_window=None, type=None), Model(id='anthropic/claude-opus-4', owned_by='anthropic', context_window=None, type=None), Model(id='anthropic/claude-sonnet-4', owned_by='anthropic', context_window=None, type=None), Model(id='google/gemma-3n-e4b-it:free', owned_by='google', context_window=None, type=None), Model(id='google/gemma-3n-e4b-it', owned_by='google', context_window=None, type=None), Model(id='nousresearch/deephermes-3-mistral-24b-preview', owned_by='nousresearch', context_window=None, type=None), Model(id='mistralai/mistral-medium-3', owned_by='mistralai', context_window=None, type=None), Model(id='google/gemini-2.5-pro-preview-05-06', owned_by='google', context_window=None, type=None), Model(id='arcee-ai/spotlight', owned_by='arcee-ai', context_window=None, type=None), Model(id='arcee-ai/maestro-reasoning', owned_by='arcee-ai', context_window=None, type=None), Model(id='arcee-ai/virtuoso-large', owned_by='arcee-ai', context_window=None, type=None), Model(id='arcee-ai/coder-large', owned_by='arcee-ai', context_window=None, type=None), Model(id='inception/mercury-coder', owned_by='inception', context_window=None, type=None), Model(id='qwen/qwen3-4b:free', owned_by='qwen', context_window=None, type=None), Model(id='meta-llama/llama-guard-4-12b', owned_by='meta-llama', context_window=None, type=None), Model(id='qwen/qwen3-30b-a3b', owned_by='qwen', context_window=None, type=None), Model(id='qwen/qwen3-8b', owned_by='qwen', context_window=None, type=None), Model(id='qwen/qwen3-14b', owned_by='qwen', context_window=None, type=None), Model(id='qwen/qwen3-32b', owned_by='qwen', context_window=None, type=None), Model(id='qwen/qwen3-235b-a22b', owned_by='qwen', context_window=None, type=None), Model(id='tngtech/deepseek-r1t-chimera:free', owned_by='tngtech', context_window=None, type=None), Model(id='tngtech/deepseek-r1t-chimera', owned_by='tngtech', context_window=None, type=None), Model(id='openai/o4-mini-high', owned_by='openai', context_window=None, type=None), Model(id='openai/o3', owned_by='openai', context_window=None, type=None), Model(id='openai/o4-mini', owned_by='openai', context_window=None, type=None), Model(id='qwen/qwen2.5-coder-7b-instruct', owned_by='qwen', context_window=None, type=None), Model(id='openai/gpt-4.1', owned_by='openai', context_window=None, type=None), Model(id='openai/gpt-4.1-mini', owned_by='openai', context_window=None, type=None), Model(id='openai/gpt-4.1-nano', owned_by='openai', context_window=None, type=None), Model(id='eleutherai/llemma_7b', owned_by='eleutherai', context_window=None, type=None), Model(id='alfredpros/codellama-7b-instruct-solidity', owned_by='alfredpros', context_window=None, type=None), Model(id='x-ai/grok-3-mini-beta', owned_by='x-ai', context_window=None, type=None), Model(id='x-ai/grok-3-beta', owned_by='x-ai', context_window=None, type=None), Model(id='nvidia/llama-3.1-nemotron-ultra-253b-v1', owned_by='nvidia', context_window=None, type=None), Model(id='meta-llama/llama-4-maverick', owned_by='meta-llama', context_window=None, type=None), Model(id='meta-llama/llama-4-scout', owned_by='meta-llama', context_window=None, type=None), Model(id='qwen/qwen2.5-vl-32b-instruct', owned_by='qwen', context_window=None, type=None), Model(id='deepseek/deepseek-chat-v3-0324', owned_by='deepseek', context_window=None, type=None), Model(id='openai/o1-pro', owned_by='openai', context_window=None, type=None), Model(id='mistralai/mistral-small-3.1-24b-instruct:free', owned_by='mistralai', context_window=None, type=None), Model(id='mistralai/mistral-small-3.1-24b-instruct', owned_by='mistralai', context_window=None, type=None), Model(id='allenai/olmo-2-0325-32b-instruct', owned_by='allenai', context_window=None, type=None), Model(id='google/gemma-3-4b-it:free', owned_by='google', context_window=None, type=None), Model(id='google/gemma-3-4b-it', owned_by='google', context_window=None, type=None), Model(id='google/gemma-3-12b-it:free', owned_by='google', context_window=None, type=None), Model(id='google/gemma-3-12b-it', owned_by='google', context_window=None, type=None), Model(id='cohere/command-a', owned_by='cohere', context_window=None, type=None), Model(id='openai/gpt-4o-mini-search-preview', owned_by='openai', context_window=None, type=None), Model(id='openai/gpt-4o-search-preview', owned_by='openai', context_window=None, type=None), Model(id='google/gemma-3-27b-it:free', owned_by='google', context_window=None, type=None), Model(id='google/gemma-3-27b-it', owned_by='google', context_window=None, type=None), Model(id='thedrummer/skyfall-36b-v2', owned_by='thedrummer', context_window=None, type=None), Model(id='perplexity/sonar-reasoning-pro', owned_by='perplexity', context_window=None, type=None), Model(id='perplexity/sonar-pro', owned_by='perplexity', context_window=None, type=None), Model(id='perplexity/sonar-deep-research', owned_by='perplexity', context_window=None, type=None), Model(id='qwen/qwq-32b', owned_by='qwen', context_window=None, type=None), Model(id='google/gemini-2.0-flash-lite-001', owned_by='google', context_window=None, type=None), Model(id='anthropic/claude-3.7-sonnet:thinking', owned_by='anthropic', context_window=None, type=None), Model(id='anthropic/claude-3.7-sonnet', owned_by='anthropic', context_window=None, type=None), Model(id='mistralai/mistral-saba', owned_by='mistralai', context_window=None, type=None), Model(id='meta-llama/llama-guard-3-8b', owned_by='meta-llama', context_window=None, type=None), Model(id='openai/o3-mini-high', owned_by='openai', context_window=None, type=None), Model(id='google/gemini-2.0-flash-001', owned_by='google', context_window=None, type=None), Model(id='qwen/qwen-vl-plus', owned_by='qwen', context_window=None, type=None), Model(id='aion-labs/aion-1.0', owned_by='aion-labs', context_window=None, type=None), Model(id='aion-labs/aion-1.0-mini', owned_by='aion-labs', context_window=None, type=None), Model(id='aion-labs/aion-rp-llama-3.1-8b', owned_by='aion-labs', context_window=None, type=None), Model(id='qwen/qwen-vl-max', owned_by='qwen', context_window=None, type=None), Model(id='qwen/qwen-turbo', owned_by='qwen', context_window=None, type=None), Model(id='qwen/qwen2.5-vl-72b-instruct', owned_by='qwen', context_window=None, type=None), Model(id='qwen/qwen-plus', owned_by='qwen', context_window=None, type=None), Model(id='qwen/qwen-max', owned_by='qwen', context_window=None, type=None), Model(id='openai/o3-mini', owned_by='openai', context_window=None, type=None), Model(id='mistralai/mistral-small-24b-instruct-2501', owned_by='mistralai', context_window=None, type=None), Model(id='deepseek/deepseek-r1-distill-qwen-32b', owned_by='deepseek', context_window=None, type=None), Model(id='perplexity/sonar', owned_by='perplexity', context_window=None, type=None), Model(id='deepseek/deepseek-r1-distill-llama-70b', owned_by='deepseek', context_window=None, type=None), Model(id='deepseek/deepseek-r1', owned_by='deepseek', context_window=None, type=None), Model(id='minimax/minimax-01', owned_by='minimax', context_window=None, type=None), Model(id='microsoft/phi-4', owned_by='microsoft', context_window=None, type=None), Model(id='sao10k/l3.1-70b-hanami-x1', owned_by='sao10k', context_window=None, type=None), Model(id='deepseek/deepseek-chat', owned_by='deepseek', context_window=None, type=None), Model(id='sao10k/l3.3-euryale-70b', owned_by='sao10k', context_window=None, type=None), Model(id='openai/o1', owned_by='openai', context_window=None, type=None), Model(id='cohere/command-r7b-12-2024', owned_by='cohere', context_window=None, type=None), Model(id='meta-llama/llama-3.3-70b-instruct:free', owned_by='meta-llama', context_window=None, type=None), Model(id='meta-llama/llama-3.3-70b-instruct', owned_by='meta-llama', context_window=None, type=None), Model(id='amazon/nova-lite-v1', owned_by='amazon', context_window=None, type=None), Model(id='amazon/nova-micro-v1', owned_by='amazon', context_window=None, type=None), Model(id='amazon/nova-pro-v1', owned_by='amazon', context_window=None, type=None), Model(id='openai/gpt-4o-2024-11-20', owned_by='openai', context_window=None, type=None), Model(id='mistralai/mistral-large-2411', owned_by='mistralai', context_window=None, type=None), Model(id='mistralai/mistral-large-2407', owned_by='mistralai', context_window=None, type=None), Model(id='mistralai/pixtral-large-2411', owned_by='mistralai', context_window=None, type=None), Model(id='qwen/qwen-2.5-coder-32b-instruct', owned_by='qwen', context_window=None, type=None), Model(id='raifle/sorcererlm-8x22b', owned_by='raifle', context_window=None, type=None), Model(id='thedrummer/unslopnemo-12b', owned_by='thedrummer', context_window=None, type=None), Model(id='anthropic/claude-3.5-haiku', owned_by='anthropic', context_window=None, type=None), Model(id='anthracite-org/magnum-v4-72b', owned_by='anthracite-org', context_window=None, type=None), Model(id='anthropic/claude-3.5-sonnet', owned_by='anthropic', context_window=None, type=None), Model(id='mistralai/ministral-8b', owned_by='mistralai', context_window=None, type=None), Model(id='mistralai/ministral-3b', owned_by='mistralai', context_window=None, type=None), Model(id='qwen/qwen-2.5-7b-instruct', owned_by='qwen', context_window=None, type=None), Model(id='nvidia/llama-3.1-nemotron-70b-instruct', owned_by='nvidia', context_window=None, type=None), Model(id='inflection/inflection-3-pi', owned_by='inflection', context_window=None, type=None), Model(id='inflection/inflection-3-productivity', owned_by='inflection', context_window=None, type=None), Model(id='thedrummer/rocinante-12b', owned_by='thedrummer', context_window=None, type=None), Model(id='meta-llama/llama-3.2-3b-instruct:free', owned_by='meta-llama', context_window=None, type=None), Model(id='meta-llama/llama-3.2-3b-instruct', owned_by='meta-llama', context_window=None, type=None), Model(id='meta-llama/llama-3.2-1b-instruct', owned_by='meta-llama', context_window=None, type=None), Model(id='meta-llama/llama-3.2-11b-vision-instruct', owned_by='meta-llama', context_window=None, type=None), Model(id='qwen/qwen-2.5-72b-instruct', owned_by='qwen', context_window=None, type=None), Model(id='neversleep/llama-3.1-lumimaid-8b', owned_by='neversleep', context_window=None, type=None), Model(id='mistralai/pixtral-12b', owned_by='mistralai', context_window=None, type=None), Model(id='cohere/command-r-08-2024', owned_by='cohere', context_window=None, type=None), Model(id='cohere/command-r-plus-08-2024', owned_by='cohere', context_window=None, type=None), Model(id='sao10k/l3.1-euryale-70b', owned_by='sao10k', context_window=None, type=None), Model(id='qwen/qwen-2.5-vl-7b-instruct:free', owned_by='qwen', context_window=None, type=None), Model(id='qwen/qwen-2.5-vl-7b-instruct', owned_by='qwen', context_window=None, type=None), Model(id='nousresearch/hermes-3-llama-3.1-70b', owned_by='nousresearch', context_window=None, type=None), Model(id='nousresearch/hermes-3-llama-3.1-405b:free', owned_by='nousresearch', context_window=None, type=None), Model(id='nousresearch/hermes-3-llama-3.1-405b', owned_by='nousresearch', context_window=None, type=None), Model(id='openai/chatgpt-4o-latest', owned_by='openai', context_window=None, type=None), Model(id='sao10k/l3-lunaris-8b', owned_by='sao10k', context_window=None, type=None), Model(id='openai/gpt-4o-2024-08-06', owned_by='openai', context_window=None, type=None), Model(id='meta-llama/llama-3.1-405b', owned_by='meta-llama', context_window=None, type=None), Model(id='meta-llama/llama-3.1-8b-instruct', owned_by='meta-llama', context_window=None, type=None), Model(id='meta-llama/llama-3.1-405b-instruct:free', owned_by='meta-llama', context_window=None, type=None), Model(id='meta-llama/llama-3.1-405b-instruct', owned_by='meta-llama', context_window=None, type=None), Model(id='meta-llama/llama-3.1-70b-instruct', owned_by='meta-llama', context_window=None, type=None), Model(id='mistralai/mistral-nemo', owned_by='mistralai', context_window=None, type=None), Model(id='openai/gpt-4o-mini-2024-07-18', owned_by='openai', context_window=None, type=None), Model(id='openai/gpt-4o-mini', owned_by='openai', context_window=None, type=None), Model(id='google/gemma-2-27b-it', owned_by='google', context_window=None, type=None), Model(id='google/gemma-2-9b-it', owned_by='google', context_window=None, type=None), Model(id='sao10k/l3-euryale-70b', owned_by='sao10k', context_window=None, type=None), Model(id='nousresearch/hermes-2-pro-llama-3-8b', owned_by='nousresearch', context_window=None, type=None), Model(id='mistralai/mistral-7b-instruct', owned_by='mistralai', context_window=None, type=None), Model(id='mistralai/mistral-7b-instruct-v0.3', owned_by='mistralai', context_window=None, type=None), Model(id='meta-llama/llama-guard-2-8b', owned_by='meta-llama', context_window=None, type=None), Model(id='openai/gpt-4o-2024-05-13', owned_by='openai', context_window=None, type=None), Model(id='openai/gpt-4o', owned_by='openai', context_window=None, type=None), Model(id='openai/gpt-4o:extended', owned_by='openai', context_window=None, type=None), Model(id='meta-llama/llama-3-70b-instruct', owned_by='meta-llama', context_window=None, type=None), Model(id='meta-llama/llama-3-8b-instruct', owned_by='meta-llama', context_window=None, type=None), Model(id='mistralai/mixtral-8x22b-instruct', owned_by='mistralai', context_window=None, type=None), Model(id='microsoft/wizardlm-2-8x22b', owned_by='microsoft', context_window=None, type=None), Model(id='openai/gpt-4-turbo', owned_by='openai', context_window=None, type=None), Model(id='anthropic/claude-3-haiku', owned_by='anthropic', context_window=None, type=None), Model(id='mistralai/mistral-large', owned_by='mistralai', context_window=None, type=None), Model(id='openai/gpt-3.5-turbo-0613', owned_by='openai', context_window=None, type=None), Model(id='openai/gpt-4-turbo-preview', owned_by='openai', context_window=None, type=None), Model(id='mistralai/mistral-tiny', owned_by='mistralai', context_window=None, type=None), Model(id='mistralai/mistral-7b-instruct-v0.2', owned_by='mistralai', context_window=None, type=None), Model(id='mistralai/mixtral-8x7b-instruct', owned_by='mistralai', context_window=None, type=None), Model(id='neversleep/noromaid-20b', owned_by='neversleep', context_window=None, type=None), Model(id='alpindale/goliath-120b', owned_by='alpindale', context_window=None, type=None), Model(id='openrouter/auto', owned_by='openrouter', context_window=None, type=None), Model(id='openai/gpt-4-1106-preview', owned_by='openai', context_window=None, type=None), Model(id='openai/gpt-3.5-turbo-instruct', owned_by='openai', context_window=None, type=None), Model(id='mistralai/mistral-7b-instruct-v0.1', owned_by='mistralai', context_window=None, type=None), Model(id='openai/gpt-3.5-turbo-16k', owned_by='openai', context_window=None, type=None), Model(id='mancer/weaver', owned_by='mancer', context_window=None, type=None), Model(id='undi95/remm-slerp-l2-13b', owned_by='undi95', context_window=None, type=None), Model(id='gryphe/mythomax-l2-13b', owned_by='gryphe', context_window=None, type=None), Model(id='openai/gpt-4-0314', owned_by='openai', context_window=None, type=None), Model(id='openai/gpt-4', owned_by='openai', context_window=None, type=None), Model(id='openai/gpt-3.5-turbo', owned_by='openai', context_window=None, type=None)]\n",
      "\n",
      "=== OPENAI Models ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/by/cg9tswr17bz7_bfx954c71yc0000gn/T/ipykernel_9620/2671027845.py:7: DeprecationWarning: The `.models` property is deprecated and will be removed in version 3.0. Use AIFactory.get_provider_models('openai-compatible') instead for static model discovery without creating provider instances.\n",
      "  print(model.models)\n",
      "/var/folders/by/cg9tswr17bz7_bfx954c71yc0000gn/T/ipykernel_9620/2671027845.py:7: DeprecationWarning: The `.models` property is deprecated and will be removed in version 3.0. Use AIFactory.get_provider_models('openrouter') instead for static model discovery without creating provider instances.\n",
      "  print(model.models)\n",
      "/var/folders/by/cg9tswr17bz7_bfx954c71yc0000gn/T/ipykernel_9620/2671027845.py:7: DeprecationWarning: The `.models` property is deprecated and will be removed in version 3.0. Use AIFactory.get_provider_models('openai') instead for static model discovery without creating provider instances.\n",
      "  print(model.models)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model(id='gpt-4-0613', owned_by='openai', context_window=None, type=None), Model(id='gpt-4', owned_by='openai', context_window=None, type=None), Model(id='gpt-3.5-turbo', owned_by='openai', context_window=None, type=None), Model(id='gpt-4-0314', owned_by='openai', context_window=None, type=None), Model(id='gpt-5.2-codex', owned_by='system', context_window=None, type=None), Model(id='gpt-4o-mini-tts-2025-12-15', owned_by='system', context_window=None, type=None), Model(id='gpt-realtime-mini-2025-12-15', owned_by='system', context_window=None, type=None), Model(id='gpt-audio-mini-2025-12-15', owned_by='system', context_window=None, type=None), Model(id='gpt-3.5-turbo-instruct', owned_by='system', context_window=None, type=None), Model(id='gpt-3.5-turbo-instruct-0914', owned_by='system', context_window=None, type=None), Model(id='gpt-4-1106-preview', owned_by='system', context_window=None, type=None), Model(id='gpt-3.5-turbo-1106', owned_by='system', context_window=None, type=None), Model(id='gpt-4-0125-preview', owned_by='system', context_window=None, type=None), Model(id='gpt-4-turbo-preview', owned_by='system', context_window=None, type=None), Model(id='gpt-3.5-turbo-0125', owned_by='system', context_window=None, type=None), Model(id='gpt-4-turbo', owned_by='system', context_window=None, type=None), Model(id='gpt-4-turbo-2024-04-09', owned_by='system', context_window=None, type=None), Model(id='gpt-4o', owned_by='system', context_window=None, type=None), Model(id='gpt-4o-2024-05-13', owned_by='system', context_window=None, type=None), Model(id='gpt-4o-mini-2024-07-18', owned_by='system', context_window=None, type=None), Model(id='gpt-4o-mini', owned_by='system', context_window=None, type=None), Model(id='gpt-4o-2024-08-06', owned_by='system', context_window=None, type=None), Model(id='gpt-4o-audio-preview', owned_by='system', context_window=None, type=None), Model(id='gpt-4o-realtime-preview', owned_by='system', context_window=None, type=None), Model(id='gpt-4o-realtime-preview-2024-12-17', owned_by='system', context_window=None, type=None), Model(id='gpt-4o-audio-preview-2024-12-17', owned_by='system', context_window=None, type=None), Model(id='gpt-4o-mini-realtime-preview-2024-12-17', owned_by='system', context_window=None, type=None), Model(id='gpt-4o-mini-audio-preview-2024-12-17', owned_by='system', context_window=None, type=None), Model(id='gpt-4o-mini-realtime-preview', owned_by='system', context_window=None, type=None), Model(id='gpt-4o-mini-audio-preview', owned_by='system', context_window=None, type=None), Model(id='gpt-4o-2024-11-20', owned_by='system', context_window=None, type=None), Model(id='gpt-4o-search-preview-2025-03-11', owned_by='system', context_window=None, type=None), Model(id='gpt-4o-search-preview', owned_by='system', context_window=None, type=None), Model(id='gpt-4o-mini-search-preview-2025-03-11', owned_by='system', context_window=None, type=None), Model(id='gpt-4o-mini-search-preview', owned_by='system', context_window=None, type=None), Model(id='gpt-4o-transcribe', owned_by='system', context_window=None, type=None), Model(id='gpt-4o-mini-transcribe', owned_by='system', context_window=None, type=None), Model(id='gpt-4o-mini-tts', owned_by='system', context_window=None, type=None), Model(id='gpt-4.1-2025-04-14', owned_by='system', context_window=None, type=None), Model(id='gpt-4.1', owned_by='system', context_window=None, type=None), Model(id='gpt-4.1-mini-2025-04-14', owned_by='system', context_window=None, type=None), Model(id='gpt-4.1-mini', owned_by='system', context_window=None, type=None), Model(id='gpt-4.1-nano-2025-04-14', owned_by='system', context_window=None, type=None), Model(id='gpt-4.1-nano', owned_by='system', context_window=None, type=None), Model(id='gpt-image-1', owned_by='system', context_window=None, type=None), Model(id='gpt-4o-realtime-preview-2025-06-03', owned_by='system', context_window=None, type=None), Model(id='gpt-4o-audio-preview-2025-06-03', owned_by='system', context_window=None, type=None), Model(id='gpt-4o-transcribe-diarize', owned_by='system', context_window=None, type=None), Model(id='gpt-5-chat-latest', owned_by='system', context_window=None, type=None), Model(id='gpt-5-2025-08-07', owned_by='system', context_window=None, type=None), Model(id='gpt-5', owned_by='system', context_window=None, type=None), Model(id='gpt-5-mini-2025-08-07', owned_by='system', context_window=None, type=None), Model(id='gpt-5-mini', owned_by='system', context_window=None, type=None), Model(id='gpt-5-nano-2025-08-07', owned_by='system', context_window=None, type=None), Model(id='gpt-5-nano', owned_by='system', context_window=None, type=None), Model(id='gpt-audio-2025-08-28', owned_by='system', context_window=None, type=None), Model(id='gpt-realtime', owned_by='system', context_window=None, type=None), Model(id='gpt-realtime-2025-08-28', owned_by='system', context_window=None, type=None), Model(id='gpt-audio', owned_by='system', context_window=None, type=None), Model(id='gpt-5-codex', owned_by='system', context_window=None, type=None), Model(id='gpt-image-1-mini', owned_by='system', context_window=None, type=None), Model(id='gpt-5-pro-2025-10-06', owned_by='system', context_window=None, type=None), Model(id='gpt-5-pro', owned_by='system', context_window=None, type=None), Model(id='gpt-audio-mini', owned_by='system', context_window=None, type=None), Model(id='gpt-audio-mini-2025-10-06', owned_by='system', context_window=None, type=None), Model(id='gpt-5-search-api', owned_by='system', context_window=None, type=None), Model(id='gpt-realtime-mini', owned_by='system', context_window=None, type=None), Model(id='gpt-realtime-mini-2025-10-06', owned_by='system', context_window=None, type=None), Model(id='gpt-5-search-api-2025-10-14', owned_by='system', context_window=None, type=None), Model(id='gpt-5.1-chat-latest', owned_by='system', context_window=None, type=None), Model(id='gpt-5.1-2025-11-13', owned_by='system', context_window=None, type=None), Model(id='gpt-5.1', owned_by='system', context_window=None, type=None), Model(id='gpt-5.1-codex', owned_by='system', context_window=None, type=None), Model(id='gpt-5.1-codex-mini', owned_by='system', context_window=None, type=None), Model(id='gpt-5.1-codex-max', owned_by='system', context_window=None, type=None), Model(id='gpt-image-1.5', owned_by='system', context_window=None, type=None), Model(id='gpt-5.2-2025-12-11', owned_by='system', context_window=None, type=None), Model(id='gpt-5.2', owned_by='system', context_window=None, type=None), Model(id='gpt-5.2-pro-2025-12-11', owned_by='system', context_window=None, type=None), Model(id='gpt-5.2-pro', owned_by='system', context_window=None, type=None), Model(id='gpt-5.2-chat-latest', owned_by='system', context_window=None, type=None), Model(id='gpt-4o-mini-transcribe-2025-12-15', owned_by='system', context_window=None, type=None), Model(id='gpt-4o-mini-transcribe-2025-03-20', owned_by='system', context_window=None, type=None), Model(id='gpt-4o-mini-tts-2025-03-20', owned_by='system', context_window=None, type=None), Model(id='gpt-3.5-turbo-16k', owned_by='openai-internal', context_window=None, type=None)]\n",
      "\n",
      "=== XAI Models ===\n",
      "[Model(id='grok-2-vision-1212', owned_by='X.AI', context_window=None, type=None), Model(id='grok-3', owned_by='X.AI', context_window=None, type=None), Model(id='grok-3-mini', owned_by='X.AI', context_window=None, type=None), Model(id='grok-4-0709', owned_by='X.AI', context_window=None, type=None), Model(id='grok-4-1-fast-non-reasoning', owned_by='X.AI', context_window=None, type=None), Model(id='grok-4-1-fast-reasoning', owned_by='X.AI', context_window=None, type=None), Model(id='grok-4-fast-non-reasoning', owned_by='X.AI', context_window=None, type=None), Model(id='grok-4-fast-reasoning', owned_by='X.AI', context_window=None, type=None), Model(id='grok-code-fast-1', owned_by='X.AI', context_window=None, type=None), Model(id='grok-2-image-1212', owned_by='X.AI', context_window=None, type=None), Model(id='grok-imagine-image', owned_by='X.AI', context_window=None, type=None), Model(id='grok-imagine-video', owned_by='X.AI', context_window=None, type=None)]\n",
      "\n",
      "=== ANTHROPIC Models ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/by/cg9tswr17bz7_bfx954c71yc0000gn/T/ipykernel_9620/2671027845.py:7: DeprecationWarning: The `.models` property is deprecated and will be removed in version 3.0. Use AIFactory.get_provider_models('xai') instead for static model discovery without creating provider instances.\n",
      "  print(model.models)\n",
      "/var/folders/by/cg9tswr17bz7_bfx954c71yc0000gn/T/ipykernel_9620/2671027845.py:7: DeprecationWarning: The `.models` property is deprecated and will be removed in version 3.0. Use AIFactory.get_provider_models('anthropic') instead for static model discovery without creating provider instances.\n",
      "  print(model.models)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model(id='claude-opus-4-5-20251101', owned_by='Anthropic', context_window=200000, type=None), Model(id='claude-haiku-4-5-20251001', owned_by='Anthropic', context_window=200000, type=None), Model(id='claude-sonnet-4-5-20250929', owned_by='Anthropic', context_window=200000, type=None), Model(id='claude-opus-4-1-20250805', owned_by='Anthropic', context_window=200000, type=None), Model(id='claude-opus-4-20250514', owned_by='Anthropic', context_window=200000, type=None), Model(id='claude-sonnet-4-20250514', owned_by='Anthropic', context_window=200000, type=None), Model(id='claude-3-7-sonnet-20250219', owned_by='Anthropic', context_window=200000, type=None), Model(id='claude-3-5-haiku-20241022', owned_by='Anthropic', context_window=200000, type=None), Model(id='claude-3-haiku-20240307', owned_by='Anthropic', context_window=200000, type=None)]\n",
      "\n",
      "=== GROQ Models ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/by/cg9tswr17bz7_bfx954c71yc0000gn/T/ipykernel_9620/2671027845.py:7: DeprecationWarning: The `.models` property is deprecated and will be removed in version 3.0. Use AIFactory.get_provider_models('groq') instead for static model discovery without creating provider instances.\n",
      "  print(model.models)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model(id='openai/gpt-oss-20b', owned_by='Groq', context_window=128000, type=None), Model(id='meta-llama/llama-prompt-guard-2-86m', owned_by='Groq', context_window=128000, type=None), Model(id='allam-2-7b', owned_by='Groq', context_window=128000, type=None), Model(id='meta-llama/llama-4-maverick-17b-128e-instruct', owned_by='Groq', context_window=128000, type=None), Model(id='canopylabs/orpheus-arabic-saudi', owned_by='Groq', context_window=128000, type=None), Model(id='meta-llama/llama-4-scout-17b-16e-instruct', owned_by='Groq', context_window=128000, type=None), Model(id='qwen/qwen3-32b', owned_by='Groq', context_window=128000, type=None), Model(id='groq/compound', owned_by='Groq', context_window=128000, type=None), Model(id='whisper-large-v3-turbo', owned_by='Groq', context_window=128000, type=None), Model(id='whisper-large-v3', owned_by='Groq', context_window=128000, type=None), Model(id='openai/gpt-oss-safeguard-20b', owned_by='Groq', context_window=128000, type=None), Model(id='groq/compound-mini', owned_by='Groq', context_window=128000, type=None), Model(id='moonshotai/kimi-k2-instruct-0905', owned_by='Groq', context_window=128000, type=None), Model(id='canopylabs/orpheus-v1-english', owned_by='Groq', context_window=128000, type=None), Model(id='moonshotai/kimi-k2-instruct', owned_by='Groq', context_window=128000, type=None), Model(id='llama-3.1-8b-instant', owned_by='Groq', context_window=128000, type=None), Model(id='meta-llama/llama-guard-4-12b', owned_by='Groq', context_window=128000, type=None), Model(id='meta-llama/llama-prompt-guard-2-22m', owned_by='Groq', context_window=128000, type=None), Model(id='openai/gpt-oss-120b', owned_by='Groq', context_window=128000, type=None), Model(id='llama-3.3-70b-versatile', owned_by='Groq', context_window=128000, type=None)]\n",
      "\n",
      "=== OLLAMA Models ===\n",
      "[Model(id='nemotron-3-nano:latest', owned_by='Ollama', context_window=32768, type=None), Model(id='glm-4.7-flash:latest', owned_by='Ollama', context_window=32768, type=None), Model(id='nomic-embed-text-v2-moe:latest', owned_by='Ollama', context_window=32768, type=None), Model(id='qwen3:32b', owned_by='Ollama', context_window=32768, type=None), Model(id='qwen3-embedding:8b', owned_by='Ollama', context_window=32768, type=None), Model(id='kimi-k2-thinking:cloud', owned_by='Ollama', context_window=32768, type=None), Model(id='deepseek-r1:14b', owned_by='Ollama', context_window=32768, type=None), Model(id='magistral:latest', owned_by='Ollama', context_window=32768, type=None), Model(id='deepseek-r1:8b', owned_by='Ollama', context_window=32768, type=None), Model(id='gpt-oss:20b', owned_by='Ollama', context_window=32768, type=None), Model(id='gemma3:27b', owned_by='Ollama', context_window=32768, type=None), Model(id='deepseek-r1:7b', owned_by='Ollama', context_window=32768, type=None), Model(id='deepseek-r1:latest', owned_by='Ollama', context_window=32768, type=None), Model(id='gemma3:12b', owned_by='Ollama', context_window=32768, type=None), Model(id='phi4-reasoning:latest', owned_by='Ollama', context_window=32768, type=None), Model(id='phi4-mini-reasoning:latest', owned_by='Ollama', context_window=32768, type=None), Model(id='gemma3:1b', owned_by='Ollama', context_window=32768, type=None), Model(id='gemma3:4b', owned_by='Ollama', context_window=32768, type=None), Model(id='nomic-embed-text:latest', owned_by='Ollama', context_window=32768, type=None), Model(id='mxbai-embed-large:latest', owned_by='Ollama', context_window=32768, type=None), Model(id='mistral-small:latest', owned_by='Ollama', context_window=32768, type=None), Model(id='phi3:mini-128k', owned_by='Ollama', context_window=32768, type=None), Model(id='phi3:14b-instruct', owned_by='Ollama', context_window=32768, type=None), Model(id='mistral-nemo:latest', owned_by='Ollama', context_window=32768, type=None), Model(id='phi3:medium-128k', owned_by='Ollama', context_window=32768, type=None), Model(id='phi3.5:3.8b-mini-instruct-fp16', owned_by='Ollama', context_window=32768, type=None), Model(id='phi4:latest', owned_by='Ollama', context_window=32768, type=None), Model(id='phi4-mini:latest', owned_by='Ollama', context_window=32768, type=None), Model(id='qwen3:14b', owned_by='Ollama', context_window=32768, type=None), Model(id='qwen3:30b', owned_by='Ollama', context_window=32768, type=None), Model(id='granite4:small-h', owned_by='Ollama', context_window=32768, type=None), Model(id='qwen3-embedding:latest', owned_by='Ollama', context_window=32768, type=None), Model(id='granite4:latest', owned_by='Ollama', context_window=32768, type=None), Model(id='ministral-3:14b', owned_by='Ollama', context_window=32768, type=None), Model(id='bigtiger:128k', owned_by='Ollama', context_window=32768, type=None), Model(id='minitiger:latest', owned_by='Ollama', context_window=32768, type=None)]\n",
      "\n",
      "=== GOOGLE Models ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/by/cg9tswr17bz7_bfx954c71yc0000gn/T/ipykernel_9620/2671027845.py:7: DeprecationWarning: The `.models` property is deprecated and will be removed in version 3.0. Use AIFactory.get_provider_models('ollama') instead for static model discovery without creating provider instances.\n",
      "  print(model.models)\n",
      "/var/folders/by/cg9tswr17bz7_bfx954c71yc0000gn/T/ipykernel_9620/2671027845.py:7: DeprecationWarning: The `.models` property is deprecated and will be removed in version 3.0. Use AIFactory.get_provider_models('google') instead for static model discovery without creating provider instances.\n",
      "  print(model.models)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model(id='gemini-2.5-flash', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-2.5-pro', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-2.0-flash', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-2.0-flash-001', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-2.0-flash-exp-image-generation', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-2.0-flash-lite-001', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-2.0-flash-lite', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-exp-1206', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-2.5-flash-preview-tts', owned_by='Google', context_window=8192, type=None), Model(id='gemini-2.5-pro-preview-tts', owned_by='Google', context_window=8192, type=None), Model(id='gemma-3-1b-it', owned_by='Google', context_window=32768, type=None), Model(id='gemma-3-4b-it', owned_by='Google', context_window=32768, type=None), Model(id='gemma-3-12b-it', owned_by='Google', context_window=32768, type=None), Model(id='gemma-3-27b-it', owned_by='Google', context_window=131072, type=None), Model(id='gemma-3n-e4b-it', owned_by='Google', context_window=8192, type=None), Model(id='gemma-3n-e2b-it', owned_by='Google', context_window=8192, type=None), Model(id='gemini-flash-latest', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-flash-lite-latest', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-pro-latest', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-2.5-flash-lite', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-2.5-flash-image', owned_by='Google', context_window=32768, type=None), Model(id='gemini-2.5-flash-preview-09-2025', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-2.5-flash-lite-preview-09-2025', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-3-pro-preview', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-3-flash-preview', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-3-pro-image-preview', owned_by='Google', context_window=131072, type=None), Model(id='nano-banana-pro-preview', owned_by='Google', context_window=131072, type=None), Model(id='gemini-robotics-er-1.5-preview', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-2.5-computer-use-preview-10-2025', owned_by='Google', context_window=131072, type=None), Model(id='deep-research-pro-preview-12-2025', owned_by='Google', context_window=131072, type=None), Model(id='embedding-001', owned_by='Google', context_window=2048, type=None), Model(id='text-embedding-004', owned_by='Google', context_window=2048, type=None), Model(id='gemini-embedding-001', owned_by='Google', context_window=2048, type=None), Model(id='aqa', owned_by='Google', context_window=7168, type=None), Model(id='imagen-4.0-generate-preview-06-06', owned_by='Google', context_window=480, type=None), Model(id='imagen-4.0-ultra-generate-preview-06-06', owned_by='Google', context_window=480, type=None), Model(id='imagen-4.0-generate-001', owned_by='Google', context_window=480, type=None), Model(id='imagen-4.0-ultra-generate-001', owned_by='Google', context_window=480, type=None), Model(id='imagen-4.0-fast-generate-001', owned_by='Google', context_window=480, type=None), Model(id='veo-2.0-generate-001', owned_by='Google', context_window=480, type=None), Model(id='veo-3.0-generate-001', owned_by='Google', context_window=480, type=None), Model(id='veo-3.0-fast-generate-001', owned_by='Google', context_window=480, type=None), Model(id='veo-3.1-generate-preview', owned_by='Google', context_window=480, type=None), Model(id='veo-3.1-fast-generate-preview', owned_by='Google', context_window=480, type=None), Model(id='gemini-2.5-flash-native-audio-latest', owned_by='Google', context_window=131072, type=None), Model(id='gemini-2.5-flash-native-audio-preview-09-2025', owned_by='Google', context_window=131072, type=None), Model(id='gemini-2.5-flash-native-audio-preview-12-2025', owned_by='Google', context_window=131072, type=None)]\n",
      "\n",
      "=== GOOGLE Models ===\n",
      "[Model(id='gemini-2.5-flash', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-2.5-pro', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-2.0-flash', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-2.0-flash-001', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-2.0-flash-exp-image-generation', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-2.0-flash-lite-001', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-2.0-flash-lite', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-exp-1206', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-2.5-flash-preview-tts', owned_by='Google', context_window=8192, type=None), Model(id='gemini-2.5-pro-preview-tts', owned_by='Google', context_window=8192, type=None), Model(id='gemma-3-1b-it', owned_by='Google', context_window=32768, type=None), Model(id='gemma-3-4b-it', owned_by='Google', context_window=32768, type=None), Model(id='gemma-3-12b-it', owned_by='Google', context_window=32768, type=None), Model(id='gemma-3-27b-it', owned_by='Google', context_window=131072, type=None), Model(id='gemma-3n-e4b-it', owned_by='Google', context_window=8192, type=None), Model(id='gemma-3n-e2b-it', owned_by='Google', context_window=8192, type=None), Model(id='gemini-flash-latest', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-flash-lite-latest', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-pro-latest', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-2.5-flash-lite', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-2.5-flash-image', owned_by='Google', context_window=32768, type=None), Model(id='gemini-2.5-flash-preview-09-2025', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-2.5-flash-lite-preview-09-2025', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-3-pro-preview', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-3-flash-preview', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-3-pro-image-preview', owned_by='Google', context_window=131072, type=None), Model(id='nano-banana-pro-preview', owned_by='Google', context_window=131072, type=None), Model(id='gemini-robotics-er-1.5-preview', owned_by='Google', context_window=1048576, type=None), Model(id='gemini-2.5-computer-use-preview-10-2025', owned_by='Google', context_window=131072, type=None), Model(id='deep-research-pro-preview-12-2025', owned_by='Google', context_window=131072, type=None), Model(id='embedding-001', owned_by='Google', context_window=2048, type=None), Model(id='text-embedding-004', owned_by='Google', context_window=2048, type=None), Model(id='gemini-embedding-001', owned_by='Google', context_window=2048, type=None), Model(id='aqa', owned_by='Google', context_window=7168, type=None), Model(id='imagen-4.0-generate-preview-06-06', owned_by='Google', context_window=480, type=None), Model(id='imagen-4.0-ultra-generate-preview-06-06', owned_by='Google', context_window=480, type=None), Model(id='imagen-4.0-generate-001', owned_by='Google', context_window=480, type=None), Model(id='imagen-4.0-ultra-generate-001', owned_by='Google', context_window=480, type=None), Model(id='imagen-4.0-fast-generate-001', owned_by='Google', context_window=480, type=None), Model(id='veo-2.0-generate-001', owned_by='Google', context_window=480, type=None), Model(id='veo-3.0-generate-001', owned_by='Google', context_window=480, type=None), Model(id='veo-3.0-fast-generate-001', owned_by='Google', context_window=480, type=None), Model(id='veo-3.1-generate-preview', owned_by='Google', context_window=480, type=None), Model(id='veo-3.1-fast-generate-preview', owned_by='Google', context_window=480, type=None), Model(id='gemini-2.5-flash-native-audio-latest', owned_by='Google', context_window=131072, type=None), Model(id='gemini-2.5-flash-native-audio-preview-09-2025', owned_by='Google', context_window=131072, type=None), Model(id='gemini-2.5-flash-native-audio-preview-12-2025', owned_by='Google', context_window=131072, type=None)]\n",
      "\n",
      "=== AZURE Models ===\n",
      "[]\n",
      "\n",
      "=== MISTRAL Models ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/by/cg9tswr17bz7_bfx954c71yc0000gn/T/ipykernel_9620/2671027845.py:7: DeprecationWarning: The `.models` property is deprecated and will be removed in version 3.0. Use AIFactory.get_provider_models('azure') instead for static model discovery without creating provider instances.\n",
      "  print(model.models)\n",
      "/var/folders/by/cg9tswr17bz7_bfx954c71yc0000gn/T/ipykernel_9620/2671027845.py:7: DeprecationWarning: The `.models` property is deprecated and will be removed in version 3.0. Use AIFactory.get_provider_models('mistral') instead for static model discovery without creating provider instances.\n",
      "  print(model.models)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model(id='mistral-medium-2505', owned_by='mistralai', context_window=None, type=None), Model(id='mistral-medium-2508', owned_by='mistralai', context_window=None, type=None), Model(id='mistral-medium-latest', owned_by='mistralai', context_window=None, type=None), Model(id='mistral-medium', owned_by='mistralai', context_window=None, type=None), Model(id='open-mistral-nemo', owned_by='mistralai', context_window=None, type=None), Model(id='open-mistral-nemo-2407', owned_by='mistralai', context_window=None, type=None), Model(id='mistral-tiny-2407', owned_by='mistralai', context_window=None, type=None), Model(id='mistral-tiny-latest', owned_by='mistralai', context_window=None, type=None), Model(id='mistral-large-2411', owned_by='mistralai', context_window=None, type=None), Model(id='pixtral-large-2411', owned_by='mistralai', context_window=None, type=None), Model(id='pixtral-large-latest', owned_by='mistralai', context_window=None, type=None), Model(id='mistral-large-pixtral-2411', owned_by='mistralai', context_window=None, type=None), Model(id='codestral-2508', owned_by='mistralai', context_window=None, type=None), Model(id='codestral-latest', owned_by='mistralai', context_window=None, type=None), Model(id='devstral-small-2507', owned_by='mistralai', context_window=None, type=None), Model(id='devstral-medium-2507', owned_by='mistralai', context_window=None, type=None), Model(id='devstral-2512', owned_by='mistralai', context_window=None, type=None), Model(id='mistral-vibe-cli-latest', owned_by='mistralai', context_window=None, type=None), Model(id='devstral-medium-latest', owned_by='mistralai', context_window=None, type=None), Model(id='devstral-latest', owned_by='mistralai', context_window=None, type=None), Model(id='labs-devstral-small-2512', owned_by='mistralai', context_window=None, type=None), Model(id='devstral-small-latest', owned_by='mistralai', context_window=None, type=None), Model(id='mistral-small-2506', owned_by='mistralai', context_window=None, type=None), Model(id='mistral-small-latest', owned_by='mistralai', context_window=None, type=None), Model(id='labs-mistral-small-creative', owned_by='mistralai', context_window=None, type=None), Model(id='magistral-medium-2509', owned_by='mistralai', context_window=None, type=None), Model(id='magistral-medium-latest', owned_by='mistralai', context_window=None, type=None), Model(id='magistral-small-2509', owned_by='mistralai', context_window=None, type=None), Model(id='magistral-small-latest', owned_by='mistralai', context_window=None, type=None), Model(id='voxtral-mini-2507', owned_by='mistralai', context_window=None, type=None), Model(id='voxtral-mini-latest', owned_by='mistralai', context_window=None, type=None), Model(id='voxtral-small-2507', owned_by='mistralai', context_window=None, type=None), Model(id='voxtral-small-latest', owned_by='mistralai', context_window=None, type=None), Model(id='mistral-large-2512', owned_by='mistralai', context_window=None, type=None), Model(id='mistral-large-latest', owned_by='mistralai', context_window=None, type=None), Model(id='ministral-3b-2512', owned_by='mistralai', context_window=None, type=None), Model(id='ministral-3b-latest', owned_by='mistralai', context_window=None, type=None), Model(id='ministral-8b-2512', owned_by='mistralai', context_window=None, type=None), Model(id='ministral-8b-latest', owned_by='mistralai', context_window=None, type=None), Model(id='ministral-14b-2512', owned_by='mistralai', context_window=None, type=None), Model(id='ministral-14b-latest', owned_by='mistralai', context_window=None, type=None), Model(id='open-mistral-7b', owned_by='mistralai', context_window=None, type=None), Model(id='mistral-tiny', owned_by='mistralai', context_window=None, type=None), Model(id='mistral-tiny-2312', owned_by='mistralai', context_window=None, type=None), Model(id='pixtral-12b-2409', owned_by='mistralai', context_window=None, type=None), Model(id='pixtral-12b', owned_by='mistralai', context_window=None, type=None), Model(id='pixtral-12b-latest', owned_by='mistralai', context_window=None, type=None), Model(id='ministral-3b-2410', owned_by='mistralai', context_window=None, type=None), Model(id='ministral-8b-2410', owned_by='mistralai', context_window=None, type=None), Model(id='codestral-2501', owned_by='mistralai', context_window=None, type=None), Model(id='codestral-2412', owned_by='mistralai', context_window=None, type=None), Model(id='codestral-2411-rc5', owned_by='mistralai', context_window=None, type=None), Model(id='mistral-small-2501', owned_by='mistralai', context_window=None, type=None), Model(id='mistral-embed-2312', owned_by='mistralai', context_window=None, type=None), Model(id='mistral-embed', owned_by='mistralai', context_window=None, type=None), Model(id='codestral-embed', owned_by='mistralai', context_window=None, type=None), Model(id='codestral-embed-2505', owned_by='mistralai', context_window=None, type=None), Model(id='mistral-moderation-2411', owned_by='mistralai', context_window=None, type=None), Model(id='mistral-moderation-latest', owned_by='mistralai', context_window=None, type=None), Model(id='mistral-ocr-2512', owned_by='mistralai', context_window=None, type=None), Model(id='mistral-ocr-latest', owned_by='mistralai', context_window=None, type=None), Model(id='mistral-ocr-2505', owned_by='mistralai', context_window=None, type=None), Model(id='mistral-ocr-2503', owned_by='mistralai', context_window=None, type=None), Model(id='voxtral-mini-transcribe-2507', owned_by='mistralai', context_window=None, type=None), Model(id='voxtral-mini-2507', owned_by='mistralai', context_window=None, type=None), Model(id='voxtral-mini-latest', owned_by='mistralai', context_window=None, type=None)]\n",
      "\n",
      "=== DEEPSEEK Models ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/by/cg9tswr17bz7_bfx954c71yc0000gn/T/ipykernel_9620/2671027845.py:7: DeprecationWarning: The `.models` property is deprecated and will be removed in version 3.0. Use AIFactory.get_provider_models('deepseek') instead for static model discovery without creating provider instances.\n",
      "  print(model.models)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    try:\n",
    "        # Create an instance of the provider class\n",
    "        provider = model[0]\n",
    "        model = model[1]\n",
    "        print(f\"\\n=== {provider.upper()} Models ===\")\n",
    "        print(model.models)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to get models for {provider}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synchronous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for openai-compatible:\n",
      "Paris is the capital city of France.\n",
      "Paris is the capital city of France.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for openrouter:\n",
      "The capital of France is Paris.\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for openai:\n",
      "The capital of France is Paris.\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for xai:\n",
      "The capital of France is Paris.\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for anthropic:\n",
      "Failed to process anthropic: Anthropic API error: Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\n",
      "Results for groq:\n",
      "The capital of France is Paris.\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for ollama:\n",
      "The capital of France is Paris.\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for google:\n",
      "The capital of France is Paris.\n",
      "\n",
      "The capital of France is Paris.\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for google:\n",
      "The capital of France is **Paris**.\n",
      "The capital of France is **Paris**.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for azure:\n",
      "The capital of France is Paris.\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for mistral:\n",
      "The capital of France is **Paris**.\n",
      "The capital of France is **Paris**.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for deepseek:\n",
      "The capital of France is **Paris**.\n",
      "The capital of France is **Paris**.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for name, llm in models:\n",
    "    try:\n",
    "        print(f\"Results for {llm.provider}:\")\n",
    "        result = llm.chat_complete(messages)\n",
    "        print(result.choices[0].message.content)\n",
    "        \n",
    "        print(result.content)\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for openai-compatible:\n",
      "Paris is the capital city of France.\n",
      "Paris is the capital city of France.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for openrouter:\n",
      "The capital of France is Paris.\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for openai:\n",
      "The capital of France is Paris.\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for xai:\n",
      "The capital of France is Paris.\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for anthropic:\n",
      "Failed to process anthropic: Anthropic API error: Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\n",
      "Results for groq:\n",
      "The capital of France is Paris.\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for ollama:\n",
      "The capital of France is **Paris**.\n",
      "The capital of France is **Paris**.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for google:\n",
      "The capital of France is Paris.\n",
      "\n",
      "The capital of France is Paris.\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for google:\n",
      "The capital of France is Paris.\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for azure:\n",
      "The capital of France is Paris.\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for mistral:\n",
      "The capital of France is **Paris**.\n",
      "The capital of France is **Paris**.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for deepseek:\n",
      "The capital of France is **Paris**.\n",
      "The capital of France is **Paris**.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for name, llm in models:\n",
    "    try:\n",
    "        print(f\"Results for {llm.provider}:\")\n",
    "        result = await llm.achat_complete(messages)\n",
    "        print(result.choices[0].message.content)\n",
    "        print(result.content)\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for openai-compatible:\n",
      "{'cities': [{'name': 'So Paulo', 'state': 'SP', 'population_estimate_2023': 12330000}, {'name': 'Rio de Janeiro', 'state': 'RJ', 'population_estimate_2023': 6748000}, {'name': 'Salvador', 'state': 'BA', 'population_estimate_2023': 2887000}]}\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for openrouter:\n",
      "{'cities': ['So Paulo', 'Rio de Janeiro', 'Braslia']}\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for openai:\n",
      "[{'rank': 1, 'city': 'So Paulo', 'state': 'So Paulo'}, {'rank': 2, 'city': 'Rio de Janeiro', 'state': 'Rio de Janeiro'}, {'rank': 3, 'city': 'Braslia', 'state': 'Distrito Federal'}]\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for xai:\n",
      "{'cities': [{'rank': 1, 'name': 'So Paulo', 'population': 12330000, 'state': 'So Paulo'}, {'rank': 2, 'name': 'Rio de Janeiro', 'population': 6748000, 'state': 'Rio de Janeiro'}, {'rank': 3, 'name': 'Braslia', 'population': 3055000, 'state': 'Distrito Federal'}]}\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for anthropic:\n",
      "Failed anthropic: Anthropic API error: Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\n",
      "Results for groq:\n",
      "{'sao paulo': {'population': 21544000, 'city': 'So Paulo', 'state': 'So Paulo'}, 'rio de janeiro': {'population': 6923000, 'city': 'Rio de Janeiro', 'state': 'Rio de Janeiro'}, 'brasilia': {'population': 3240000, 'city': 'Braslia', 'state': 'Federal District'}}\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for ollama:\n",
      "[{'city': 'So Paulo', 'population': 12300000}, {'city': 'Rio de Janeiro', 'population': 6740000}, {'city': 'Salvador', 'population': 2890000}]\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for google:\n",
      "Error decoding JSON\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"city\": \"So Paulo\",\n",
      "    \"state\": \"SP\"\n",
      "  },\n",
      "  {\n",
      "    \"city\": \"Rio de Janeiro\",\n",
      "    \"state\": \"RJ\"\n",
      "  },\n",
      "  {\n",
      "    \"city\": \"Braslia\",\n",
      "    \"state\": \"DF\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for google:\n",
      "[{'name': 'So Paulo', 'state': 'So Paulo', 'population': 12390000}, {'name': 'Rio de Janeiro', 'state': 'Rio de Janeiro', 'population': 6770000}, {'name': 'Braslia', 'state': 'Federal District', 'population': 3090000}]\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for azure:\n",
      "{'top_cities': ['So Paulo', 'Rio de Janeiro', 'Braslia']}\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for mistral:\n",
      "{'top_brazilian_cities': [{'rank': 1, 'city': 'So Paulo', 'state': 'So Paulo', 'population': 12325232}, {'rank': 2, 'city': 'Rio de Janeiro', 'state': 'Rio de Janeiro', 'population': 6747815}, {'rank': 3, 'city': 'Braslia', 'state': 'Federal District', 'population': 3094325}], 'source': 'IBGE (Brazilian Institute of Geography and Statistics) - 2022 estimates'}\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for deepseek:\n",
      "{'cities': [{'name': 'So Paulo', 'population': 'Approximately 12.3 million', 'state': 'So Paulo', 'note': 'Largest city in Brazil and South America by population'}, {'name': 'Rio de Janeiro', 'population': 'Approximately 6.7 million', 'state': 'Rio de Janeiro', 'note': 'Famous for its iconic landmarks like Christ the Redeemer and Copacabana Beach'}, {'name': 'Braslia', 'population': 'Approximately 3.1 million', 'state': 'Federal District', 'note': 'Capital of Brazil, planned and built in the 20th century'}]}\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Please return the top 3 brazilian cities in JSON format. Dont include ```json```  in the response.\"},\n",
    "    ]\n",
    "\n",
    "\n",
    "for name, llm in models:\n",
    "    try:\n",
    "        print(f\"Results for {llm.provider}:\")\n",
    "        result = llm.chat_complete(json_messages)\n",
    "        try:\n",
    "            json_data = json.loads(result.choices[0].message.content)\n",
    "            print(json_data)\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Error decoding JSON\")\n",
    "            print(result.choices[0].message.content)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed {name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pydantic (WIP)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from pydantic import BaseModel\n",
    "# from typing import List\n",
    "\n",
    "# class Country(BaseModel):\n",
    "#     name: str\n",
    "#     population: int\n",
    "\n",
    "# class Response(BaseModel):\n",
    "#     countries: List[Country]\n",
    "\n",
    "# json_messages = [\n",
    "#         {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#         {\"role\": \"user\", \"content\": \"Please return the top 3 countries in terms of population. Responda no formato JSON.\"},\n",
    "#     ]\n",
    "\n",
    "\n",
    "# for name, config in models.items():\n",
    "#     try:\n",
    "#         llm = config[\"class\"](model_name=config[\"model\"], structured={\"type\": \"json\", \"model\": Response})\n",
    "#         print(f\"Results for {llm.provider}:\")\n",
    "#         result = llm.chat_complete(json_messages)\n",
    "#         try:\n",
    "#             json_data = json.loads(result.choices[0].message.content)\n",
    "#             print(json_data)\n",
    "#         except json.JSONDecodeError:\n",
    "#             print(\"Error decoding JSON\")\n",
    "        \n",
    "#         print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to get models for {name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synchronous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for openai-compatible:\n",
      "id='chatcmpl-h5wnpl9em8hja7hgsvrk7' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-oss-120b' created=1769794689 object='chat.completion.chunk'\n",
      "id='chatcmpl-h5wnpl9em8hja7hgsvrk7' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-oss-120b' created=1769794689 object='chat.completion.chunk'\n",
      "id='chatcmpl-h5wnpl9em8hja7hgsvrk7' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-oss-120b' created=1769794689 object='chat.completion.chunk'\n",
      "id='chatcmpl-h5wnpl9em8hja7hgsvrk7' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-oss-120b' created=1769794689 object='chat.completion.chunk'\n",
      "id='chatcmpl-h5wnpl9em8hja7hgsvrk7' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-oss-120b' created=1769794689 object='chat.completion.chunk'\n",
      "id='chatcmpl-h5wnpl9em8hja7hgsvrk7' choices=[StreamChoice(index=0, delta=DeltaMessage(content='Paris', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-oss-120b' created=1769794689 object='chat.completion.chunk'\n",
      "id='chatcmpl-h5wnpl9em8hja7hgsvrk7' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' is', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-oss-120b' created=1769794689 object='chat.completion.chunk'\n",
      "id='chatcmpl-h5wnpl9em8hja7hgsvrk7' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' the', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-oss-120b' created=1769794689 object='chat.completion.chunk'\n",
      "id='chatcmpl-h5wnpl9em8hja7hgsvrk7' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' capital', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-oss-120b' created=1769794689 object='chat.completion.chunk'\n",
      "id='chatcmpl-h5wnpl9em8hja7hgsvrk7' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' city', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-oss-120b' created=1769794689 object='chat.completion.chunk'\n",
      "id='chatcmpl-h5wnpl9em8hja7hgsvrk7' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' of', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-oss-120b' created=1769794689 object='chat.completion.chunk'\n",
      "id='chatcmpl-h5wnpl9em8hja7hgsvrk7' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' France', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-oss-120b' created=1769794689 object='chat.completion.chunk'\n",
      "id='chatcmpl-h5wnpl9em8hja7hgsvrk7' choices=[StreamChoice(index=0, delta=DeltaMessage(content='.', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-oss-120b' created=1769794689 object='chat.completion.chunk'\n",
      "id='chatcmpl-h5wnpl9em8hja7hgsvrk7' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='stop')] model='openai/gpt-oss-120b' created=1769794689 object='chat.completion.chunk'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for openrouter:\n",
      "id='gen-1769794662-0zj6SNZ8MIpdP2yIOpe2' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-4o' created=1769794662 object='chat.completion.chunk'\n",
      "id='gen-1769794662-0zj6SNZ8MIpdP2yIOpe2' choices=[StreamChoice(index=0, delta=DeltaMessage(content='The', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-4o' created=1769794662 object='chat.completion.chunk'\n",
      "id='gen-1769794662-0zj6SNZ8MIpdP2yIOpe2' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' capital', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-4o' created=1769794662 object='chat.completion.chunk'\n",
      "id='gen-1769794662-0zj6SNZ8MIpdP2yIOpe2' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' of', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-4o' created=1769794662 object='chat.completion.chunk'\n",
      "id='gen-1769794662-0zj6SNZ8MIpdP2yIOpe2' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' France', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-4o' created=1769794662 object='chat.completion.chunk'\n",
      "id='gen-1769794662-0zj6SNZ8MIpdP2yIOpe2' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' is', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-4o' created=1769794662 object='chat.completion.chunk'\n",
      "id='gen-1769794662-0zj6SNZ8MIpdP2yIOpe2' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' Paris', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-4o' created=1769794662 object='chat.completion.chunk'\n",
      "id='gen-1769794662-0zj6SNZ8MIpdP2yIOpe2' choices=[StreamChoice(index=0, delta=DeltaMessage(content='.', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-4o' created=1769794662 object='chat.completion.chunk'\n",
      "id='gen-1769794662-0zj6SNZ8MIpdP2yIOpe2' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='stop')] model='openai/gpt-4o' created=1769794662 object='chat.completion.chunk'\n",
      "id='gen-1769794662-0zj6SNZ8MIpdP2yIOpe2' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-4o' created=1769794662 object='chat.completion.chunk'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for openai:\n",
      "id='chatcmpl-D3mj9Z01aHjpzJ8nC1JFn8Cc39lnx' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-5-mini-2025-08-07' created=1769794663 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mj9Z01aHjpzJ8nC1JFn8Cc39lnx' choices=[StreamChoice(index=0, delta=DeltaMessage(content='The', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-5-mini-2025-08-07' created=1769794663 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mj9Z01aHjpzJ8nC1JFn8Cc39lnx' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' capital', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-5-mini-2025-08-07' created=1769794663 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mj9Z01aHjpzJ8nC1JFn8Cc39lnx' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' of', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-5-mini-2025-08-07' created=1769794663 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mj9Z01aHjpzJ8nC1JFn8Cc39lnx' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' France', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-5-mini-2025-08-07' created=1769794663 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mj9Z01aHjpzJ8nC1JFn8Cc39lnx' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' is', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-5-mini-2025-08-07' created=1769794663 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mj9Z01aHjpzJ8nC1JFn8Cc39lnx' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' Paris', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-5-mini-2025-08-07' created=1769794663 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mj9Z01aHjpzJ8nC1JFn8Cc39lnx' choices=[StreamChoice(index=0, delta=DeltaMessage(content='.', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-5-mini-2025-08-07' created=1769794663 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mj9Z01aHjpzJ8nC1JFn8Cc39lnx' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='stop')] model='gpt-5-mini-2025-08-07' created=1769794663 object='chat.completion.chunk'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for xai:\n",
      "id='2e5bc718-0ed1-b07f-0578-cef2832a5fa2' choices=[StreamChoice(index=0, delta=DeltaMessage(content='The', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='grok-3' created=1769794665 object='chat.completion.chunk'\n",
      "id='2e5bc718-0ed1-b07f-0578-cef2832a5fa2' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' capital', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='grok-3' created=1769794665 object='chat.completion.chunk'\n",
      "id='2e5bc718-0ed1-b07f-0578-cef2832a5fa2' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' of', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='grok-3' created=1769794665 object='chat.completion.chunk'\n",
      "id='2e5bc718-0ed1-b07f-0578-cef2832a5fa2' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' France', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='grok-3' created=1769794665 object='chat.completion.chunk'\n",
      "id='2e5bc718-0ed1-b07f-0578-cef2832a5fa2' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' is', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='grok-3' created=1769794665 object='chat.completion.chunk'\n",
      "id='2e5bc718-0ed1-b07f-0578-cef2832a5fa2' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' Paris', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='grok-3' created=1769794665 object='chat.completion.chunk'\n",
      "id='2e5bc718-0ed1-b07f-0578-cef2832a5fa2' choices=[StreamChoice(index=0, delta=DeltaMessage(content='.', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='grok-3' created=1769794665 object='chat.completion.chunk'\n",
      "id='2e5bc718-0ed1-b07f-0578-cef2832a5fa2' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='stop')] model='grok-3' created=1769794665 object='chat.completion.chunk'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for anthropic:\n",
      "Failed to process for anthropic: Anthropic API error: Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\n",
      "Results for groq:\n",
      "id='chatcmpl-18942be9-7b71-4daa-8d4f-13a4707228b9' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='llama-3.1-8b-instant' created=1769794666 object='chat.completion.chunk'\n",
      "id='chatcmpl-18942be9-7b71-4daa-8d4f-13a4707228b9' choices=[StreamChoice(index=0, delta=DeltaMessage(content='The', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='llama-3.1-8b-instant' created=1769794666 object='chat.completion.chunk'\n",
      "id='chatcmpl-18942be9-7b71-4daa-8d4f-13a4707228b9' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' capital', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='llama-3.1-8b-instant' created=1769794666 object='chat.completion.chunk'\n",
      "id='chatcmpl-18942be9-7b71-4daa-8d4f-13a4707228b9' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' of', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='llama-3.1-8b-instant' created=1769794666 object='chat.completion.chunk'\n",
      "id='chatcmpl-18942be9-7b71-4daa-8d4f-13a4707228b9' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' France', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='llama-3.1-8b-instant' created=1769794666 object='chat.completion.chunk'\n",
      "id='chatcmpl-18942be9-7b71-4daa-8d4f-13a4707228b9' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' is', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='llama-3.1-8b-instant' created=1769794666 object='chat.completion.chunk'\n",
      "id='chatcmpl-18942be9-7b71-4daa-8d4f-13a4707228b9' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' Paris', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='llama-3.1-8b-instant' created=1769794666 object='chat.completion.chunk'\n",
      "id='chatcmpl-18942be9-7b71-4daa-8d4f-13a4707228b9' choices=[StreamChoice(index=0, delta=DeltaMessage(content='.', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='llama-3.1-8b-instant' created=1769794666 object='chat.completion.chunk'\n",
      "id='chatcmpl-18942be9-7b71-4daa-8d4f-13a4707228b9' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='stop')] model='llama-3.1-8b-instant' created=1769794666 object='chat.completion.chunk'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for ollama:\n",
      "id='3c9ecec7-bf1d-44db-ab6a-c0253eda38be' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='037869b7-f0de-48ee-9b4d-6ed0839a3b50' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='e2aa5116-424f-444a-9faa-854c0ebb6c37' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='e4db542a-49ad-446b-830e-e6735f07efc5' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='617e8256-43e8-4b4a-b426-1559871201bd' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='7f4bab51-200d-454a-89c2-c83801d7801e' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='951c0a35-2712-426a-b68a-e3125dffadac' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='b2c91d9c-88eb-438d-9cbc-cebfbd6e3748' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='2974c47d-398b-43fd-830e-6be7e2574d76' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='27446d33-6517-49b9-a780-3186b5ac2f7e' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='6b319775-bf76-4c18-915f-67bb8748a2b8' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='eacb85c8-cb5e-4a8a-be14-797232f8f4ae' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='df2e9406-fd42-4f95-9dec-cafdbcf803ab' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='4db5288d-2f9f-4f36-9794-daee15f48ac4' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='feab841b-22ee-4245-bf4e-e8003ecf8c7f' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='978e5d40-6b7e-4dc1-ad9b-4997bca38954' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='68ee11e2-7e63-4f4d-af12-53070e330f20' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='2d368e0f-1b69-4114-b910-81c026891ac9' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='1be631bd-8a05-49fc-bb28-a004793ed580' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='4ba099b3-250a-43cb-8e99-e62e546697b3' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='0e4c1de0-7c4f-4113-b4ad-40a4966a0a4f' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='9f3bab25-14e2-4bb1-b3ae-eb25a24fc43e' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='d8f3c24f-1e99-4809-b10d-c11e3752f2c0' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='ea7bdaa2-94f6-45da-aa83-5ef092564cf2' choices=[StreamChoice(index=0, delta=DeltaMessage(content='The', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='1ce5c2a8-ad80-4f26-89d8-2deab74f171d' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' capital', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='3cc7d631-1373-4244-a10f-743cfcf10762' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' of', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='81b0d691-85cf-414b-aa2b-50e276205fe9' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' France', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='bf2dcf8f-e5fe-4660-a610-b16914910a6c' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' is', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='db0e26ae-69c3-44f9-842a-da84bc6fa4a8' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' **', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='24883919-ea7e-451a-8287-b5e44fed5b84' choices=[StreamChoice(index=0, delta=DeltaMessage(content='Paris', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='114dd41a-aec2-4946-a3e0-f4d389c3e633' choices=[StreamChoice(index=0, delta=DeltaMessage(content='**', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='a911350b-42ad-4d01-bd88-d8ad933e579f' choices=[StreamChoice(index=0, delta=DeltaMessage(content='.', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "id='5f6892b7-1ef6-42ba-b40b-e3080cdd51f6' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='stop')] model='gpt-oss:20b' created=1769794696 object='chat.completion.chunk'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for google:\n",
      "id='2aa200e6-e78b-4c55-ad1b-bc3de2e0f5d5' choices=[StreamChoice(index=0, delta=DeltaMessage(content='The', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gemini-2.0-flash' created=1769794697 object='chat.completion.chunk'\n",
      "id='1be9bdcd-572b-4be9-bbde-9e0ef7cf63ba' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' capital of France', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gemini-2.0-flash' created=1769794697 object='chat.completion.chunk'\n",
      "id='bbb12c62-81ea-4f74-93dd-3d280bf72bea' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' is Paris.\\n', role='assistant', function_call=None, tool_calls=None), finish_reason='stop')] model='gemini-2.0-flash' created=1769794697 object='chat.completion.chunk'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for google:\n",
      "id='f41e1661-f717-47b2-898e-1a889473edd3' choices=[StreamChoice(index=0, delta=DeltaMessage(content='The capital of France is **Paris**.', role='assistant', function_call=None, tool_calls=None), finish_reason='stop')] model='gemini-2.5-flash' created=1769794697 object='chat.completion.chunk'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for azure:\n",
      "id='' choices=[] model='' created=0 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mjFJeCii6ZM3Xf1Y3mdw4j2qsat' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1769794669 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mjFJeCii6ZM3Xf1Y3mdw4j2qsat' choices=[StreamChoice(index=0, delta=DeltaMessage(content='The', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1769794669 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mjFJeCii6ZM3Xf1Y3mdw4j2qsat' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' capital', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1769794669 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mjFJeCii6ZM3Xf1Y3mdw4j2qsat' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' of', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1769794669 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mjFJeCii6ZM3Xf1Y3mdw4j2qsat' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' France', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1769794669 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mjFJeCii6ZM3Xf1Y3mdw4j2qsat' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' is', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1769794669 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mjFJeCii6ZM3Xf1Y3mdw4j2qsat' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' Paris', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1769794669 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mjFJeCii6ZM3Xf1Y3mdw4j2qsat' choices=[StreamChoice(index=0, delta=DeltaMessage(content='.', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1769794669 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mjFJeCii6ZM3Xf1Y3mdw4j2qsat' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='stop')] model='o4-mini-2025-04-16' created=1769794669 object='chat.completion.chunk'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for mistral:\n",
      "id='b4efe0cee9d8474bb6310c362aa0f6d3' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='mistral-large-latest' created=1769794670 object='chat.completion.chunk'\n",
      "id='b4efe0cee9d8474bb6310c362aa0f6d3' choices=[StreamChoice(index=0, delta=DeltaMessage(content='The', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='mistral-large-latest' created=1769794670 object='chat.completion.chunk'\n",
      "id='b4efe0cee9d8474bb6310c362aa0f6d3' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' capital of France', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='mistral-large-latest' created=1769794670 object='chat.completion.chunk'\n",
      "id='b4efe0cee9d8474bb6310c362aa0f6d3' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' is **Paris', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='mistral-large-latest' created=1769794670 object='chat.completion.chunk'\n",
      "id='b4efe0cee9d8474bb6310c362aa0f6d3' choices=[StreamChoice(index=0, delta=DeltaMessage(content='**.', role='assistant', function_call=None, tool_calls=None), finish_reason='stop')] model='mistral-large-latest' created=1769794670 object='chat.completion.chunk'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for deepseek:\n",
      "id='c3adbe0d-f8ee-4e23-8a68-756a2b65ed28' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='deepseek-chat' created=1769794671 object='chat.completion.chunk'\n",
      "id='c3adbe0d-f8ee-4e23-8a68-756a2b65ed28' choices=[StreamChoice(index=0, delta=DeltaMessage(content='The', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='deepseek-chat' created=1769794671 object='chat.completion.chunk'\n",
      "id='c3adbe0d-f8ee-4e23-8a68-756a2b65ed28' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' capital', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='deepseek-chat' created=1769794671 object='chat.completion.chunk'\n",
      "id='c3adbe0d-f8ee-4e23-8a68-756a2b65ed28' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' of', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='deepseek-chat' created=1769794671 object='chat.completion.chunk'\n",
      "id='c3adbe0d-f8ee-4e23-8a68-756a2b65ed28' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' France', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='deepseek-chat' created=1769794671 object='chat.completion.chunk'\n",
      "id='c3adbe0d-f8ee-4e23-8a68-756a2b65ed28' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' is', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='deepseek-chat' created=1769794671 object='chat.completion.chunk'\n",
      "id='c3adbe0d-f8ee-4e23-8a68-756a2b65ed28' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' **', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='deepseek-chat' created=1769794671 object='chat.completion.chunk'\n",
      "id='c3adbe0d-f8ee-4e23-8a68-756a2b65ed28' choices=[StreamChoice(index=0, delta=DeltaMessage(content='Paris', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='deepseek-chat' created=1769794671 object='chat.completion.chunk'\n",
      "id='c3adbe0d-f8ee-4e23-8a68-756a2b65ed28' choices=[StreamChoice(index=0, delta=DeltaMessage(content='**.', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='deepseek-chat' created=1769794671 object='chat.completion.chunk'\n",
      "id='c3adbe0d-f8ee-4e23-8a68-756a2b65ed28' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='stop')] model='deepseek-chat' created=1769794671 object='chat.completion.chunk'\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for name, llm in models:\n",
    "    try:\n",
    "        print(f\"Results for {llm.provider}:\")\n",
    "        result = llm.chat_complete(\n",
    "            messages, stream=True\n",
    "        )\n",
    "\n",
    "        for chunk in result:\n",
    "            print(chunk)\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    except Exception as e:\n",
    "            print(f\"Failed to process for {name}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for openai-compatible:\n",
      "id='chatcmpl-1t5i8sajfnbmp5xmwpslph' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-oss-120b' created=1769794701 object='chat.completion.chunk'\n",
      "id='chatcmpl-1t5i8sajfnbmp5xmwpslph' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-oss-120b' created=1769794701 object='chat.completion.chunk'\n",
      "id='chatcmpl-1t5i8sajfnbmp5xmwpslph' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-oss-120b' created=1769794701 object='chat.completion.chunk'\n",
      "id='chatcmpl-1t5i8sajfnbmp5xmwpslph' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-oss-120b' created=1769794701 object='chat.completion.chunk'\n",
      "id='chatcmpl-1t5i8sajfnbmp5xmwpslph' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-oss-120b' created=1769794701 object='chat.completion.chunk'\n",
      "id='chatcmpl-1t5i8sajfnbmp5xmwpslph' choices=[StreamChoice(index=0, delta=DeltaMessage(content='Paris', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-oss-120b' created=1769794701 object='chat.completion.chunk'\n",
      "id='chatcmpl-1t5i8sajfnbmp5xmwpslph' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' is', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-oss-120b' created=1769794701 object='chat.completion.chunk'\n",
      "id='chatcmpl-1t5i8sajfnbmp5xmwpslph' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' the', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-oss-120b' created=1769794701 object='chat.completion.chunk'\n",
      "id='chatcmpl-1t5i8sajfnbmp5xmwpslph' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' capital', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-oss-120b' created=1769794701 object='chat.completion.chunk'\n",
      "id='chatcmpl-1t5i8sajfnbmp5xmwpslph' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' city', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-oss-120b' created=1769794701 object='chat.completion.chunk'\n",
      "id='chatcmpl-1t5i8sajfnbmp5xmwpslph' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' of', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-oss-120b' created=1769794701 object='chat.completion.chunk'\n",
      "id='chatcmpl-1t5i8sajfnbmp5xmwpslph' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' France', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-oss-120b' created=1769794701 object='chat.completion.chunk'\n",
      "id='chatcmpl-1t5i8sajfnbmp5xmwpslph' choices=[StreamChoice(index=0, delta=DeltaMessage(content='.', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-oss-120b' created=1769794701 object='chat.completion.chunk'\n",
      "id='chatcmpl-1t5i8sajfnbmp5xmwpslph' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='stop')] model='openai/gpt-oss-120b' created=1769794701 object='chat.completion.chunk'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for openrouter:\n",
      "id='gen-1769794674-VjoOIr6AyY6YZ8GTi7qS' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-4o' created=1769794674 object='chat.completion.chunk'\n",
      "id='gen-1769794674-VjoOIr6AyY6YZ8GTi7qS' choices=[StreamChoice(index=0, delta=DeltaMessage(content='The', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-4o' created=1769794674 object='chat.completion.chunk'\n",
      "id='gen-1769794674-VjoOIr6AyY6YZ8GTi7qS' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' capital', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-4o' created=1769794674 object='chat.completion.chunk'\n",
      "id='gen-1769794674-VjoOIr6AyY6YZ8GTi7qS' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' of', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-4o' created=1769794674 object='chat.completion.chunk'\n",
      "id='gen-1769794674-VjoOIr6AyY6YZ8GTi7qS' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' France', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-4o' created=1769794674 object='chat.completion.chunk'\n",
      "id='gen-1769794674-VjoOIr6AyY6YZ8GTi7qS' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' is', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-4o' created=1769794674 object='chat.completion.chunk'\n",
      "id='gen-1769794674-VjoOIr6AyY6YZ8GTi7qS' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' Paris', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-4o' created=1769794674 object='chat.completion.chunk'\n",
      "id='gen-1769794674-VjoOIr6AyY6YZ8GTi7qS' choices=[StreamChoice(index=0, delta=DeltaMessage(content='.', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-4o' created=1769794674 object='chat.completion.chunk'\n",
      "id='gen-1769794674-VjoOIr6AyY6YZ8GTi7qS' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='stop')] model='openai/gpt-4o' created=1769794674 object='chat.completion.chunk'\n",
      "id='gen-1769794674-VjoOIr6AyY6YZ8GTi7qS' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='openai/gpt-4o' created=1769794674 object='chat.completion.chunk'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for openai:\n",
      "id='chatcmpl-D3mjLnJCdmpICHksTuhTlNJhzgzAd' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-5-mini-2025-08-07' created=1769794675 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mjLnJCdmpICHksTuhTlNJhzgzAd' choices=[StreamChoice(index=0, delta=DeltaMessage(content='The', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-5-mini-2025-08-07' created=1769794675 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mjLnJCdmpICHksTuhTlNJhzgzAd' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' capital', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-5-mini-2025-08-07' created=1769794675 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mjLnJCdmpICHksTuhTlNJhzgzAd' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' of', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-5-mini-2025-08-07' created=1769794675 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mjLnJCdmpICHksTuhTlNJhzgzAd' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' France', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-5-mini-2025-08-07' created=1769794675 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mjLnJCdmpICHksTuhTlNJhzgzAd' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' is', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-5-mini-2025-08-07' created=1769794675 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mjLnJCdmpICHksTuhTlNJhzgzAd' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' Paris', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-5-mini-2025-08-07' created=1769794675 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mjLnJCdmpICHksTuhTlNJhzgzAd' choices=[StreamChoice(index=0, delta=DeltaMessage(content='.', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-5-mini-2025-08-07' created=1769794675 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mjLnJCdmpICHksTuhTlNJhzgzAd' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='stop')] model='gpt-5-mini-2025-08-07' created=1769794675 object='chat.completion.chunk'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for xai:\n",
      "id='db0f757a-5d9b-627c-d086-1c0759f52a57' choices=[StreamChoice(index=0, delta=DeltaMessage(content='The', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='grok-3' created=1769794677 object='chat.completion.chunk'\n",
      "id='db0f757a-5d9b-627c-d086-1c0759f52a57' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' capital', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='grok-3' created=1769794678 object='chat.completion.chunk'\n",
      "id='db0f757a-5d9b-627c-d086-1c0759f52a57' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' of', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='grok-3' created=1769794678 object='chat.completion.chunk'\n",
      "id='db0f757a-5d9b-627c-d086-1c0759f52a57' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' France', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='grok-3' created=1769794678 object='chat.completion.chunk'\n",
      "id='db0f757a-5d9b-627c-d086-1c0759f52a57' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' is', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='grok-3' created=1769794678 object='chat.completion.chunk'\n",
      "id='db0f757a-5d9b-627c-d086-1c0759f52a57' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' Paris', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='grok-3' created=1769794678 object='chat.completion.chunk'\n",
      "id='db0f757a-5d9b-627c-d086-1c0759f52a57' choices=[StreamChoice(index=0, delta=DeltaMessage(content='.', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='grok-3' created=1769794678 object='chat.completion.chunk'\n",
      "id='db0f757a-5d9b-627c-d086-1c0759f52a57' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='stop')] model='grok-3' created=1769794679 object='chat.completion.chunk'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for anthropic:\n",
      "Failed to process for anthropic: Anthropic API error: Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\n",
      "Results for groq:\n",
      "id='chatcmpl-dd11beba-9452-454e-9a46-42de85f2bf39' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='llama-3.1-8b-instant' created=1769794679 object='chat.completion.chunk'\n",
      "id='chatcmpl-dd11beba-9452-454e-9a46-42de85f2bf39' choices=[StreamChoice(index=0, delta=DeltaMessage(content='The', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='llama-3.1-8b-instant' created=1769794679 object='chat.completion.chunk'\n",
      "id='chatcmpl-dd11beba-9452-454e-9a46-42de85f2bf39' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' capital', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='llama-3.1-8b-instant' created=1769794679 object='chat.completion.chunk'\n",
      "id='chatcmpl-dd11beba-9452-454e-9a46-42de85f2bf39' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' of', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='llama-3.1-8b-instant' created=1769794679 object='chat.completion.chunk'\n",
      "id='chatcmpl-dd11beba-9452-454e-9a46-42de85f2bf39' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' France', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='llama-3.1-8b-instant' created=1769794679 object='chat.completion.chunk'\n",
      "id='chatcmpl-dd11beba-9452-454e-9a46-42de85f2bf39' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' is', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='llama-3.1-8b-instant' created=1769794679 object='chat.completion.chunk'\n",
      "id='chatcmpl-dd11beba-9452-454e-9a46-42de85f2bf39' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' Paris', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='llama-3.1-8b-instant' created=1769794679 object='chat.completion.chunk'\n",
      "id='chatcmpl-dd11beba-9452-454e-9a46-42de85f2bf39' choices=[StreamChoice(index=0, delta=DeltaMessage(content='.', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='llama-3.1-8b-instant' created=1769794679 object='chat.completion.chunk'\n",
      "id='chatcmpl-dd11beba-9452-454e-9a46-42de85f2bf39' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='stop')] model='llama-3.1-8b-instant' created=1769794679 object='chat.completion.chunk'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for ollama:\n",
      "id='b06b3c01-ce29-4c8f-b181-aae481f1c83a' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "id='d1cd7351-e0ac-4375-a422-95650890dd2c' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "id='fb680cce-0fdf-47ef-852c-43f7ebc92098' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "id='108f67d2-97ac-40ca-8e01-cbe97c2934d6' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "id='87af95e1-fa39-434f-94be-a4f22d601cf7' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "id='1316afe4-ac83-4879-a69d-c3ff57d08b04' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "id='e8fb2ae0-05a3-46b8-9ee8-d414fbced58a' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "id='4c08fbe5-2fa9-45b3-ad3c-72e8b7c178d7' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "id='645d467a-c77f-4923-81d4-b7210204e302' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "id='bf5cd12b-e75f-4ef9-b8e4-c3ab6058bcc7' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "id='b1036b45-bbec-4b81-a800-e2f66165774d' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "id='63efe753-10d0-44a0-8195-bbda6143a156' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "id='acc2a764-af1a-4b79-9abc-6b7ccb39114d' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "id='658fbcf9-bf39-4193-ac6a-5dc6692e897a' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "id='75c1cff3-8a8b-448f-9b7e-0bac7ce4bb29' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "id='305dc754-2a94-42e5-847a-1eb6996a3859' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "id='09dca794-3d0d-4d70-a156-2e673c023638' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "id='85a6fef5-244d-42b7-96fa-6ecdb74c7885' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "id='e6788af6-5504-4edc-ae84-69f9c82e2040' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "id='f6b9ada7-8769-4aa9-8524-94a5d6152b96' choices=[StreamChoice(index=0, delta=DeltaMessage(content='The', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "id='9f47985a-c0a2-4f62-bcb7-33d29c52d524' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' capital', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "id='f90e7b26-3980-4f3d-8c68-113059800a2b' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' of', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "id='1e1afaa6-c143-40a0-a6c3-a3d83b5e2341' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' France', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "id='0668e2fe-3571-4059-a6dc-8e01bdbf91eb' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' is', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "id='0e08ba90-7661-4dec-90ae-125b639c30bf' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' **', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "id='f872fb6e-0b70-4843-8f46-25ec647a2d3b' choices=[StreamChoice(index=0, delta=DeltaMessage(content='Paris', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "id='966c22a0-62af-4cbb-9fee-3b8e341d8fc0' choices=[StreamChoice(index=0, delta=DeltaMessage(content='**', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "id='903bf941-0142-4242-9581-04f9c74b8df0' choices=[StreamChoice(index=0, delta=DeltaMessage(content='.', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "id='6579988b-ed94-495d-bc26-692514a86704' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='stop')] model='gpt-oss:20b' created=1769794709 object='chat.completion.chunk'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for google:\n",
      "id='0f707081-2029-48c1-9a8a-fc6d0d53eec4' choices=[StreamChoice(index=0, delta=DeltaMessage(content='The', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gemini-2.0-flash' created=1769794710 object='chat.completion.chunk'\n",
      "id='c8ce18d5-3fa6-41b7-8417-392e64ab1804' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' capital of France', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='gemini-2.0-flash' created=1769794710 object='chat.completion.chunk'\n",
      "id='496291fc-25fc-41df-846f-4ef43d5e08b1' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' is Paris.\\n', role='assistant', function_call=None, tool_calls=None), finish_reason='stop')] model='gemini-2.0-flash' created=1769794710 object='chat.completion.chunk'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for google:\n",
      "id='84c78024-f25d-49c9-9a3c-e0f72fda8b94' choices=[StreamChoice(index=0, delta=DeltaMessage(content='The capital of France is **Paris**.', role='assistant', function_call=None, tool_calls=None), finish_reason='stop')] model='gemini-2.5-flash' created=1769794711 object='chat.completion.chunk'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for azure:\n",
      "id='' choices=[] model='' created=0 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mjSPT0WDfvaIbnRArfntD8xHZDM' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1769794682 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mjSPT0WDfvaIbnRArfntD8xHZDM' choices=[StreamChoice(index=0, delta=DeltaMessage(content='The', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1769794682 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mjSPT0WDfvaIbnRArfntD8xHZDM' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' capital', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1769794682 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mjSPT0WDfvaIbnRArfntD8xHZDM' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' of', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1769794682 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mjSPT0WDfvaIbnRArfntD8xHZDM' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' France', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1769794682 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mjSPT0WDfvaIbnRArfntD8xHZDM' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' is', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1769794682 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mjSPT0WDfvaIbnRArfntD8xHZDM' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' Paris', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1769794682 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mjSPT0WDfvaIbnRArfntD8xHZDM' choices=[StreamChoice(index=0, delta=DeltaMessage(content='.', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='o4-mini-2025-04-16' created=1769794682 object='chat.completion.chunk'\n",
      "id='chatcmpl-D3mjSPT0WDfvaIbnRArfntD8xHZDM' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='stop')] model='o4-mini-2025-04-16' created=1769794682 object='chat.completion.chunk'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for mistral:\n",
      "id='a4390aaf887e4d938a0467ccdd7d6afb' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='mistral-large-latest' created=1769794683 object='chat.completion.chunk'\n",
      "id='a4390aaf887e4d938a0467ccdd7d6afb' choices=[StreamChoice(index=0, delta=DeltaMessage(content='The', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='mistral-large-latest' created=1769794683 object='chat.completion.chunk'\n",
      "id='a4390aaf887e4d938a0467ccdd7d6afb' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' capital of France', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='mistral-large-latest' created=1769794683 object='chat.completion.chunk'\n",
      "id='a4390aaf887e4d938a0467ccdd7d6afb' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' is **Paris', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='mistral-large-latest' created=1769794683 object='chat.completion.chunk'\n",
      "id='a4390aaf887e4d938a0467ccdd7d6afb' choices=[StreamChoice(index=0, delta=DeltaMessage(content='**.', role='assistant', function_call=None, tool_calls=None), finish_reason='stop')] model='mistral-large-latest' created=1769794683 object='chat.completion.chunk'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for deepseek:\n",
      "id='7ca9b527-2dbb-431b-86f2-6bbc55a5801f' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='deepseek-chat' created=1769794684 object='chat.completion.chunk'\n",
      "id='7ca9b527-2dbb-431b-86f2-6bbc55a5801f' choices=[StreamChoice(index=0, delta=DeltaMessage(content='The', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='deepseek-chat' created=1769794684 object='chat.completion.chunk'\n",
      "id='7ca9b527-2dbb-431b-86f2-6bbc55a5801f' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' capital', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='deepseek-chat' created=1769794684 object='chat.completion.chunk'\n",
      "id='7ca9b527-2dbb-431b-86f2-6bbc55a5801f' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' of', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='deepseek-chat' created=1769794684 object='chat.completion.chunk'\n",
      "id='7ca9b527-2dbb-431b-86f2-6bbc55a5801f' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' France', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='deepseek-chat' created=1769794684 object='chat.completion.chunk'\n",
      "id='7ca9b527-2dbb-431b-86f2-6bbc55a5801f' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' is', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='deepseek-chat' created=1769794684 object='chat.completion.chunk'\n",
      "id='7ca9b527-2dbb-431b-86f2-6bbc55a5801f' choices=[StreamChoice(index=0, delta=DeltaMessage(content=' **', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='deepseek-chat' created=1769794684 object='chat.completion.chunk'\n",
      "id='7ca9b527-2dbb-431b-86f2-6bbc55a5801f' choices=[StreamChoice(index=0, delta=DeltaMessage(content='Paris', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='deepseek-chat' created=1769794684 object='chat.completion.chunk'\n",
      "id='7ca9b527-2dbb-431b-86f2-6bbc55a5801f' choices=[StreamChoice(index=0, delta=DeltaMessage(content='**.', role='assistant', function_call=None, tool_calls=None), finish_reason='None')] model='deepseek-chat' created=1769794684 object='chat.completion.chunk'\n",
      "id='7ca9b527-2dbb-431b-86f2-6bbc55a5801f' choices=[StreamChoice(index=0, delta=DeltaMessage(content='', role='assistant', function_call=None, tool_calls=None), finish_reason='stop')] model='deepseek-chat' created=1769794684 object='chat.completion.chunk'\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for name, llm in models:\n",
    "    try:\n",
    "        print(f\"Results for {llm.provider}:\")\n",
    "        result = await llm.achat_complete(\n",
    "            messages, stream=True\n",
    "        )\n",
    "\n",
    "        async for chunk in result:\n",
    "            print(chunk)\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process for {name}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synchronous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for openai-compatible:\n",
      "Paris is the capital city of France.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for openrouter:\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for openai:\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for xai:\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for anthropic:\n",
      "Failed to process for anthropic: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}, 'request_id': 'req_011CXdyCwtpqmXRDf2WxgcxK'}\n",
      "Results for groq:\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for ollama:\n",
      "The capital of France is **Paris**.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for google:\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for google:\n",
      "The capital of France is **Paris**.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for azure:\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for mistral:\n",
      "The capital of France is **Paris**.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for deepseek:\n",
      "The capital of France is **Paris**.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for name, llm in models:\n",
    "    try:\n",
    "        print(f\"Results for {llm.provider}:\")\n",
    "        model = llm.to_langchain()\n",
    "        response = model.invoke(messages)\n",
    "        print(response.content)\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process for {name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for openai-compatible:\n",
      "The capital of France is **Paris**.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for openrouter:\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for openai:\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for xai:\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for anthropic:\n",
      "Failed to process for anthropic: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}, 'request_id': 'req_011CXdyDxst7ZMyFtEKgEmGY'}\n",
      "Results for groq:\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for ollama:\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for google:\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for google:\n",
      "The capital of France is **Paris**.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for azure:\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for mistral:\n",
      "The capital of France is **Paris**.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for deepseek:\n",
      "The capital of France is **Paris**.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for name, llm in models:\n",
    "    try:\n",
    "        print(f\"Results for {llm.provider}:\")\n",
    "        model = llm.to_langchain()\n",
    "        response = await model.ainvoke(messages)\n",
    "        print(response.content)\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process for {name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for openai-compatible:\n",
      "content='' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-a506-7c21-94a7-58388df2b10d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-a506-7c21-94a7-58388df2b10d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-a506-7c21-94a7-58388df2b10d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-a506-7c21-94a7-58388df2b10d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-a506-7c21-94a7-58388df2b10d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='Paris' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-a506-7c21-94a7-58388df2b10d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' is' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-a506-7c21-94a7-58388df2b10d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' the' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-a506-7c21-94a7-58388df2b10d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' capital' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-a506-7c21-94a7-58388df2b10d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' city' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-a506-7c21-94a7-58388df2b10d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' of' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-a506-7c21-94a7-58388df2b10d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' France' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-a506-7c21-94a7-58388df2b10d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='.' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-a506-7c21-94a7-58388df2b10d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'openai/gpt-oss-120b', 'model_provider': 'openai'} id='lc_run--019c0ffc-a506-7c21-94a7-58388df2b10d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-a506-7c21-94a7-58388df2b10d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[] chunk_position='last'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for openrouter:\n",
      "content='' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-ab20-7c50-914e-114775ded484' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='The' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-ab20-7c50-914e-114775ded484' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' capital' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-ab20-7c50-914e-114775ded484' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' of' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-ab20-7c50-914e-114775ded484' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' France' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-ab20-7c50-914e-114775ded484' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' is' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-ab20-7c50-914e-114775ded484' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' Paris' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-ab20-7c50-914e-114775ded484' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='.' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-ab20-7c50-914e-114775ded484' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'openai/gpt-4o', 'system_fingerprint': 'fp_fa7f5b168b', 'model_provider': 'openai'} id='lc_run--019c0ffc-ab20-7c50-914e-114775ded484' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-ab20-7c50-914e-114775ded484' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 23, 'output_tokens': 7, 'total_tokens': 30, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}} tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-ab20-7c50-914e-114775ded484' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[] chunk_position='last'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for openai:\n",
      "content='' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-ae48-70b2-9665-e0d19b35b4ed' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='The' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-ae48-70b2-9665-e0d19b35b4ed' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' capital' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-ae48-70b2-9665-e0d19b35b4ed' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' of' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-ae48-70b2-9665-e0d19b35b4ed' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' France' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-ae48-70b2-9665-e0d19b35b4ed' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' is' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-ae48-70b2-9665-e0d19b35b4ed' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' Paris' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-ae48-70b2-9665-e0d19b35b4ed' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='.' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-ae48-70b2-9665-e0d19b35b4ed' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-5-mini-2025-08-07', 'service_tier': 'default', 'model_provider': 'openai'} id='lc_run--019c0ffc-ae48-70b2-9665-e0d19b35b4ed' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-ae48-70b2-9665-e0d19b35b4ed' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[] chunk_position='last'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for xai:\n",
      "content='The' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-b414-7ce2-a27e-d0e1de980253' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' capital' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-b414-7ce2-a27e-d0e1de980253' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' of' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-b414-7ce2-a27e-d0e1de980253' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' France' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-b414-7ce2-a27e-d0e1de980253' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' is' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-b414-7ce2-a27e-d0e1de980253' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' Paris' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-b414-7ce2-a27e-d0e1de980253' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='.' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-b414-7ce2-a27e-d0e1de980253' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'grok-3', 'system_fingerprint': 'fp_a50f881eb7', 'model_provider': 'openai'} id='lc_run--019c0ffc-b414-7ce2-a27e-d0e1de980253' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-b414-7ce2-a27e-d0e1de980253' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[] chunk_position='last'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for anthropic:\n",
      "Failed to process for anthropic: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}, 'request_id': 'req_011CXdyEwvrpDR5Y5Y1oq8nm'}\n",
      "Results for groq:\n",
      "content='' additional_kwargs={} response_metadata={'model_provider': 'groq'} id='lc_run--019c0ffc-beae-7ef0-96b0-145eeb104132' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='The' additional_kwargs={} response_metadata={'model_provider': 'groq'} id='lc_run--019c0ffc-beae-7ef0-96b0-145eeb104132' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' capital' additional_kwargs={} response_metadata={'model_provider': 'groq'} id='lc_run--019c0ffc-beae-7ef0-96b0-145eeb104132' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' of' additional_kwargs={} response_metadata={'model_provider': 'groq'} id='lc_run--019c0ffc-beae-7ef0-96b0-145eeb104132' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' France' additional_kwargs={} response_metadata={'model_provider': 'groq'} id='lc_run--019c0ffc-beae-7ef0-96b0-145eeb104132' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' is' additional_kwargs={} response_metadata={'model_provider': 'groq'} id='lc_run--019c0ffc-beae-7ef0-96b0-145eeb104132' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' Paris' additional_kwargs={} response_metadata={'model_provider': 'groq'} id='lc_run--019c0ffc-beae-7ef0-96b0-145eeb104132' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='.' additional_kwargs={} response_metadata={'model_provider': 'groq'} id='lc_run--019c0ffc-beae-7ef0-96b0-145eeb104132' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_6b5c123dd9', 'service_tier': 'on_demand'} id='lc_run--019c0ffc-beae-7ef0-96b0-145eeb104132' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 48, 'output_tokens': 8, 'total_tokens': 56} tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-beae-7ef0-96b0-145eeb104132' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[] chunk_position='last'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for ollama:\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-bfe4-7ad3-b052-18a4d911e960' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-bfe4-7ad3-b052-18a4d911e960' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-bfe4-7ad3-b052-18a4d911e960' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-bfe4-7ad3-b052-18a4d911e960' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-bfe4-7ad3-b052-18a4d911e960' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-bfe4-7ad3-b052-18a4d911e960' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-bfe4-7ad3-b052-18a4d911e960' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-bfe4-7ad3-b052-18a4d911e960' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-bfe4-7ad3-b052-18a4d911e960' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-bfe4-7ad3-b052-18a4d911e960' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-bfe4-7ad3-b052-18a4d911e960' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-bfe4-7ad3-b052-18a4d911e960' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-bfe4-7ad3-b052-18a4d911e960' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-bfe4-7ad3-b052-18a4d911e960' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='The' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-bfe4-7ad3-b052-18a4d911e960' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' capital' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-bfe4-7ad3-b052-18a4d911e960' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' of' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-bfe4-7ad3-b052-18a4d911e960' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' France' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-bfe4-7ad3-b052-18a4d911e960' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' is' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-bfe4-7ad3-b052-18a4d911e960' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' **' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-bfe4-7ad3-b052-18a4d911e960' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='Paris' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-bfe4-7ad3-b052-18a4d911e960' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='**' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-bfe4-7ad3-b052-18a4d911e960' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='.' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-bfe4-7ad3-b052-18a4d911e960' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={'model': 'gpt-oss:20b', 'created_at': '2026-01-30T17:38:40.218217553Z', 'done': True, 'done_reason': 'stop', 'total_duration': 800447301, 'load_duration': 114184405, 'prompt_eval_count': 87, 'prompt_eval_duration': 20961570, 'eval_count': 33, 'eval_duration': 650801402, 'logprobs': None, 'model_name': 'gpt-oss:20b', 'model_provider': 'ollama'} id='lc_run--019c0ffc-bfe4-7ad3-b052-18a4d911e960' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 87, 'output_tokens': 33, 'total_tokens': 120} tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-bfe4-7ad3-b052-18a4d911e960' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[] chunk_position='last'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for google:\n",
      "content='The' additional_kwargs={} response_metadata={'safety_ratings': [], 'model_provider': 'google_genai'} id='lc_run--019c0ffc-c32f-79c3-aa3c-aad01df8568e' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 15, 'output_tokens': 0, 'total_tokens': 15, 'input_token_details': {'cache_read': 0}} tool_call_chunks=[]\n",
      "content=' capital of France' additional_kwargs={} response_metadata={'safety_ratings': [], 'model_provider': 'google_genai'} id='lc_run--019c0ffc-c32f-79c3-aa3c-aad01df8568e' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0, 'input_tokens': 0} tool_call_chunks=[]\n",
      "content=' is Paris.\\n' additional_kwargs={} response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': [], 'model_provider': 'google_genai'} id='lc_run--019c0ffc-c32f-79c3-aa3c-aad01df8568e' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_token_details': {'cache_read': 0}, 'total_tokens': 7, 'output_tokens': 8, 'input_tokens': -1} tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-c32f-79c3-aa3c-aad01df8568e' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[] chunk_position='last'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for google:\n",
      "content='The capital of France is **Paris**.' additional_kwargs={} response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'} id='lc_run--019c0ffc-c5cb-7511-8d23-75fe46249ea8' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 15, 'output_tokens': 30, 'total_tokens': 45, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 22}} tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-c5cb-7511-8d23-75fe46249ea8' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[] chunk_position='last'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for azure:\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-c93e-7b63-b582-e712a2923f29' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-c93e-7b63-b582-e712a2923f29' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='The' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-c93e-7b63-b582-e712a2923f29' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' capital' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-c93e-7b63-b582-e712a2923f29' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' of' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-c93e-7b63-b582-e712a2923f29' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' France' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-c93e-7b63-b582-e712a2923f29' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' is' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-c93e-7b63-b582-e712a2923f29' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' Paris' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-c93e-7b63-b582-e712a2923f29' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='.' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-c93e-7b63-b582-e712a2923f29' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'o4-mini-2025-04-16', 'model_provider': 'openai'} id='lc_run--019c0ffc-c93e-7b63-b582-e712a2923f29' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-c93e-7b63-b582-e712a2923f29' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[] chunk_position='last'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for mistral:\n",
      "content='' additional_kwargs={} response_metadata={'model_provider': 'mistralai'} id='lc_run--019c0ffc-d188-7442-934a-1417836062c3' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='The' additional_kwargs={} response_metadata={'model_provider': 'mistralai'} id='lc_run--019c0ffc-d188-7442-934a-1417836062c3' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' capital of France' additional_kwargs={} response_metadata={'model_provider': 'mistralai'} id='lc_run--019c0ffc-d188-7442-934a-1417836062c3' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' is **Paris' additional_kwargs={} response_metadata={'model_provider': 'mistralai'} id='lc_run--019c0ffc-d188-7442-934a-1417836062c3' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='**.' additional_kwargs={} response_metadata={'model_provider': 'mistralai', 'model_name': 'mistral-large-latest', 'finish_reason': 'stop'} id='lc_run--019c0ffc-d188-7442-934a-1417836062c3' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 18, 'output_tokens': 9, 'total_tokens': 27} tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-d188-7442-934a-1417836062c3' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[] chunk_position='last'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for deepseek:\n",
      "content='' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-d485-7e63-8653-121eb77f3878' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='The' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-d485-7e63-8653-121eb77f3878' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' capital' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-d485-7e63-8653-121eb77f3878' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' of' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-d485-7e63-8653-121eb77f3878' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' France' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-d485-7e63-8653-121eb77f3878' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' is' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-d485-7e63-8653-121eb77f3878' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' **' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-d485-7e63-8653-121eb77f3878' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='Paris' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-d485-7e63-8653-121eb77f3878' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='**.' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-d485-7e63-8653-121eb77f3878' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'model_provider': 'openai'} id='lc_run--019c0ffc-d485-7e63-8653-121eb77f3878' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 17, 'output_tokens': 8, 'total_tokens': 25, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}} tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-d485-7e63-8653-121eb77f3878' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[] chunk_position='last'\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, llm in models:\n",
    "    try:\n",
    "        # Create a new streaming instance using the factory\n",
    "        streaming_llm = AIFactory.create_language(llm.provider, llm.model_name, config={\"streaming\": True})\n",
    "        print(f\"Results for {streaming_llm.provider}:\")\n",
    "        model = streaming_llm.to_langchain()\n",
    "        response = model.stream(messages)\n",
    "        for chunk in response:\n",
    "            print(chunk)\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process for {name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for openai-compatible:\n",
      "content='' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-d9ea-7432-841b-06d0200ad999' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-d9ea-7432-841b-06d0200ad999' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-d9ea-7432-841b-06d0200ad999' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-d9ea-7432-841b-06d0200ad999' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-d9ea-7432-841b-06d0200ad999' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='Paris' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-d9ea-7432-841b-06d0200ad999' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' is' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-d9ea-7432-841b-06d0200ad999' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' the' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-d9ea-7432-841b-06d0200ad999' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' capital' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-d9ea-7432-841b-06d0200ad999' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' city' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-d9ea-7432-841b-06d0200ad999' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' of' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-d9ea-7432-841b-06d0200ad999' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' France' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-d9ea-7432-841b-06d0200ad999' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='.' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-d9ea-7432-841b-06d0200ad999' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'openai/gpt-oss-120b', 'model_provider': 'openai'} id='lc_run--019c0ffc-d9ea-7432-841b-06d0200ad999' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-d9ea-7432-841b-06d0200ad999' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[] chunk_position='last'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for openrouter:\n",
      "content='' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-dff3-7b10-8ad3-c8daa3f397c5' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='The' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-dff3-7b10-8ad3-c8daa3f397c5' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' capital' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-dff3-7b10-8ad3-c8daa3f397c5' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' of' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-dff3-7b10-8ad3-c8daa3f397c5' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' France' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-dff3-7b10-8ad3-c8daa3f397c5' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' is' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-dff3-7b10-8ad3-c8daa3f397c5' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' Paris' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-dff3-7b10-8ad3-c8daa3f397c5' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='.' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-dff3-7b10-8ad3-c8daa3f397c5' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'openai/gpt-4o', 'system_fingerprint': 'fp_fa7f5b168b', 'model_provider': 'openai'} id='lc_run--019c0ffc-dff3-7b10-8ad3-c8daa3f397c5' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-dff3-7b10-8ad3-c8daa3f397c5' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 23, 'output_tokens': 7, 'total_tokens': 30, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}} tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-dff3-7b10-8ad3-c8daa3f397c5' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[] chunk_position='last'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for openai:\n",
      "content='' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-e2f8-7d01-a2b7-983832bd81e9' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='The' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-e2f8-7d01-a2b7-983832bd81e9' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' capital' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-e2f8-7d01-a2b7-983832bd81e9' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' of' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-e2f8-7d01-a2b7-983832bd81e9' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' France' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-e2f8-7d01-a2b7-983832bd81e9' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' is' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-e2f8-7d01-a2b7-983832bd81e9' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' Paris' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-e2f8-7d01-a2b7-983832bd81e9' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='.' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-e2f8-7d01-a2b7-983832bd81e9' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-5-mini-2025-08-07', 'service_tier': 'default', 'model_provider': 'openai'} id='lc_run--019c0ffc-e2f8-7d01-a2b7-983832bd81e9' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-e2f8-7d01-a2b7-983832bd81e9' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[] chunk_position='last'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for xai:\n",
      "content='The' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-ebaa-7141-b68e-b3bb57369575' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' capital' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-ebaa-7141-b68e-b3bb57369575' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' of' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-ebaa-7141-b68e-b3bb57369575' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' France' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-ebaa-7141-b68e-b3bb57369575' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' is' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-ebaa-7141-b68e-b3bb57369575' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' Paris' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-ebaa-7141-b68e-b3bb57369575' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='.' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-ebaa-7141-b68e-b3bb57369575' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'grok-3', 'system_fingerprint': 'fp_a50f881eb7', 'model_provider': 'openai'} id='lc_run--019c0ffc-ebaa-7141-b68e-b3bb57369575' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-ebaa-7141-b68e-b3bb57369575' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[] chunk_position='last'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for anthropic:\n",
      "Failed to process for anthropic: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}, 'request_id': 'req_011CXdyFtP5EZGn3ij5TZeTL'}\n",
      "Results for groq:\n",
      "content='' additional_kwargs={} response_metadata={'model_provider': 'groq'} id='lc_run--019c0ffc-f060-7b20-9418-8ab4f0e26555' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='The' additional_kwargs={} response_metadata={'model_provider': 'groq'} id='lc_run--019c0ffc-f060-7b20-9418-8ab4f0e26555' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' capital' additional_kwargs={} response_metadata={'model_provider': 'groq'} id='lc_run--019c0ffc-f060-7b20-9418-8ab4f0e26555' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' of' additional_kwargs={} response_metadata={'model_provider': 'groq'} id='lc_run--019c0ffc-f060-7b20-9418-8ab4f0e26555' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' France' additional_kwargs={} response_metadata={'model_provider': 'groq'} id='lc_run--019c0ffc-f060-7b20-9418-8ab4f0e26555' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' is' additional_kwargs={} response_metadata={'model_provider': 'groq'} id='lc_run--019c0ffc-f060-7b20-9418-8ab4f0e26555' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' Paris' additional_kwargs={} response_metadata={'model_provider': 'groq'} id='lc_run--019c0ffc-f060-7b20-9418-8ab4f0e26555' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='.' additional_kwargs={} response_metadata={'model_provider': 'groq'} id='lc_run--019c0ffc-f060-7b20-9418-8ab4f0e26555' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_020e283281', 'service_tier': 'on_demand'} id='lc_run--019c0ffc-f060-7b20-9418-8ab4f0e26555' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 48, 'output_tokens': 8, 'total_tokens': 56} tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-f060-7b20-9418-8ab4f0e26555' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[] chunk_position='last'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for ollama:\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-f171-73e0-b966-616fd227072d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-f171-73e0-b966-616fd227072d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-f171-73e0-b966-616fd227072d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-f171-73e0-b966-616fd227072d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-f171-73e0-b966-616fd227072d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-f171-73e0-b966-616fd227072d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-f171-73e0-b966-616fd227072d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-f171-73e0-b966-616fd227072d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-f171-73e0-b966-616fd227072d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-f171-73e0-b966-616fd227072d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-f171-73e0-b966-616fd227072d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-f171-73e0-b966-616fd227072d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='The' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-f171-73e0-b966-616fd227072d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' capital' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-f171-73e0-b966-616fd227072d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' of' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-f171-73e0-b966-616fd227072d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' France' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-f171-73e0-b966-616fd227072d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' is' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-f171-73e0-b966-616fd227072d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' **' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-f171-73e0-b966-616fd227072d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='Paris' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-f171-73e0-b966-616fd227072d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='**' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-f171-73e0-b966-616fd227072d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='.' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-f171-73e0-b966-616fd227072d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={'model': 'gpt-oss:20b', 'created_at': '2026-01-30T17:38:52.889287956Z', 'done': True, 'done_reason': 'stop', 'total_duration': 786794498, 'load_duration': 141211841, 'prompt_eval_count': 87, 'prompt_eval_duration': 21380788, 'eval_count': 31, 'eval_duration': 611871767, 'logprobs': None, 'model_name': 'gpt-oss:20b', 'model_provider': 'ollama'} id='lc_run--019c0ffc-f171-73e0-b966-616fd227072d' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 87, 'output_tokens': 31, 'total_tokens': 118} tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-f171-73e0-b966-616fd227072d' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[] chunk_position='last'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for google:\n",
      "content='The' additional_kwargs={} response_metadata={'safety_ratings': [], 'model_provider': 'google_genai'} id='lc_run--019c0ffc-f4af-7652-b8e8-53f65f9701b2' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 15, 'output_tokens': 0, 'total_tokens': 15, 'input_token_details': {'cache_read': 0}} tool_call_chunks=[]\n",
      "content=' capital of France' additional_kwargs={} response_metadata={'safety_ratings': [], 'model_provider': 'google_genai'} id='lc_run--019c0ffc-f4af-7652-b8e8-53f65f9701b2' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_token_details': {'cache_read': 0}, 'total_tokens': 0, 'output_tokens': 0, 'input_tokens': 0} tool_call_chunks=[]\n",
      "content=' is Paris.\\n' additional_kwargs={} response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': [], 'model_provider': 'google_genai'} id='lc_run--019c0ffc-f4af-7652-b8e8-53f65f9701b2' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_token_details': {'cache_read': 0}, 'total_tokens': 7, 'output_tokens': 8, 'input_tokens': -1} tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-f4af-7652-b8e8-53f65f9701b2' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[] chunk_position='last'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for google:\n",
      "content='The capital of France is **Paris**.' additional_kwargs={} response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'} id='lc_run--019c0ffc-f74a-7bd0-9af4-a583b6b29c0c' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 15, 'output_tokens': 30, 'total_tokens': 45, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 22}} tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-f74a-7bd0-9af4-a583b6b29c0c' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[] chunk_position='last'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for azure:\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-fc45-7031-92e4-e5e293f67eae' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-fc45-7031-92e4-e5e293f67eae' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='The' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-fc45-7031-92e4-e5e293f67eae' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' capital' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-fc45-7031-92e4-e5e293f67eae' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' of' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-fc45-7031-92e4-e5e293f67eae' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' France' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-fc45-7031-92e4-e5e293f67eae' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' is' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-fc45-7031-92e4-e5e293f67eae' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' Paris' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-fc45-7031-92e4-e5e293f67eae' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='.' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffc-fc45-7031-92e4-e5e293f67eae' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'o4-mini-2025-04-16', 'model_provider': 'openai'} id='lc_run--019c0ffc-fc45-7031-92e4-e5e293f67eae' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffc-fc45-7031-92e4-e5e293f67eae' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[] chunk_position='last'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for mistral:\n",
      "content='' additional_kwargs={} response_metadata={'model_provider': 'mistralai'} id='lc_run--019c0ffd-00ff-7aa0-8504-6e5456baa0a2' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='The' additional_kwargs={} response_metadata={'model_provider': 'mistralai'} id='lc_run--019c0ffd-00ff-7aa0-8504-6e5456baa0a2' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' capital of France' additional_kwargs={} response_metadata={'model_provider': 'mistralai'} id='lc_run--019c0ffd-00ff-7aa0-8504-6e5456baa0a2' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' is **Paris' additional_kwargs={} response_metadata={'model_provider': 'mistralai'} id='lc_run--019c0ffd-00ff-7aa0-8504-6e5456baa0a2' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='**.' additional_kwargs={} response_metadata={'model_provider': 'mistralai', 'model_name': 'mistral-large-latest', 'finish_reason': 'stop'} id='lc_run--019c0ffd-00ff-7aa0-8504-6e5456baa0a2' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 18, 'output_tokens': 9, 'total_tokens': 27} tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffd-00ff-7aa0-8504-6e5456baa0a2' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[] chunk_position='last'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for deepseek:\n",
      "content='' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffd-0327-7df2-9faf-5ca46bf8a100' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='The' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffd-0327-7df2-9faf-5ca46bf8a100' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' capital' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffd-0327-7df2-9faf-5ca46bf8a100' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' of' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffd-0327-7df2-9faf-5ca46bf8a100' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' France' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffd-0327-7df2-9faf-5ca46bf8a100' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' is' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffd-0327-7df2-9faf-5ca46bf8a100' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content=' **' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffd-0327-7df2-9faf-5ca46bf8a100' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='Paris' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffd-0327-7df2-9faf-5ca46bf8a100' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='**.' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c0ffd-0327-7df2-9faf-5ca46bf8a100' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'model_provider': 'openai'} id='lc_run--019c0ffd-0327-7df2-9faf-5ca46bf8a100' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 17, 'output_tokens': 8, 'total_tokens': 25, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}} tool_call_chunks=[]\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--019c0ffd-0327-7df2-9faf-5ca46bf8a100' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[] chunk_position='last'\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, llm in models:\n",
    "    try:\n",
    "        # Create a new streaming instance using the factory\n",
    "        streaming_llm = AIFactory.create_language(llm.provider, llm.model_name, config={\"streaming\": True})\n",
    "        print(f\"Results for {streaming_llm.provider}:\")\n",
    "        model = streaming_llm.to_langchain()\n",
    "        response = model.astream(messages)\n",
    "        async for chunk in response:\n",
    "            print(chunk)\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process for {name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pydantic AI\n",
    "\n",
    "Test Esperanto's Pydantic AI integration across all providers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Agent Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for openai-compatible:\n",
      "The capital of France is **Paris**.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for openrouter:\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for openai:\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for xai:\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for anthropic:\n",
      "Failed to process for anthropic: Anthropic API error: Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\n",
      "Results for groq:\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for ollama:\n",
      "The capital of France is **Paris**.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for google:\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for google:\n",
      "The capital of France is **Paris**.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for azure:\n",
      "The capital of France is Paris.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for mistral:\n",
      "The capital of France is **Paris**.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for deepseek:\n",
      "The capital of France is **Paris**.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydantic_ai import Agent\n",
    "\n",
    "\n",
    "for name, llm in models:\n",
    "    try:\n",
    "        print(f\"Results for {llm.provider}:\")\n",
    "        pydantic_model = llm.to_pydantic_ai()\n",
    "        agent = Agent(pydantic_model)\n",
    "        result = await agent.run(\"What's the capital of France?\")\n",
    "        print(result.output)\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process for {name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for openai-compatible:\n",
      "1  \n",
      "2  \n",
      "3  \n",
      "4  \n",
      "5\n",
      "==================================================\n",
      "\n",
      "Results for openrouter:\n",
      "1, 2, 3, 4, 5\n",
      "==================================================\n",
      "\n",
      "Results for openai:\n",
      "1, 2, 3, 4, 5\n",
      "==================================================\n",
      "\n",
      "Results for xai:\n",
      "1, 2, 3, 4, 5\n",
      "==================================================\n",
      "\n",
      "Results for anthropic:\n",
      "Failed to process for anthropic: Anthropic API error: Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\n",
      "Results for groq:\n",
      "Here's the count from 1 to 5:\n",
      "\n",
      "1, 2, 3, 4, 5.\n",
      "==================================================\n",
      "\n",
      "Results for ollama:\n",
      "1, 2, 3, 4, 5\n",
      "==================================================\n",
      "\n",
      "Results for google:\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for google:\n",
      "1, 2, 3, 4, 5\n",
      "==================================================\n",
      "\n",
      "Results for azure:\n",
      "1  \n",
      "2  \n",
      "3  \n",
      "4  \n",
      "5\n",
      "==================================================\n",
      "\n",
      "Results for mistral:\n",
      "Here you go:\n",
      "\n",
      "1, 2, 3, 4, 5\n",
      "==================================================\n",
      "\n",
      "Results for deepseek:\n",
      "1  \n",
      "2  \n",
      "3  \n",
      "4  \n",
      "5\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, llm in models:\n",
    "    try:\n",
    "        print(f\"Results for {llm.provider}:\")\n",
    "        pydantic_model = llm.to_pydantic_ai()\n",
    "        agent = Agent(pydantic_model)\n",
    "        \n",
    "        async with agent.run_stream(\"Count from 1 to 5.\") as response:\n",
    "            async for chunk in response.stream_text():\n",
    "                print(chunk, end=\"\", flush=True)\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process for {name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for openai-compatible:\n",
      "Failed to process for openai-compatible: Exceeded maximum retries (1) for output validation\n",
      "Results for openrouter:\n",
      "The result of the dice roll is 4.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for openai:\n",
      "You rolled a 5.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for xai:\n",
      "The die roll resulted in a 2.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for anthropic:\n",
      "Failed to process for anthropic: Anthropic API error: Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\n",
      "Results for groq:\n",
      "You rolled a 6 and then a 5.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for ollama:\n",
      "You rolled a **5**!  If youd like another roll or have something else in mind, just let me know.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for google:\n",
      "Okay, I rolled the dice and you got a 2.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for google:\n",
      "You rolled a 4!\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for azure:\n",
      "You rolled a 2.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for mistral:\n",
      "The dice landed on **1**! \n",
      "Want to roll again?\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for deepseek:\n",
      "You rolled a 2!\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "for name, llm in models:\n",
    "    try:\n",
    "        print(f\"Results for {llm.provider}:\")\n",
    "        pydantic_model = llm.to_pydantic_ai()\n",
    "        \n",
    "        agent = Agent(\n",
    "            pydantic_model,\n",
    "            instructions=\"You're playing a dice game. Roll the die and tell the user the result.\"\n",
    "        )\n",
    "        \n",
    "        @agent.tool_plain\n",
    "        def roll_dice() -> str:\n",
    "            \"\"\"Roll a six-sided die and return the result.\"\"\"\n",
    "            result = random.randint(1, 6)\n",
    "            return str(result)\n",
    "        \n",
    "        result = await agent.run(\"Roll the dice for me!\")\n",
    "        print(result.output)\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process for {name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for openai-compatible:\n",
      "Failed to process for openai-compatible: Exceeded maximum retries (1) for output validation\n",
      "Results for openrouter:\n",
      "Cities: cities=[City(name='Tokyo', country='Japan', population=37400068), City(name='Delhi', country='India', population=29399141), City(name='Shanghai', country='China', population=26317104)]\n",
      "  - Tokyo, Japan: 37400068\n",
      "  - Delhi, India: 29399141\n",
      "  - Shanghai, China: 26317104\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for openai:\n",
      "Cities: cities=[City(name='Tokyo', country='Japan', population=37400000), City(name='Delhi', country='India', population=31000000), City(name='Shanghai', country='China', population=27000000)]\n",
      "  - Tokyo, Japan: 37400000\n",
      "  - Delhi, India: 31000000\n",
      "  - Shanghai, China: 27000000\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for xai:\n",
      "Cities: cities=[City(name='Tokyo', country='Japan', population=37400068), City(name='Delhi', country='India', population=29399141), City(name='Shanghai', country='China', population=26317104)]\n",
      "  - Tokyo, Japan: 37400068\n",
      "  - Delhi, India: 29399141\n",
      "  - Shanghai, China: 26317104\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for anthropic:\n",
      "Failed to process for anthropic: Anthropic API error: Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\n",
      "Results for groq:\n",
      "Failed to process for groq: Groq API error: Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\n",
      "Results for ollama:\n",
      "Cities: cities=[City(name='Tokyo', country='Japan', population=37400068), City(name='Delhi', country='India', population=31870000), City(name='Shanghai', country='China', population=25760000)]\n",
      "  - Tokyo, Japan: 37400068\n",
      "  - Delhi, India: 31870000\n",
      "  - Shanghai, China: 25760000\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for google:\n",
      "Failed to process for google: Exceeded maximum retries (1) for output validation\n",
      "Results for google:\n",
      "Cities: cities=[City(name='Tokyo', country='Japan', population=37000000), City(name='Delhi', country='India', population=32000000), City(name='Shanghai', country='China', population=28000000)]\n",
      "  - Tokyo, Japan: 37000000\n",
      "  - Delhi, India: 32000000\n",
      "  - Shanghai, China: 28000000\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for azure:\n",
      "Cities: cities=[City(name='Tokyo', country='Japan', population=37400000), City(name='Delhi', country='India', population=30200000), City(name='Shanghai', country='China', population=27100000)]\n",
      "  - Tokyo, Japan: 37400000\n",
      "  - Delhi, India: 30200000\n",
      "  - Shanghai, China: 27100000\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for mistral:\n",
      "Cities: cities=[City(name='Tokyo', country='Japan', population=37435000), City(name='Delhi', country='India', population=32941000), City(name='Shanghai', country='China', population=29210000)]\n",
      "  - Tokyo, Japan: 37435000\n",
      "  - Delhi, India: 32941000\n",
      "  - Shanghai, China: 29210000\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for deepseek:\n",
      "Cities: cities=[City(name='Tokyo', country='Japan', population=37400068), City(name='Delhi', country='India', population=28514000), City(name='Shanghai', country='China', population=25582000)]\n",
      "  - Tokyo, Japan: 37400068\n",
      "  - Delhi, India: 28514000\n",
      "  - Shanghai, China: 25582000\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "from esperanto import AIFactory\n",
    "from pydantic_ai import Agent\n",
    "params = {\n",
    "    \"max_tokens\": 850,\n",
    "    \"temperature\": 1.0,\n",
    "    \"streaming\": False,\n",
    "    \"top_p\": 0.9,\n",
    "    # \"structured\": {\"type\": \"json\"}\n",
    "}\n",
    "\n",
    "models = [\n",
    "    (\"openai-compatible\", AIFactory.create_language(\"openai-compatible\", \"qwen3:4b\", config=params)),\n",
    "    (\"openrouter\", AIFactory.create_language(\"openrouter\", \"openai/gpt-4o\", config=params)),\n",
    "    (\"openai\", AIFactory.create_language(\"openai\", \"gpt-5-mini\", config=params)),\n",
    "    (\"xai\", AIFactory.create_language(\"xai\", \"grok-3\", config=params)),\n",
    "    (\"anthropic\", AIFactory.create_language(\"anthropic\", \"claude-4-sonnet-latest\", config=params)),\n",
    "    (\"groq\", AIFactory.create_language(\"groq\", \"llama-3.1-8b-instant\", config=params)),\n",
    "    (\"ollama\", AIFactory.create_language(\"ollama\", \"gpt-oss:20b\", config=params)),\n",
    "    (\"google\", AIFactory.create_language(\"google\", \"gemini-2.0-flash\", config=params)),\n",
    "    (\"google\", AIFactory.create_language(\"google\", \"gemini-2.5-flash\", config=params)),\n",
    "    (\"azure\", AIFactory.create_language(\"azure\", \"o4-mini\", config=params)),\n",
    "    (\"mistral\", AIFactory.create_language(\"mistral\", \"mistral-large-latest\", config=params)),\n",
    "    (\"deepseek\", AIFactory.create_language(\"deepseek\", \"deepseek-chat\", config=params)),\n",
    "    # (\"vertex\", AIFactory.create_language(\"vertex\", \"gemini-2.0-flash\")),\n",
    "]\n",
    "\n",
    "\n",
    "class City(BaseModel):\n",
    "    \"\"\"A city with its details.\"\"\"\n",
    "    name: str\n",
    "    country: str\n",
    "    population: Optional[int] = None\n",
    "\n",
    "class CitiesResponse(BaseModel):\n",
    "    \"\"\"Response containing a list of cities.\"\"\"\n",
    "    cities: List[City]\n",
    "\n",
    "for name, llm in models:\n",
    "    try:\n",
    "        print(f\"Results for {llm.provider}:\")\n",
    "        pydantic_model = llm.to_pydantic_ai()\n",
    "        \n",
    "        agent = Agent(pydantic_model, output_type=CitiesResponse)\n",
    "        \n",
    "        result = await agent.run(\"List the top 3 most populous cities in the world. - return it as a JSON object, like this: {cities: [{name: 'City 1', country: 'Country 1', population: 1000000}, {name: 'City 2', country: 'Country 2', population: 2000000}, {name: 'City 3', country: 'Country 3', population: 3000000}]}\")\n",
    "        print(f\"Cities: {result.output}\")\n",
    "        for city in result.output.cities:\n",
    "            print(f\"  - {city.name}, {city.country}: {city.population}\")\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process for {name}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
